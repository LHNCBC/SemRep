This is sicstus.info, produced by makeinfo version 5.2 from
sicstus.texi.

INFO-DIR-SECTION SICStus Prolog
START-INFO-DIR-ENTRY
* SICStus Prolog Manual: (sicstus).			SICStus Prolog User's Manual.
END-INFO-DIR-ENTRY

Generated March 15, 2018.


File: sicstus.info,  Node: lib-aggregate,  Next: lib-assoc,  Up: The Prolog Library

10.1 An Aggregation Operator for Data-Base-Style Queries--'library(aggregate)'
==============================================================================

Data base query languages usually provide so-called "aggregation"
operations.  Given a relation, aggregation specifies
   * a column of the relation
   * an operation, one of {sum,max,min,ave,var} or more

   One might, for example, ask

         PRINT DEPT,SUM(AREA) WHERE OFFICE(_ID,DEPT,AREA,_OCCUPANT)

   and get a table of <DEPARTMENT,TOTALAREA> pairs.  The Prolog
equivalent of this might be

         dept_office_area(Dept, TotalArea) :-
                 aggregate(sum(Area),
                     I^O^office(I,Dept,Area,O), TotalArea).

   where AREA is the column and 'sum(_)' is the aggregation operator.
We can also ask who has the smallest office in each department:

         smallest_office(Dept, Occupant) :-
                 aggregate(min(Area),
                         I^O^office(I,Dept,Area,O), MinArea),
                 office(_, Dept, MinArea, Occupant).

   This module provides an aggregation operator in Prolog:

             aggregate(Template, Generator, Results)

   where:
   * TEMPLATE is OPERATOR(EXPRESSION) or CONSTRUCTOR(ARG,...,ARG)
   * each ARG is OPERATOR(EXPRESSION)
   * OPERATOR is 'sum | min | max' {for now}
   * EXPRESSION is an arithmetic expression

   RESULTS is unified with a form of the same structure as TEMPLATE.

   Things like mean and standard deviation can be calculated from sums,
e.g.  to find the average population of countries (defined as "if you
sampled people at random, what would be the mean size of their answers
to the question 'what is the population of your country?'?")  we could
do

     ?-  aggregate(x(sum(Pop),sum(Pop*Pop)),
                   Country^population(Country,Pop),
                   x(People,PeopleTimesPops)),
         AveragePop is PeopleTimesPops/People.

   Note that according to this definition, 'aggregate/3' FAILS if there
are no solutions.  For 'max(_)', 'min(_)', and many other operations
(such as 'mean(_)') this is the only sensible definition (which is why
'bagof/3' works that way).  Even if BAGOF/3 yielded an empty list,
AGGREGATE/3 would still fail.

   Concerning the minimum and maximum, it is convenient at times to know
Which term had the minimum or maximum value.  So we write

         min(Expression, Term)
         max(Expression, Term)

   and in the constructed term we will have

         min(MinimumValue, TermForThatValue)
         max(MaximumValue, TermForThatValue)

   So another way of asking who has the smallest office is

         smallest_office(Dept, Occupant) :-
                 aggregate(min(Area,O),
                         I^office(I,Dept,Area,O), min(_,Occupant)).

   Consider queries like

         aggregate(sum(Pay), Person^pay(Person,Pay), TotalPay)

   where for some reason 'pay/2' might have multiple solutions.  (For
example, someone might be listed in two departments.)  We need a way of
saying "treat identical instances of the Template as a single instance,
UNLESS they correspond to different instances of a Discriminator."  That
is what

         aggregate(Template, Discriminator, Generator, Results)

   does.

   Operations available:
'count'
     'sum(1)'
'sum(E)'
     sum of values of E
'min(E)'
     minimum of values of E
'min(E,X)'
     'min(E)' with corresponding instance of X
'max(E)'
     maximum of values of E
'max(E,X)'
     'max(E)' with corresponding instance of X
'set(X)'
     ordered set of instances of X
'bag(X)'
     list of instances of X in generated order.

     bagof(X, G, B) :- aggregate(bag(X),    G, L).
     setof(X, G, B) :- aggregate(set(X), X, G, L).

   Exported predicates:

'forall(:GENERATOR, :GOAL)'

     succeeds when GOAL is provable for each true instance of GENERATOR.
     Note that there is a sort of double negation going on in here (it
     is in effect a nested pair of failure-driven loops), so it will
     never bind any of the variables which occur in it.
'foreach(:GENERATOR, :GOAL)'

     for each proof of Generator in turn, we make a copy of GOAL with
     the appropriate substitution, then we execute these copies in
     sequence.  For example, 'foreach(between(1,3,I), p(I))' is
     equivalent to 'p(1), p(2), p(3)'.

     Note that this is not the same as 'forall/2'.  For example,
     'forall(between(1,3,I), p(I))' is equivalent to '\+ \+ p(1), \+ \+
     p(2), \+ \+ p(3)'.

     The trick in 'foreach/2' is to ensure that the variables of GOAL
     which do not occur in GENERATOR are restored properly.  (If there
     are no such variables, you might as well use 'forall/2'.)

     Like 'forall/2', this predicate does a failure-driven loop over the
     GENERATOR.  Unlike 'forall/2', the GOALS are executed as an
     ordinary conjunction, and may succeed in more than one way.
'aggregate(+TEMPLATE, +DISCRIMINATOR, :GENERATOR, -RESULT)'

     is a generalisation of 'setof/3' which lets you compute sums,
     minima, maxima, and so on.
'aggregate(+TEMPLATE, :GENERATOR, -RESULT)'

     is a generalisation of 'findall/3' which lets you compute sums,
     minima, maxima, and so on.
'aggregate_all(+Template, +Discriminator, :Generator, -Result)'

     is like 'aggregate/4' except that it will find at most one
     solution, and does not bind free variables in the GENERATOR.
'aggregate_all(+Template, :Generator, -Result)'

     is like 'aggregate/3' except that it will find at most one
     solution, and does not bind free variables in the GENERATOR.
'free_variables(:Goal, +Bound, +Vars0, -Vars)'

     binds VARS to the union of VARS0 with the set of _free_ variables
     in GOAL, that is the set of variables which are captured neither by
     BOUND nor by any internal quantifiers or templates in GOAL.  We
     have to watch out for 'setof/3' and 'bagof/3' themselves, for the
     explicit existential quantifier 'VARS^GOAL', and for things like
     '\+(_)' which might look as though they bind variables but can't.
'term_variables(+TERM, +VARS0, -VARS)'

     binds VARS to a union of VARS0 and the variables which occur in
     TERM.  This doesn't take quantifiers into account at all.

     New code should consider the built in 'term_variables/2' which is
     likely to be faster, and works for cyclic terms.

     Could be defined as:

          term_variables(Term, Vars0, Vars) :-
          	nonvar(Term), !,
          	(   foreacharg(Arg,Term),
          	    fromto(Vars0,S0,S,Vars)
          	do  term_variables(Arg, S0, S)
          	).
          term_variables(Term, Vars0, Vars) :-
          	(   foreach(X,Vars0),
          	    param(Term)
          	do  X\==Term
          	), !,
              Vars = [Term|Vars0].
          term_variables(_, Vars, Vars).


File: sicstus.info,  Node: lib-assoc,  Next: lib-atts,  Prev: lib-aggregate,  Up: The Prolog Library

10.2 Association Lists--'library(assoc)'
========================================

This library provides a binary tree implementation of "association
lists".  The binary tree is _not_ kept balanced, as opposed to
'library(avl)', which provides similar functionality based on balanced
AVL trees.

   Exported predicates:

'empty_assoc(?ASSOC)'

     is true when ASSOC is an empty assoc.
'assoc_to_list(+ASSOC, -LIST)'

     assumes that ASSOC is a proper "assoc" tree, and is true when LIST
     is a list of KEY-VALUE pairs in ascending order with no duplicate
     KEYS specifying the same finite function as ASSOC.  Use this to
     convert an assoc to a list.
'gen_assoc(?KEY, +ASSOC, ?VALUE)'

     assumes that ASSOC is a proper "assoc" tree, and is true when KEY
     is associated with VALUE in ASSOC.  Use this to enumerate KEYS and
     VALUES in the ASSOC, or to find KEYS associated with a particular
     VALUE.  If you want to look up a particular KEY, you should use
     'get_assoc/3'.  Note that this predicate is not determinate.  If
     you want to maintain a finite bijection, it is better to maintain
     two assocs than to drive one both ways.  The KEYS and VALUES are
     enumerated in ascending order of KEYS.
'get_assoc(+KEY, +ASSOC, -VALUE)'

     assumes that ASSOC is a proper "assoc" tree.  It is true when KEY
     is identical to ('==') one of the keys in ASSOC, and Value unifies
     with the associated value.  Note that since we use the term
     ordering to identify keys, we obtain logarithmic access, at the
     price that it is not enough for the KEY to unify with a key in
     ASSOC, it must be identical.  This predicate is determinate.  The
     argument order follows the pattern established by the built-in
     predicate 'arg/3' (called the 'arg/3', or selector, rule):
              PREDICATE(INDICES, STRUCTURE, ELEMENT).
     The analogy with 'arg(N, TERM, ELEMENT)' is that
              KEY:N :: ASSOC:TERM :: VALUE:ELEMENT.
'get_next_assoc(+KEY, +ASSOC, -KNEXT, -VNEXT)'

     is true when KNEXT is the smallest key in ASSOC such that
     KNEXT@>KEY, and VNEXT is the value associated with KNEXT.  If there
     is no such KNEXT, 'get_next_assoc/4' naturally fails.  It assumes
     that ASSOC is a proper assoc.  KEY should normally be ground.  Note
     that there is no need for KEY to be in the association at all.  You
     can use this predicate in combination with 'min_assoc/3' to
     traverse an association tree; but if there are N pairs in the tree
     the cost will be O(N LG N).  If you want to traverse all the pairs,
     calling 'assoc_to_list/2' and walking down the list will take O(N)
     time.
'get_prev_assoc(+KEY, +ASSOC, -KPREV, -VPREV)'

     is true when KPREV is the largest key in ASSOC such that
     KPREV@<KEY, and VPREV is the value associated with KPREV.  You can
     use this predicate in combination with 'max_assoc/3' to traverse an
     assoc.  See the notes on 'get_next_assoc/4'.
'is_assoc(+THING)'

     is true when THING is a (proper) association tree.  If you use the
     routines in this file, you have no way of constructing a tree with
     an unbound tip, and the heading of this file explicitly warns
     against using variables as keys, so such structures are NOT
     recognised as being association trees.  Note that the code relies
     on variables (to be precise, the first anonymous variable in
     'is_assoc/1') being '@<' than any non-variable.
'list_to_assoc(+LIST, -ASSOC)'

     is true when LIST is a proper list of KEY-VAL pairs (in any order)
     and ASSOC is an association tree specifying the same finite
     function from KEYS to VALUES.  Note that the list should not
     contain any duplicate keys.  In this release, 'list_to_assoc/2'
     doesn't check for duplicate keys, but the association tree which
     gets built won't work.
'ord_list_to_assoc(+LIST, -ASSOC)'

     is a version of 'list_to_assoc/2' which trusts you to have sorted
     the list already.  If you pair up an ordered set with suitable
     values, calling this instead will save the sort.
'map_assoc(:PRED, +ASSOC)'

     is true when ASSOC is a proper association tree, and for each
     KEY->VAL pair in ASSOC, the proposition PRED(VAL) is true.  PRED
     must be a closure, and ASSOC should be proper.  There should be a
     version of this predicate which passes KEY to PRED as well as VAL,
     but there isn't.
'map_assoc(:PRED, ?OLDASSOC, ?NEWASSOC)'

     is true when OLDASSOC and NEWASSOC are association trees of the
     same shape (at least one of them should be provided as a proper
     assoc, or 'map_assoc/3' may not terminate), and for each KEY, if
     KEY is associated with OLD in OLDASSOC and with NEW in NEWASSOC,
     the proposition PRED(OLD,NEW) is true.  Normally we assume that
     PRED is a function from OLD to NEW, but the code does not require
     that.  There should be a version of this predicate which passes KEY
     to PRED as well as OLD and NEW, but there isn't.  If you'd have a
     use for it, please tell us.
'max_assoc(+ASSOC, -KEY, -VAL)'

     is true when KEY is the largest KEY in ASSOC, and VAL is the
     associated value.  It assumes that ASSOC is a proper assoc.  This
     predicate is determinate.  If ASSOC is empty, it just fails
     quietly; an empty set can have no largest element!
'min_assoc(+ASSOC, -KEY, -VAL)'

     is true when KEY is the smallest KEY in ASSOC, and VAL is the
     associated value.  It assumes that ASSOC is a proper assoc.  This
     predicate is determinate.  If ASSOC is empty, it just fails
     quietly; an empty set can have no smallest element!
'portray_assoc(+ASSOC)'

     writes an association tree to the current output stream in a pretty
     form so that you can easily see what it is.  Note that an
     association tree written out this way can NOT be read back in.  For
     that, use 'writeq/1'.  The point of this predicate is to get
     association trees displayed nicely by 'print/1'.
'put_assoc(+KEY, +OLDASSOC, +VAL, -NEWASSOC)'

     is true when OLDASSOC and NEWASSOC define the same finite function,
     except that NEWASSOC associates VAL with KEY.  OLDASSOC need not
     have associated any value at all with Key,


File: sicstus.info,  Node: lib-atts,  Next: lib-avl,  Prev: lib-assoc,  Up: The Prolog Library

10.3 Attributed Variables--'library(atts)'
==========================================

This package implements attributed variables.  It provides a means of
associating with variables arbitrary attributes, i.e. named properties
that can be used as storage locations as well as to extend the default
unification algorithm when such variables are unified with other terms
or with each other.  This facility was primarily designed as a clean
interface between Prolog and constraint solvers, but has a number of
other uses as well.  The basic idea is due to Christian Holzbaur and he
was actively involved in the final design.  For background material, see
the dissertation [Holzbaur 90].

   The package provides a means to declare and access named attributes
of variables.  The attributes are compound terms whose arguments are the
actual attribute values.  The attribute names are _private_ to the
module in which they are defined.  They are defined with a declaration

     :- attribute ATTRIBUTESPEC, ..., ATTRIBUTESPEC.

where each ATTRIBUTESPEC has the form (NAME/ARITY).  There must be at
most one such declaration in a module MODULE.

   Having declared some attribute names, these attributes can now be
added, updated and deleted from unbound variables.  For each declared
attribute name, any variable can have at most one such attribute
(initially it has none).

   The declaration causes the following two access predicates to become
defined by means of the 'goal_expansion/5' mechanism.  They take a
variable and an ACCESSSPEC as arguments where an ACCESSSPEC is either
'+(ATTRIBUTE)', '-(ATTRIBUTE)', or a list of such.  The '+' prefix may
be dropped for convenience.  ATTRIBUTE must be nonvariable at compile
time.  The meaning of the '+'/'-' prefix is documented below:

'MODULE:get_atts(-VAR, ?ACCESSSPEC)'
     Gets the attributes of VAR according to ACCESSSPEC.  If ACCESSSPEC
     is unbound, it will be bound to a list of all present attributes of
     VAR, which must be a variable.  The elements of ACCESSSPEC have the
     following meaning:
     '+(ATTRIBUTE)'
          The corresponding actual attribute must be present and is
          unified with ATTRIBUTE.

     '-(ATTRIBUTE)'
          The corresponding actual attribute must be absent.  The
          arguments of ATTRIBUTE are ignored, only the name and arity
          are relevant.

'MODULE:put_atts(-VAR, +ACCESSSPEC)'
     Sets the attributes of VAR, which must be a variable, according to
     ACCESSSPEC.  The effects of 'put_atts/2' are undone on
     backtracking.
     '+(ATTRIBUTE)'
          The corresponding actual attribute is set to ATTRIBUTE.  If
          the actual attribute was already present, it is simply
          replaced.

     '-(ATTRIBUTE)'
          The corresponding actual attribute is removed.  If the actual
          attribute was already absent, nothing happens.

   A module that contains an attribute declaration has an opportunity to
extend the default unification algorithm by defining the following
predicate:

'MODULE:verify_attributes(-VAR, +VALUE, -GOALS)   hook'
     This predicate is called whenever a variable VAR that might have
     attributes in MODULE is about to be bound to VALUE (it might have
     none).  The unification resumes after the call to
     'verify_attributes/3'.  VALUE is a nonvariable, or another
     attributed variable.  VAR might have no attributes present in
     MODULE; the unification extension mechanism is not sophisticated
     enough to filter out exactly the variables that are relevant for
     MODULE.

     'verify_attributes/3' is called _before_ VAR has actually been
     bound to VALUE.  If it fails, the unification is deemed to have
     failed.  It may succeed nondeterminately, in which case the
     unification might backtrack to give another answer.  It is expected
     to return, in GOALS, a list of goals to be called _after_ VAR has
     been bound to VALUE.  Finally, after calling GOALS, any goals
     blocked on VAR are called.

     'verify_attributes/3' may invoke arbitrary Prolog goals, but VAR
     should _not_ be bound by it.  Binding VAR will result in undefined
     behavior.

     If VALUE is a nonvariable, 'verify_attributes/3' will typically
     inspect the attributes of VAR and check that they are compatible
     with VALUE and fail otherwise.  If VALUE is another attributed
     variable, 'verify_attributes/3' will typically copy the attributes
     of VAR over to VALUE, or merge them with VALUE's, in preparation
     for VAR to be bound to VALUE.  In either case,
     'verify_attributes/3' may determine VAR's current attributes by
     calling 'get_atts(VAR,LIST)' with an unbound LIST.

     In the case when a single unification binds multiple attributed
     variables, first all such bindings are _undone_, then the following
     actions are carried out for each relevant variable:

       1. For each relevant module M, 'M:verify_attributes/3' is called,
          collecting a list of returned GOALS.
       2. The variable binding is _redone_.
       3. Any GOALS are called.
       4. Any blocked goals are called.

   An important use for attributed variables is in implementing
coroutining facilities as an alternative or complement to the built-in
coroutining mechanisms.  In this context it might be useful to be able
to interpret some of the attributes of a variable as a goal that is
blocked on that variable.  Certain built-in predicates ('frozen/2',
'copy_term/3') and the Prolog top-level need to access blocked goals,
and so need a means of getting the goal interpretation of attributed
variables by calling:

'MODULE:attribute_goal(-VAR, -GOAL)   hook'
     This predicate is called in each module that contains an attribute
     declaration, when an interpretation of the attributes as a goal is
     needed, in particular in 'frozen/2', 'copy_term/3' and the Prolog
     top-level.  It should unify GOAL with the interpretation, or merely
     fail if no such interpretation is available.

   An important use for attributed variables is to provide an interface
to constraint solvers.  An important function for a constraint solver in
the constraint logic programming paradigm is to be able to perform
projection of the residual constraints onto the variables that occurred
in the top-level query.  A module that contains an attribute declaration
has an opportunity to perform such projection of its residual
constraints by defining the following predicate:

'MODULE:project_attributes(+QUERYVARS, +ATTRVARS)   hook'
     This predicate is called by the Prolog top level in each module
     that contains an attribute declaration.  QUERYVARS is the list of
     variables occurring in the query, or in terms bound to such
     variables, and ATTRVARS is a list of possibly attributed variables
     created during the execution of the query.  The two lists of
     variables may or may not be disjoint.

     If the attributes on ATTRVARS can be interpreted as constraints,
     this predicate will typically "project" those constraints onto the
     relevant QUERYVARS.  Ideally, the residual constraints will be
     expressed entirely in terms of the QUERYVARS, treating all other
     variables as existentially quantified.  Operationally,
     'project_attributes/2' must remove all attributes from ATTRVARS,
     and add transformed attributes representing the projected
     constraints to some of the QUERYVARS.

     Projection has the following effect on the Prolog top-level.  When
     the top-level query has succeeded, 'project_attributes/2' is called
     first.  The top-level then prints the answer substition and
     residual constraints.  While doing so, it searches for attributed
     variables created during the execution of the query.  For each such
     variable, it calls 'attribute_goal/2' to get a printable
     representation of the constraint encoded by the attribute.  Thus,
     'project_attributes/2' is a mechanism for controlling how the
     residual constraints should be displayed at top-level.

     The exact definition of 'project_attributes/2' is constraint system
     dependent, but *note Answer Constraints:: and *note CLPQR
     Projection:: for details about projection in CLPFD and CLP(Q,R)
     respectively.

   In the following example we sketch the implementation of a finite
domain "solver".  Note that an industrial strength solver would have to
provide a wider range of functionality and that it quite likely would
utilize a more efficient representation for the domains proper.  The
module exports a single predicate 'domain(-VAR,?DOMAIN)', which
associates DOMAIN (a list of terms) with VAR.  A variable can be queried
for its domain by leaving DOMAIN unbound.

   We do not present here a definition for 'project_attributes/2'.
Projecting finite domain constraints happens to be difficult.

                                                          _% domain.pl_
     :- module(domain, [domain/2]).

     :- use_module(library(atts)).
     :- use_module(library(ordsets), [
             ord_intersection/3,
             ord_intersect/2,
             list_to_ord_set/2
        ]).

     :- attribute dom/1.

     verify_attributes(Var, Other, Goals) :-
             get_atts(Var, dom(Da)), !,          % are we involved?
             (   var(Other) ->                   % must be attributed then
                 (   get_atts(Other, dom(Db)) -> %   has a domain?
                     ord_intersection(Da, Db, Dc),
                     Dc = [El|Els],              % at least one element
                     (   Els = [] ->             % exactly one element
                         Goals = [Other=El]      % implied binding
                     ;   Goals = [],
                         put_atts(Other, dom(Dc))% rescue intersection
                     )
                 ;   Goals = [],
                     put_atts(Other, dom(Da))    % rescue the domain
                 )
             ;   Goals = [],
                 ord_intersect([Other], Da)      % value in domain?
             ).
     verify_attributes(_, _, []).                % unification triggered
                                                 % because of attributes
                                                 % in other modules

     attribute_goal(Var, domain(Var,Dom)) :-     % interpretation as goal
             get_atts(Var, dom(Dom)).

     domain(X, Dom) :-
             var(Dom), !,
             get_atts(X, dom(Dom)).
     domain(X, List) :-
             list_to_ord_set(List, Set),
             Set = [El|Els],                     % at least one element
             (   Els = [] ->                     % exactly one element
                 X = El                          % implied binding
             ;   put_atts(Fresh, dom(Set)),
                 X = Fresh                       % may call
                                                 % verify_attributes/3
             ).

   Note that the "implied binding" 'Other=El' was deferred until after
the completion of 'verify_attribute/3'.  Otherwise, there might be a
danger of recursively invoke 'verify_attribute/3', which might bind
'Var', which is not allowed inside the scope of 'verify_attribute/3'.
Deferring unifications into the third argument of 'verify_attribute/3'
effectively serializes th calls to 'verify_attribute/3'.

   Assuming that the code resides in the file 'domain.pl', we can load
it via:

     | ?- use_module(domain).

   Let's test it:

     | ?- domain(X,[5,6,7,1]), domain(Y,[3,4,5,6]), domain(Z,[1,6,7,8]).

     domain(X,[1,5,6,7]),
     domain(Y,[3,4,5,6]),
     domain(Z,[1,6,7,8])

     | ?- domain(X,[5,6,7,1]), domain(Y,[3,4,5,6]), domain(Z,[1,6,7,8]), 
          X=Y.

     Y = X,
     domain(X,[5,6]),
     domain(Z,[1,6,7,8])

     | ?- domain(X,[5,6,7,1]), domain(Y,[3,4,5,6]), domain(Z,[1,6,7,8]),
          X=Y, Y=Z.

     X = 6,
     Y = 6,
     Z = 6

   To demonstrate the use of the GOALS argument of
'verify_attributes/3', we give an implementation of 'freeze/2'.  We have
to name it 'myfreeze/2' in order to avoid a name clash with the built-in
predicate of the same name.

                                                        _% myfreeze.pl_
     :- module(myfreeze, [myfreeze/2]).

     :- use_module(library(atts)).

     :- attribute frozen/1.

     verify_attributes(Var, Other, Goals) :-
             get_atts(Var, frozen(Fa)), !,       % are we involved?
             (   var(Other) ->                   % must be attributed then
                 (   get_atts(Other, frozen(Fb)) % has a pending goal?
                 ->  put_atts(Other, frozen((Fa,Fb))) % rescue conjunction
                 ;   put_atts(Other, frozen(Fa)) % rescue the pending goal
                 ),
                 Goals = []
             ;   Goals = [Fa]
             ).
     verify_attributes(_, _, []).

     attribute_goal(Var, Goal) :-                % interpretation as goal
             get_atts(Var, frozen(Goal)).

     myfreeze(X, Goal) :-
             put_atts(Fresh, frozen(Goal)),
             Fresh = X.

   Assuming that this code lives in file 'myfreeze.pl', we would use it
via:

     | ?- use_module(myfreeze).
     | ?- myfreeze(X,print(bound(x,X))), X=2.

     bound(x,2)                      % side-effect
     X = 2                           % bindings

   The two solvers even work together:

     | ?- myfreeze(X,print(bound(x,X))), domain(X,[1,2,3]),
          domain(Y,[2,10]), X=Y.

     bound(x,2)                      % side-effect
     X = 2,                          % bindings
     Y = 2

   The two example solvers interact via bindings to shared attributed
variables only.  More complicated interactions are likely to be found in
more sophisticated solvers.  The corresponding 'verify_attributes/3'
predicates would typically refer to the attributes from other known
solvers/modules via the module prefix in 'MODULE:get_atts/2'.


File: sicstus.info,  Node: lib-avl,  Next: lib-bags,  Prev: lib-atts,  Up: The Prolog Library

10.4 AVL Trees--'library(avl)'
==============================

This library module provides an AVL tree implementation of "association
lists".  The binary tree _is_ kept balanced, as opposed to
'library(assoc)', which provides similar functionality based on binary
trees that are not kept balanced.

   Exported predicates:

'empty_avl(?AVL)'

     is true when AVL is an empty AVL tree.
'avl_to_list(+AVL, -LIST)'

     assumes that AVL is a proper AVL tree, and is true when LIST is a
     list of KEY-VALUE pairs in ascending order with no duplicate keys
     specifying the same finite function as AVL.  Use this to convert an
     AVL to an ordered list.
'is_avl(+AVL)'

     is true when AVL is a (proper) AVL tree.  It checks both the order
     condition (that the keys are in ascending order as you go from left
     to right) and the height balance condition.  This code relies on
     variables (to be precise, the first anonymous variable in is_avl/1)
     being '@<' than any non-variable.  in strict point of fact you
     _can_ construct an AVL tree with variables as keys, but 'is_avl/1'
     doesn't believe it, and it is not good taste to do so.
'avl_domain(+AVL, -DOMAIN)'

     unifies DOMAIN with the ordered set representation of the domain of
     the AVL tree (the keys of it).  As the keys are in ascending order
     with no duplicates, we just read them off like 'avl_to_list/2'.
'avl_range(+AVL, -RANGE)'

     unifies RANGE with the ordered set representation of the range of
     the AVL (the values associated with its keys, not the keys
     themselves).  Note that the cardinality (length) of the domain and
     the range are seldom equal, except of course for trees representing
     intertible maps.
'avl_min(+AVL, -KEY)'

     is true when KEY is the smallest key in AVL.
'avl_min(+AVL, -KEY, -VAL)'

     is true when KEY is the smallest key in AVL and VAL is its value.
'avl_max(+AVL, -KEY)'

     is true when KEY is the greatest key in AVL.
'avl_max(+AVL, -KEY, -VAL)'

     is true when KEY is the greatest key in AVL and VAL is its value.
'avl_height(+AVL, -HEIGHT)'

     is true when HEIGHT is the height of the given AVL tree, that is,
     the longest path in the tree has HEIGHT 'node's on it.
'avl_size(+AVL, -SIZE)'

     is true when SIZE is the size of the AVL tree, the number of
     'node's in it.
'portray_avl(+AVL)'

     writes an AVL tree to the current output stream in a pretty form so
     that you can easily see what it is.  Note that an AVL tree written
     out this way can NOT be read back in; for that use 'writeq/1'.  The
     point of this predicate is to get AVL trees displayed nicely by
     'print/1'.
'avl_member(?KEY, +AVL)'

     is true when KEY is one of the keys in the given AVL. This
     predicate should be used to enumerate the keys, not to look for a
     particular key (use 'avl_fetch/2' or 'avl_fetch/3' for that).  The
     KEYS are enumerated in ascending order.
'avl_member(?KEY, +AVL, ?VAL)'

     is true when KEY is one of the keys in the given AVL and VAL is the
     value the AVL associates with that KEY.  This predicate should be
     used to enumerate the keys and their values, not to look up the
     value of a known key (use 'avl_fetch/3') for that.  The KEYS are
     enumerated in ascending order.
'avl_fetch(+KEY, +AVL)'

     is true when the (given) KEY is one of the keys in the (given) AVL.
     Use this to test whether a known Key occurs in AVL and you don't
     want to know the value associated with it.
'avl_fetch(+KEY, +AVL, -VAL)'

     is true when the (given) KEY is one of the keys in the (given) AVL
     and the value associated with it therein is VAL.  It should be used
     to look up _known_ keys, not to enumerate keys (use either
     'avl_member/2' or 'avl_member/3' for that).
'avl_next(+KEY, +AVL, -KNEXT)'

     is true when KNEXT is the next key after KEY in AVL; that is, KNEXT
     is the smallest key in AVL such that KNEXT @> KEY.
'avl_next(+KEY, +AVL, -KNEXT, -VNEXT)'

     is true when KNEXT is the next key after KEY in AVL and VNEXT is
     the value associated with KNEXT in AVL.  That is, KNEXT is the
     smallest key in AVL such that KNEXT @> KEY, and 'avl_fetch(KNEXT,
     AVL, VNEXT)'.
'avl_prev(+KEY, +AVL, -KPREV)'

     is true when KPREV is the key previous to KEY in AVL; that is,
     KPREV is the greatest key in AVL such that KPREV @< KEY.
'avl_prev(+KEY, +AVL, -KPREV, -VPREV)'

     is true when KPREV is the key previous to Key in AVL and VPREV is
     the value associated with KPREV in AVL.  That is, KPREV is the
     greatest key in AVL such that KPREV @< KEY, and 'avl_fetch(KPREV,
     AVL, VPREV)'.
'avl_change(+KEY, ?AVL1, ?VAL1, ?AVL2, ?VAL2)'

     is true when AVL1 and AVL2 are avl trees of exactly the same shape,
     KEY is a key of both of them, VAL1 is the value associated with KEY
     in AVL1 and VAL2 is the value associated with it in AVL2, and when
     AVL1 and AVL2 are identical except perhaps for the value they
     assign to KEY.  Use this to change the value associated with a KEY
     which is already present, not to insert a new KEY (it won't).
'ord_list_to_avl(+LIST, -AVL)'

     is given a list of KEY-VAL pairs where the KEYS are already in
     standard order with no duplicates (this is not checked) and returns
     an AVL representing the same associations.  This takes O(N) time,
     unlike 'list_to_avl/2' which takes O(N LG N).
'list_to_avl(+PAIRS, -AVL)'

     is given a proper list of KEY-VAL pairs where the KEYS are in no
     particular order (but are sufficiently instantiated to be told
     apart) and returns an AVL representing the same associations.  This
     works by starting with an empty tree and inserting the elements of
     the list into it.  This takes O(N LG N) time.  Since it is possible
     to read off a sorted list in O(N) time from the result, O(N LG N)
     is as good as can possibly be done.  If the same KEY appears more
     than once in the input, the last value associated with it will be
     used.  Could be defined as:

          list_to_avl(Pairs, AVL) :-
          	(   foreach(K-V,Pairs),
          	    fromto(empty,AVL0,AVL1,AVL)
          	do  avl_store(K, AVL0, V, AVL1)
          	).
'avl_store(+KEY, +OLDAVL, +VAL, +NEWAVL)'

     is true when OLDAVL and NEWAVL define the same finite function
     except that NEWAVL associates VAL with KEY.  OLDAVL need not have
     associated any value at all with KEY.  When it didn't, you can read
     this as "insert (KEY->VAL) into OLDAVL giving NEWAVL".
'avl_incr(+KEY, +OLDAVL, +INCR, +NEWAVL)'

     if KEY is not present in OLDAVL, adds KEY->INCR.  if KEY->N is
     present in OLDAVL, changes it to KEY->N+INCR.
'avl_delete(+KEY, +OLDAVL, -VAL, -NEWAVL)'

     is true when OLDAVL and NEWAVL define the same finite function
     except that OLDAVL associates KEY with VAL and NEWAVL doesn't
     associate KEY with any value.
'avl_del_min(+OLDAVL, -KEY, -VAL, -NEWAVL)'

     is true when OLDAVL and NEWAVL define the same finite function
     except that OLDAVL associates KEY with VAL and NEWAVL doesn't
     associate KEY with any value and KEY precedes all other keys in
     OLDAVL.
'avl_del_max(+OLDAVL, -KEY, -VAL, -NEWAVL)'

     is true when OLDAVL and NEWAVL define the same finite function
     except that OLDAVL associates KEY with VAL and NEWAVL doesn't
     associate KEY with any value and KEY is preceded by all other keys
     in OLDAVL.
'avl_map(:PRED, +AVL)'

     is true when AVL is an association tree, and for each KEY, if KEY
     is associated with VALUE in AVL, PRED(VALUE) is true.
'avl_map(:PRED, +OLDAVL, -NEWAVL)'

     is true when OLDAVL and NEWAVL are association trees of the same
     shape, and for each KEY, if KEY is associated with OLD in OLDAVL
     and with NEW in NEWAVL, PRED(OLD,NEW) is true.


File: sicstus.info,  Node: lib-bags,  Next: lib-bdb,  Prev: lib-avl,  Up: The Prolog Library

10.5 Bags, or Multisets--'library(bags)'
========================================

This library module provides operations on bags.  Bags are also known as
multisets.  A bag B is a function from a set 'dom(B)' to the
non-negative integers.  For the purposes of this module, a bag is
constructed from two functions:

'bag'
     creates an empty bag
'bag(E,M,B)'
     extends the bag B with a _new_ element E which occurs with
     multiplicity M, and which precedes all elements of B in Prolog's
     order.

   A bag is represented by a Prolog term mirroring its construction.
There is one snag with this: what are we to make of
         bag(f(a,Y), 1, bag(f(X,b), 1, bag))     ?
   As a term it has two distinct elements, but 'f(a,b)' will be reported
as occurring in it twice.  But according to the definition above,
         bag(f(a,b), 1, bag(f(a,b), 1, bag))
   is not the representation of any bag, that bag is represented by
         bag(f(a,b), 2, bag)
   alone.  We are apparently stuck with a scheme which is only
guaranteed to work for "sufficiently instantiated" terms, but then,
that's true of a lot of Prolog code.

   The reason for insisting on the order is to make union and
intersection linear in the sizes of their arguments.  'library(ordsets)'
does the same for ordinary sets.

   Exported predicates:

'is_bag(+BAG)'

     recognises proper well-formed bags.  You can pass variables to
     'is_bag/1', and it will reject them.
'portray_bag(+BAG)'

     writes a bag to the current output stream in a pretty form so that
     you can easily see what it is.  Note that a bag written out this
     way can _not_ be read back in.  For that, use 'write_canonical/1'.
     The point of this predicate is to have bags displayed nicely by
     print/1 and the debugger.  This will print things which are not
     fully instantiated, which is mainly of interest for debugging this
     module.
'checkbag(:PRED, +BAG)'

     is true when BAG is a BAG{E1:M1, ..., EN:MN} with elements EI of
     multiplicity MI, and PRED(EI, MI) is true for each I.
'mapbag(:PRED, +BAG)'

     is true when BAG is a BAG{E1:M1, ..., EN:MN} with elements EI of
     multiplicity MI, and PRED(EI) is true for each element EI.  The
     multiplicities are ignored: if you don't want this, use
     'checkbag/2'.
'mapbag(:PRED, +OLDBAG, -NEWBAG)'

     is true when OLDBAG is a BAG{E1:M1, ..., EN:MN} and NEWBAG is a
     BAG{F1:M'1, ..., FN:M'N} and the elements of OLDBAG and NEWBAG are
     related by PRED(EI, FJ).  What happens is that the elements of
     OLDBAG are mapped, and then the result is converted to a bag, so
     there is no positional correspondence between EI and FJ.  Even when
     PRED is bidirectional, 'mapbag/3' is _not_.  OLDBAG should satisfy
     'is_bag/1' before 'mapbag/3' is called.
'somebag(:PRED, +BAG)'

     is true when BAG is a BAG{E1:M1, ..., EN:MN} with elements EI of
     multiplicity MI and PRED(EI, MI) is true of some element EI and its
     multiplicity.  There is no version which ignores the MI.
'somechkbag(:PRED, +BAG)'

     is like 'somebag(PRED, BAG)', but commits to the first solution it
     finds.  For example, if 'p(X,X,_)', 'somechk(p(X), BAG)' would be
     an analogue of 'memberchk/2' for bags.
'bag_to_list(+BAG, -LIST)'

     converts a BAG{E1:M1, ..., EN:MN} to a list where each element
     appears as many times as its multiplicity requires.  For example,
     'Bag{a:1, b:3, c:2}' would be converted to '[a,b,b,b,c,c]'.
'bag_to_ord_set(+BAG, -ORDSET)'

     converts a BAG{E1:M1, ..., EN:MN} to a list where each element
     appears once without its multiplicity.  The result is always an
     ordered (representation of a) set, suitable for processing by
     'library(ordsets)'.  See also 'bag_to_list/2'.
'bag_to_ord_set(+BAG, +THRESHOLD, -ORDSET)'

     given a BAG{E1:M1, ..., EN:MN} returns a list in standard order of
     the set of elements {EI | MI >= THRESHOLD}.  The result is an
     Ordset.
'list_to_bag(+LIST, -BAG)'

     converts a proper list LIST to a BAG representing the same
     multi-set.  Each element of the List appears once in the BAG
     together with the number of times it appears in the LIST.
'bag_to_set(+BAG, -SET)'

     converts a BAG{E1:M1, ..., EN:MN} to a list which represents the
     SET {E1, ..., EN}.  The order of elements in the result is not
     defined: for a version where the order is defined use
     'bag_to_ord_set/2'.
'bag_to_set(+BAG, +THRESHOLD, -SET)'

     given a BAG{E1:M1, ..., EN:MN} returns a list which represents the
     SET of elements {EI | MI >= THRESHOLD}.  Because the BAG is sorted,
     the result is necessarily an ordered set.
'empty_bag(?BAG)'

     is true when BAG is the representation of an empty bag.  It can be
     used both to make and to recognise empty bags.
'member(?ELEMENT, ?MULTIPLICITY, +BAG)'

     is true when ELEMENT appears in the multi-set represented by BAG
     with the indicated MULTIPLICITY.  BAG should be instantiated, but
     ELEMENT and MULTIPLICITY may severally be given or solved for.
'memberchk(+ELEMENT, ?MULTIPLICITY, +BAG)'

     is true when ELEMENT appears in the multi-set represented by BAG,
     with the indicated MULTIPLICITY.  It should only be used to check
     whether a given element occurs in the BAG, or whether there is an
     element with the given MULTIPLICITY.  Note that guessing the
     multiplicity and getting it wrong may force the wrong choice of
     clause, but the result will be correct if 'is_bag(BAG)'.
'bag_max(+BAG, -COMMONESTELEMENT)'

     unifies COMMONESTELEMENT with the element of BAG which occurs most
     often, picking the leftmost element if several have this
     multiplicity.  To find the multiplicity as well, use 'bag_max/3'.
     'bag_max/2' and 'bag_min/2' break ties the same way.
'bag_min(+BAG, -RARESTELEMENT)'

     unifies RARESTELEMENT with the element of BAG which occurs least
     often, picking the leftmost element if several have this
     multiplicity.  To find the multiplicity as well, use 'bag_min/3'.
     'bag_max/2' and 'bag_min/2' break ties the same way, so
              bag_max(Bag, Elt), bag_min(Bag, Elt)
     is true only when all the elements of BAG have the same
     multiplicity.
'bag_max(+BAG, -COMMONESTELEMENT, -MULTIPLICITY)'

     unifies COMMONESTELEMENT with the element of BAG which occurs most
     often, and MULTIPLICITY with the multiplicity of that element.  If
     there are several elements with the same greatest multiplicity, the
     left-most is returned.  'bag_min/3' breaks ties the same way.
'bag_min(+BAG, -RARESTELEMENT)'

     unifies RARESTELEMENT with the element of BAG which occurs least
     often, and MULTIPLICITY with the multiplicity of that element.  If
     there are several elements with the same least multiplicity, the
     left-most is returned.  'bag_max/3' breaks ties the same way, so
              bag_max(Bag, Elt, Mult), bag_min(Bag, Elt, Mult)
     is true only when all the elements of BAG have multiplicity MULT.
'length(+BAG, -BAGCARDINALITY, -SETCARDINALITY)'

     unifies BAGCARDINALITY with the total cardinality of the multi-set
     BAG (the sum of the multiplicities of its elements) and
     SETCARDINALITY with the number of distinct elements.
'make_sub_bag(+BAG, -SUBBAG)'

     enumerates the sub-bags of BAG, unifying SUBBAG with each of them
     in turn.  The order in which the sub-bags are generated is such
     that if SB2 is a sub-bag of SB1 which is a sub-bag of Bag, SB1 is
     generated before SB2.  In particular, Bag is enumerated first and
     bag last.
'test_sub_bag(+BAG, +SUBBAG)'

     is true when SUBBAG is (already) a sub-bag of BAG.  That is, each
     element of SubBag must occur in BAG with at least the same
     multiplicity.  If you know SUBBAG, you should use this to test, not
     'make_sub_bag/2'.
'bag_union(+BAG1, +BAG2, -UNION)'

     unifies UNION with the multi-set union of bags BAG1 and BAG2.
'bag_union(+LISTOFBAGS, -UNION)'

     is true when LISTOFBAGS is given as a proper list of bags and UNION
     is their multi-set union.  Letting K be the length of LISTOFBAGS,
     and N the sum of the sizes of its elements, the cost is O(N LG K).
'bag_intersection(+BAG1, +BAG2, -INTERSECTION)'

     unifies INTERSECTION with the multi-set intersection of bags BAG1
     and BAG2.
'bag_intersection(+LISTOFBAGS, -INTERSECTION)'

     is true when LISTOFBAGS is given as a non-empty proper list of Bags
     and INTERSECTION is their intersection.  The intersection of an
     empty list of Bags would be the universe with infinite
     multiplicities!
'bag_intersect(+BAG1, +BAG2)'

     is true when the multi-sets BAG1 and BAG2 have at least one element
     in common.
'bag_add_element(+BAG1, +ELEMENT, +MULTIPLICITY, -BAG2)'

     computes BAG2 = BAG1 U {ELEMENT:MULTIPLICITY}.  MULTIPLICITY must
     be an integer.
'bag_del_element(+BAG1, +ELEMENT, +MULTIPLICITY, -BAG2)'

     computes BAG2 = BAG1 \ {ELEMENT:MULTIPLICITY}.  MULTIPLICITY must
     be an integer.
'bag_subtract(+BAG1, +BAG2, -DIFFERENCE)'

     is true when DIFFERENCE is the multiset difference of BAG1 and
     BAG2.


File: sicstus.info,  Node: lib-bdb,  Next: lib-between,  Prev: lib-bags,  Up: The Prolog Library

10.6 External Storage of Terms (Berkeley DB)--'library(bdb)'
============================================================

This library module handles storage and retrieval of terms on files.  By
using indexing, the store/retrieve operations are efficient also for
large data sets.  The package is an interface to the Berkeley DB
toolset.

* Menu:

* BDB Basics:: Basics
* Current Limitations:: Current Limitations
* Berkeley DB:: Berkeley DB
* The DB-Spec Informal Description:: The DB-Spec--Informal Description
* Predicates:: Predicates
* An Example Session:: An Example Session
* The DB-Spec:: The DB-Spec
* Exporting and importing a database:: Exporting and importing a database


File: sicstus.info,  Node: BDB Basics,  Next: Current Limitations,  Up: lib-bdb

10.6.1 Basics
-------------

The idea is to get a behavior similar to 'assert/1', 'retract/1' and
'clause/2', but the terms are stored on files instead of in primary
memory.

   The differences compared with the Prolog database are:

   * A "database" must be opened before any access and closed after the
     last access.  (There are special predicates for this:
     'db_open/[4,5]' and 'db_close/1'.)

   * The functors and the indexing specifications of the terms to be
     stored have to be given when the database is created.  (*note The
     DB-Spec::).

   * The indexing is specified when the database is created.  It is
     possible to index on other parts of the term than just the functor
     and first argument.

   * Changes affect the database immediately.

   * The database will store variables with attributes or with blocked
     goals as ordinary variables.

   Some commercial databases can't store non-ground terms or more than
one instance of a term.  This library module can however store terms of
either kind.


File: sicstus.info,  Node: Current Limitations,  Next: Berkeley DB,  Prev: BDB Basics,  Up: lib-bdb

10.6.2 Current Limitations
--------------------------

   * The terms are not necessarily fetched in the same order as they
     were stored.

   * If the process dies during an update operation ('db_store/3',
     'db_erase/[2,3]'), the database can be inconsistent.

   * Databases can only be shared between processes running on the
     machine where the environment is created (*note Predicates::).  The
     database itself can be on a different machine.

   * The number of terms ever inserted in a database cannot exceed
     2^32-1.

   * Duplicate keys are not handled efficiently by Berkeley DB. This
     limitation is supposed to get lifted in the future.  Duplicate keys
     can result from indexing on non-key attribute sets, inserting terms
     with variables on indexing positions, or simply from storing the
     same term more than once.


File: sicstus.info,  Node: Berkeley DB,  Next: The DB-Spec Informal Description,  Prev: Current Limitations,  Up: lib-bdb

10.6.3 Berkeley DB
------------------

This library module is an interface to the Berkeley DB toolset to
support persistent storage of Prolog terms.  Some of the notions of
Berkeley DB are directly inherited, e.g. the environment.

   The interface uses the Concurrent Access Methods product of Berkeley
DB. This means that multiple processes can open the same database, but
transactions and disaster recovery are not supported.

   The environment and the database files are ordinary Berkeley DB
entities which means that the standard support utilities (e.g.
'db_stat') will work.


File: sicstus.info,  Node: The DB-Spec Informal Description,  Next: Predicates,  Prev: Berkeley DB,  Up: lib-bdb

10.6.4 The DB-Spec--Informal Description
----------------------------------------

The "db-spec" defines which functors are allowed and which parts of a
term are used for indexing in a database.  The syntax of a db-spec is a
skeletal goal with no module.  The db-spec is a list of atoms and
compound terms where the arguments are either '+' or '-'.  A term can be
inserted in the database if there is a spec in the spec list with the
same functor.

   Multilevel indexing is not supported, terms have to be "flattened".

   Every spec with the functor of the "indexed term" specifies an
indexing.  Every argument where there is a '+' in the spec is indexed
on.

   The idea of the db-spec is illustrated with a few examples.  (A
section further down explains the db-spec in a more formal way).

   Given a spec of '[f(+,-), .(+,-), g, f(-,+)]' the indexing works as
follows.  (The parts with indexing are underlined.)

TERM        STORE                            FETCH
'g(x,y)'    domain error                     domain error
'f(A,B)'    'f(A,B)'                         instantiation error
            '-'
'f(a,b)'    'f(a,b) f(a,b)'                  'f(a,b)'
            '- - - -'                        '- -'
'[a,b]'     '.(a,.(b,[]))'                   '.(a,.(b,[]))'
            '- -'                            '- -'
'g'         'g'                              'g'
            '-'                              '-'

   The specification '[f(+,-), f(-,+)]' is different from '[f(+,+)]'.
The first specifies that two indices are to be made whereas the second
specifies that only one index is to be made on both arguments of the
term.


File: sicstus.info,  Node: Predicates,  Next: An Example Session,  Prev: The DB-Spec Informal Description,  Up: lib-bdb

10.6.5 Predicates
-----------------

* Menu:

* Conventions:: Conventions
* The Environment:: The Environment
* Memory Leaks:: Memory Leaks
* The Predicates:: The Predicates


File: sicstus.info,  Node: Conventions,  Next: The Environment,  Up: Predicates

10.6.5.1 Conventions
....................

The following conventions are used in the predicate descriptions below.
   * MODE is either 'update' or 'read' or 'enumerate'.  In mode 'read'
     no updates can be made.  Mode 'enumerate' is like mode 'read', but
     indexing cannot be used, i.e. you can only sequentially enumerate
     the items in the database.  In mode 'enumerate' only the file
     storing the terms along with their references is used.

   * ENVREF is a reference to an open database environment.  The
     environment is returned when it is opened.  The reference becomes
     invalid after the environment has been closed.

   * DBREF is a reference to an open database.  The reference is
     returned when the database is opened.  The reference becomes
     invalid after the database has been closed.

   * TERMREF is a reference to a term in a given database.  The
     reference is returned when a term is stored.  The reference stays
     valid even after the database has been closed and hence can be
     stored permanently as part of another term.  However, if such
     references are stored in the database, automatic compression of the
     database (using 'db_compress/[2,3]') is not possible, in that case
     the user has to write her own compressing predicate.

   * SPECLIST is a description of the indexing scheme; *note The
     DB-Spec::.

   * TERM is any Prolog term.

   * ITERATOR is a non-backtrackable mutable object.  It can be used to
     iterate through a set of terms stored in a database.  The iterators
     are unidirectional.


File: sicstus.info,  Node: The Environment,  Next: Memory Leaks,  Prev: Conventions,  Up: Predicates

10.6.5.2 The Environment
........................

To enable sharing of databases between process, programs have to create
"environments" and the databases should be opened in these environments.
A database can be shared between processes that open it in the same
environment.  An environment physically consists of a directory
containing the files needed to enable sharing databases between
processes.  The directory of the environment has to be located in a
local file system.

   Databases can be opened outside any environment (see 'db_open/4'),
but in that case a process writing the database must ensure exclusive
access or the behavior of the predicates is undefined.


File: sicstus.info,  Node: Memory Leaks,  Next: The Predicates,  Prev: The Environment,  Up: Predicates

10.6.5.3 Memory Leaks
.....................

In order to avoid memory leaks, environments, databases and iterators
should always be closed explicitly.  Consider using 'call_cleanup/2' to
automate the closing/deallocation of these objects.  You can always use
'db_current_env/1', 'db_current/5' and 'db_current_iterator/3' to
enumerate the currently living objects.

     *Please note*: a database must not be closed while there are
     outstanding choices for some 'db_fetch/3' goal that refers to that
     database.  Outstanding choices can be removed with a cut ('!').


File: sicstus.info,  Node: The Predicates,  Prev: Memory Leaks,  Up: Predicates

10.6.5.4 The Predicates
.......................

'db_open_env(+ENVNAME, -ENVREF)'
'db_open_env(+ENVNAME, +CACHESIZE, -ENVREF)'

     Opens an environment with the name ENVNAME.  A directory with this
     name is created for the environment if necessary.

     By using 'db_open_env/3' one can specify the size of the cache:
     CACHESIZE is the (integer) size of the cache in kilobytes.  The
     size of the cache cannot be less than 20 kilobytes.
     'db_open_env/2' will create a cache of the system's default size.

     The size of the cache is determined when the environment is created
     and cannot be changed by future openings.

     A process cannot open the same environment more than once.
'db_close_env(+ENVREF)'

     Closes an environment.  All databases opened in the environment
     will be closed as well.
'db_current_env(?ENVNAME, ?ENVREF)'

     Unifies the arguments with the open environments.  This predicate
     can be used for enumerating all currently open environments through
     backtracking.
'db_open(+DBNAME, +MODE, ?SPECLIST, -DBREF)'
'db_open(+DBNAME, +MODE, ?SPECLIST, +OPTIONS, -DBREF)'

     Opens a database with the name DBNAME.  The database physically
     consists of a directory with the same name, containing the files
     that make up the database.  If the directory does not exist, it is
     created.  In that case MODE must be 'update' and the db-spec
     SPECLIST must be ground.  If an existing database is opened and
     MODE is 'read' or 'update', SPECLIST is unified with the db-spec
     given when the database was created.  If the unification fails an
     error is raised.  DBREF is unified with a reference to the opened
     database.

     If MODE is 'enumerate' then the indexing specification is not read,
     and SPECLIST is left unbound.

     OPTIONS provides a way to specify an environment in which to open
     the database, or a cache size.  OPTIONS should be a list of terms
     of the following form:

     'environment(ENVREF)'
          The database will be opened in this environment.

     'cache_size(CACHESIZE)'
          This is the (integer) size of the cache in kilobytes.  The
          size of the cache cannot be less than 20 kilobytes.  If
          CACHESIZE is given as the atom 'default', a default cache size
          will be used.  If CACHESIZE is given as the atom 'off' or the
          atom 'none', all modified records will be flushed to disk
          after each operation.

     To avoid inconsistency, if multiple processes open the same
     database, then all of them should do that with MODE set to 'read'
     or 'enumerate'.  (This is not enforced by the system.)
'db_close(+DBREF)'

     Closes the database referenced by DBREF.  Any iterators opened in
     the database will be deallocated.
'db_current(?DBNAME, ?MODE, ?SPECLIST, ?ENVREF, ?DBREF)'

     Unifies the arguments with the open databases.  This predicate can
     be used to enumerate all currently open databases through
     backtracking.  If the database was opened without an environment,
     then ENVREF will be unified with the atom 'none'.
'db_store(+DBREF, +TERM, -TERMREF)'

     Stores TERM in the database DBREF.  TERMREF is unified with a
     corresponding term reference.  The functor of TERM must match the
     functor of a spec in the db-spec associated with DBREF.
'db_fetch(+DBREF, ?TERM, ?TERMREF)'

     Unifies TERM with a term from the database DBREF.  At the same
     time, TERMREF is unified with a corresponding term reference.
     Backtracking over the predicate unifies with all terms matching
     TERM.

     If TERMREF is not instantiated then both the functor and the
     instantiatedness of TERM must match a spec in the db-spec
     associated with DBREF.

     If TERMREF is instantiated, the referenced term is read and unified
     with TERM.

     If you simply want to find all matching terms, it is more efficient
     to use 'db_findall/5' or 'db_enumerate/3'.
'db_erase(+DBREF, +TERMREF)'
'db_erase(+DBREF, +TERMREF, +TERM)'

     Deletes the term from the database DBREF that is referenced by
     TERMREF.

     In the case of 'db_erase/2' the term associated with TERMREF has to
     be looked up.  'db_erase/3' assumes that the term TERM is identical
     with the term associated with TERMREF (modulo variable renaming).
     If this is not the case, the behavior is undefined.
'db_enumerate(+DBREF, ?TERM, ?TERMREF)'

     Unifies TERM with a term from the database DBREF.  At the same
     time, TERMREF is unified with a corresponding term reference.
     Backtracking over the predicate unifies with all terms matching
     TERM.

     Implemented by linear search--the db-spec associated with DBREF is
     ignored.  It is not useful to call this predicate with TERMREF
     instantiated.
'db_findall(+DBREF, +TEMPLATE, +TERM, :GOAL, -BAG)'

     Unifies BAG with the list of instances of TEMPLATE in all proofs of
     GOAL found when TERM is unified with a matching term from the
     database DBREF.  Both the functor and the instantiatedness of TERM
     must match a spec in the db-spec associated with DBREF.
     Conceptually, this predicate is equivalent to 'findall(TEMPLATE,
     (db_fetch(DBREF, TERM, _), GOAL), BAG)'.
'db_compress(+DBREF, +DBNAME)'
'db_compress(+DBREF, +DBNAME, +SPECLIST)'

     Copies the database given by DBREF to a new database named by
     DBNAME.  The new database will be a compressed version of the first
     one in the sense that it will not have "holes" resulting from
     deletion of terms.  Deleted term references will also be reused,
     which implies that references that refer to terms in the old
     database will be invalid in the new one.

     'db_compress/2' looks for a database with the db-spec of the
     original one.  'db_compress/3' stores the terms found in the
     original database with the indexing specification SPECLIST.
     'db_compress/2' cannot be used if the database DBREF was opened in
     mode 'enumerate'.

     If the database DBNAME already exists then the terms of DBREF will
     be appended to it.  Of course DBNAME must have an indexing
     specification, which enables the terms in DBREF to be inserted into
     it.

     In the case of 'db_compress/3' if the database DBNAME does not
     exist, then SPECLIST must be a valid indexing specification.
'db_sync(+DBREF)'

     Flushes any cached information from the database referenced by
     DBREF to stable storage.
'db_make_iterator(+DBREF, -ITERATOR)'
'db_make_iterator(+DBREF, +TERM, -ITERATOR)'

     Creates a new iterator and unifies it with ITERATOR.  Iterators
     created with 'db_make_iterator/2' iterate through the whole
     database.  Iterators created with 'db_make_iterator/3' iterate
     through the terms that would be found by 'db_fetch(DBREF, TERM,
     _)'.

     Every iterator created by 'db_make_iterator/[2,3]' must be
     destroyed with 'db_iterator_done/1'.
'db_iterator_next(+ITERATOR, -TERM, -TERMREF)'

     ITERATOR advances to the next term, TERM and TERMREF is unified
     with the term and its reference pointed to by ITERATOR.  If there
     is no next term, the predicate fails.
'db_iterator_done(+ITERATOR)'

     Deallocates ITERATOR, which must not be in use anymore.
'db_current_iterator(?DBREF, ?TERM, ?ITERATOR)'

     Unifies the variables with the respective properties of the living
     iterators.  This predicate can be used to enumerate all currently
     alive iterators through backtracking.  If ITERATOR was made with
     'db_make_iterator/2' then TERM will be left unbound.
'db_export(+DBNAME, +EXPORTFILE)'
'db_export(+DBNAME, +OPTIONS, +EXPORTFILE)'

     Exports the database with the name DBNAME to the text file
     EXPORTFILE.  EXPORTFILE can be imported by 'db_import/[2,3]'.

     OPTIONS should be an options list of the form acceptable by
     'db_open/[4,5]'.

     In SICStus 3.12.0 'bdb:export/[2,3]' is available instead of
     'db_export/[2,3]'.
'db_import(+DBNAME, +IMPORTFILE)'
'db_import(+DBNAME, +OPTIONS, +IMPORTFILE)'

     Imports the text file IMPORTFILE into the database with the name
     DBNAME.

     If IMPORTFILE is imported into an existing database, the SPECLIST
     found in the IMPORTFILE will be unified with the SPECLIST in the
     database.

     OPTIONS should be an options list of the form acceptable by
     'db_open/[4,5]'.

     In SICStus 3.12.0 'bdb:import/[2,3]' is available instead of
     'db_import/[2,3]'.


File: sicstus.info,  Node: An Example Session,  Next: The DB-Spec,  Prev: Predicates,  Up: lib-bdb

10.6.6 An Example Session
-------------------------

     | ?- db_open(tempdb, update, [a(+,-)], DBRef), assert(tempdb(DBRef)).
     DBRef = '$db'(1077241400)

     | ?- tempdb(DBRef), db_store(DBRef, a(b,1), _).
     DBRef = '$db'(1077241400)

     | ?- tempdb(DBRef), db_store(DBRef, a(c,2), _).
     DBRef = '$db'(1077241400)

     | ?- tempdb(DBRef), db_fetch(DBRef, a(b,X), _).
     X = 1,
     DBRef = '$db'(1077241400) ? ;
     no

     | ?- tempdb(DBRef), db_enumerate(DBRef, X, _).
     X = a(b,1),
     DBRef = '$db'(1077241400) ? ;
     X = a(c,2),
     DBRef = '$db'(1077241400) ? ;
     no

     | ?- db_current(DBName, Mode, Spec, EnvRef, DBRef).
     Mode = update,
     Spec = [a(+,-)],
     DBRef = '$db'(1077241400),
     DBName = tempdb,
     EnvRef = none ? ;
     no

     | ?- tempdb(DBRef), db_close(DBRef).
     DBRef = '$db'(1077241400)


File: sicstus.info,  Node: The DB-Spec,  Next: Exporting and importing a database,  Prev: An Example Session,  Up: lib-bdb

10.6.7 The DB-Spec
------------------

A db-spec has the form of a SPECLIST:

SPECLIST
     = '['SPEC1, ..., SPECM']'

SPEC
     = FUNCTOR'('ARGSPEC1, ..., ARGSPECN')'

ARGSPEC
     = '+' | '-'
   where FUNCTOR is a Prolog atom.  The case N = 0 is allowed.

   A spec F'('ARGSPEC1, ..., ARGSPECN')' is _applicable_ to any nonvar
term with principal functor F/N.

   When storing a term T we generate a hash code for every applicable
spec in the db-spec, and a reference to T is stored with each of them.
(More precisely with each element of the set of generated hash codes).
If T contains nonvar elements on each '+' position in the spec, then the
hash code depends on each of these elements.  If T does contain some
variables on '+' position, then the hash code depends only on the
functor of T.

   When fetching a term Q we look for an applicable spec for which there
are no variables in Q on positions maked '+'.  If no applicable spec can
be found a domain error is raised.  If no spec can be found where on
each '+' position a nonvar term occurs in Q an instantiation error is
raised.  Otherwise, we choose the spec with the most '+' postitions in
it breaking ties by choosing the leftmost one.

   The terms that contain nonvar terms on every '+' postition will be
looked up using indexing based on the principal functor of the term and
the principal functor of terms on '+' postitions.  The other (more
general) terms will be looked up using an indexing based on the
principal functor of the term only.

   As can be seen, storing and fetching terms with variables on '+'
positions are not vigorously supported operations.


File: sicstus.info,  Node: Exporting and importing a database,  Prev: The DB-Spec,  Up: lib-bdb

10.6.8 Exporting and importing a database
-----------------------------------------

Since the database format of a Berkeley DB may change from version to
version it may become necessary to migrate a database when upgrading.
To this purpose there are two predicates available: 'db_export/[2,3]'
and 'db_import/[2,3]' (*note The Predicates::).

   The export/import feature was introduced in SICStus 3.12.0, but in
that version you have to use 'bdb:export/[2,3]' and 'bdb:import/[2,3]'.
Neither is exported from the bdb module, but can be used with module
prefixing.

   Since the bdb interface prior to SICStus 4 uses a custom hash
function, the standard Berkeley DB migration tools will not work when
migrating a database from SICStus 3 to SICStus 4.


File: sicstus.info,  Node: lib-between,  Next: lib-chr,  Prev: lib-bdb,  Up: The Prolog Library

10.7 Generating Integers--'library(between)'
============================================

This library module provides some means of generating integers.
Exported predicates:

'between(+LOWER, +UPPER, -NUMBER)'

     is true when LOWER, UPPER, and NUMBER are integers, and LOWER =<
     NUMBER =< UPPER.  If LOWER and UPPER are given, NUMBER can be
     tested or enumerated.  If either LOWER or UPPER is absent, there is
     not enough information to find it, and an error will be reported.
'gen_nat(?N)'

     is true when N is a natural number.  If N is a variable, it will
     enumerate the natural numbers 0,1,2,...  and of course not
     terminate.  It is not meant to be applied to anything but integers
     and variables.
'gen_int(?I)'

     is true when I is an integer.  If I is a variable, it will
     enumerate the integers in the order 0, 1, -1, 2, -2, 3, -3, &c.  Of
     course this sequence has no end.  It is not meant to be applied to
     anything but integers and variables.
'repeat(+N)'

     (where N is a non-negative integer) succeeds exactly N times.  You
     can only understand it procedurally, and really it is only included
     for compatibility with some other Prologs.
'numlist(?UPPER, ?LIST)'

     is true when LIST is the list of integers [1, ..., UPPER].  For
     example, 'numlist(3,L)' binds 'L = [1,2,3]'.
'numlist(?LOWER, ?UPPER, ?LIST)'
     is true when LIST is [LOWER, ..., UPPER], LOWER and UPPER integers.
     For example, 'numlist(1, 3, L)' binds 'L = [1,2,3]'.
'numlist(?LOWER, ?STEP, ?UPPER, ?LENGTH, ?LIST)'
     is true when LIST is the list of integers [LOWER, LOWER+STEP, ...,
     UPPER] and of length LENGTH.  For example,
     'numlist(L,2,U,S,[1,X,Y,Z])' binds 'L=1, S=4, U=7, X=3, U=5, Z=7'.


File: sicstus.info,  Node: lib-chr,  Next: lib-clpb,  Prev: lib-between,  Up: The Prolog Library

10.8 Constraint Handling Rules--'library(chr)'
==============================================

This section is written by Tom Schrijvers, K.U. Leuven, and adjustments
by Jan Wielemaker.

   The CHR system of SICStus Prolog is the K.U.Leuven CHR system.  The
runtime environment is written by Christian Holzbaur and Tom Schrijvers
while the compiler is written by Tom Schrijvers.  Both are integrated
with SICStus Prolog and licensed under compatible conditions with
permission from the authors.

   The main reference for the CHR system is [Schrijvers & Demoen 04].

* Menu:

* CHR Introduction::            
* CHR Syntax and Semantics::    
* CHR in Prolog Programs::      
* CHR Debugging::               
* CHR Examples::                
* CHR Guidelines::              


File: sicstus.info,  Node: CHR Introduction,  Next: CHR Syntax and Semantics,  Up: lib-chr

10.8.1 Introduction
-------------------

Constraint Handling Rules (CHR) is a committed-choice rule-based
language embedded in Prolog.  It is designed for writing constraint
solvers and is particularly useful for providing application-specific
constraints.  It has been used in many kinds of applications, like
scheduling, model checking, abduction, type checking among many others.

   CHR has previously been implemented in other Prolog systems (SICStus,
Eclipse, Yap), Haskell and Java.  This CHR system is based on the
compilation scheme and runtime environment of CHR in SICStus.

   In this documentation we restrict ourselves to giving a short
overview of CHR in general and mainly focus on elements specific to this
implementation.  For a more thorough review of CHR we refer the reader
to [Fruehwirth 98].

   In *note CHR Syntax and Semantics:: we present the syntax of CHR in
Prolog and explain informally its operational semantics.  Next, *note
CHR in Prolog Programs:: deals with practical issues of writing and
compiling Prolog programs containing CHR. *note CHR Debugging:: explains
the currently primitive CHR debugging facilities.  *note CHR Debugging
Predicates:: provides a few useful predicates to inspect the constraint
store and *note CHR Examples:: illustrates CHR with two example
programs.  Finally, *note CHR Guidelines:: concludes with a few
practical guidelines for using CHR.


File: sicstus.info,  Node: CHR Syntax and Semantics,  Next: CHR in Prolog Programs,  Prev: CHR Introduction,  Up: lib-chr

10.8.2 Syntax and Semantics
---------------------------

* Menu:

* CHR Syntax::                  
* CHR Semantics::               


File: sicstus.info,  Node: CHR Syntax,  Next: CHR Semantics,  Up: CHR Syntax and Semantics

10.8.2.1 Syntax
...............

The syntax of CHR rules is the following:

RULES          ::= RULE RULES
RULES          ::= EMPTY
RULE           ::= NAME ACTUAL_RULE PRAGMA '.'
NAME           ::= ATOM '@'
NAME           ::= EMPTY
ACTUAL_RULE    ::= SIMPLIFICATION_RULE
ACTUAL_RULE    ::= PROPAGATION_RULE
ACTUAL_RULE    ::= SIMPAGATION_RULE
SIMPLIFICATION_RULE::= HEAD '<=>' GUARD BODY
PROPAGATION_RULE::= HEAD '==>' GUARD BODY
SIMPAGATION_RULE::= HEAD '\' HEAD '<=>' GUARD BODY
HEAD           ::= CONSTRAINTS
CONSTRAINTS    ::= CONSTRAINT CONSTRAINT_ID
CONSTRAINTS    ::= CONSTRAINT CONSTRAINT_ID ',' CONSTRAINTS
CONSTRAINT     ::= COMPOUND_TERM
CONSTRAINT_ID  ::= EMPTY
CONSTRAINT_ID  ::= '#' VARIABLE
GUARD          ::= EMPTY
GUARD          ::= GOAL DISJ
BODY           ::= GOAL
PRAGMA         ::= EMPTY
PRAGMA         ::= 'pragma' ACTUAL_PRAGMAS
ACTUAL_PRAGMAS ::= ACTUAL_PRAGMA
ACTUAL_PRAGMAS ::= ACTUAL_PRAGMA ',' ACTUAL_PRAGMAS
ACTUAL_PRAGMA  ::= 'passive(VARIABLE)'
DISJ           ::= ';' | '|' { read as ';' unless '|' is declared infix
               }

   Note that the guard of a rule may not contain any goal that binds a
variable in the head of the rule with a non-variable or with another
variable in the head of the rule.  It may however bind variables that do
not appear in the head of the rule, e.g. an auxiliary variable
introduced in the guard.

   Note also that, unless '|' has been declared as an operator, '|' and
';' are indistinguishable as infix operators--both are read as ';'
(*note ref-syn-syn-sen::).  So if e.g. a simplification rule is given
as:

     HEAD '<=>' '(P ; Q)'
then CHR will break the ambiguity by treating P as the guard and Q as
the body, which is probably not what you want.  To get the intended
interpretation, you must supply a dummy guard 'true |':

     HEAD '<=>' 'true | (P ; Q)'

   *Please note*: the above is true as long as you do not declare '|' as
an infix operator, which is possible since release 4.3 for ISO
compliance.  Declaring '|' as an infix operator will confuse CHR.


File: sicstus.info,  Node: CHR Semantics,  Prev: CHR Syntax,  Up: CHR Syntax and Semantics

10.8.2.2 Semantics
..................

In this subsubsection the operational semantics of CHR in Prolog are
presented informally.  They do not differ essentially from other CHR
systems.

   When a constraint is called, it is considered an active constraint
and the system will try to apply the rules to it.  Rules are tried and
executed sequentially in the order they are written.

   A rule is conceptually tried for an active constraint in the
following way.  The active constraint is matched with a constraint in
the head of the rule.  If more constraints appear in the head, then they
are looked for among the suspended constraints, which are called passive
constraints in this context.  If the necessary passive constraints can
be found and all match with the head of the rule and the guard of the
rule succeeds, then the rule is committed and the body of the rule
executed.  If not all the necessary passive constraint can be found,
then the matching fails or the guard fails, the body is not executed and
the process of trying and executing simply continues with the following
rules.  If for a rule, there are multiple constraints in the head, then
the active constraint will try the rule sequentially multiple times,
each time trying to match with another constraint.

   This process ends either when the active constraint disappears, i.e.
it is removed by some rule, or after the last rule has been processed.
In the latter case the active constraint becomes suspended.

   A suspended constraint is eligible as a passive constraint for an
active constraint.  The other way it may interact again with the rules,
is when a variable appearing in the constraint becomes bound to either a
non-variable or another variable involved in one or more constraints.
In that case the constraint is triggered, i.e. it becomes an active
constraint and all the rules are tried.

   Rule Types.  There are three different kinds of rules, each with
their specific semantics:

"simplification"
     The simplification rule removes the constraints in its head and
     calls its body.

"propagation"
     The propagation rule calls its body exactly once for the
     constraints in its head.

"simpagation"
     The simpagation rule removes the constraints in its head after the
     '\' and then calls its body.  It is an optimization of
     simplification rules of the form:

          CONSTRAINTS_1, CONSTRAINTS_2 <=> CONSTRAINTS_1, BODY

     namely, in the simpagation form:

          CONSTRAINTS_1 \ CONSTRAINTS_2 <=> BODY

     the CONSTRAINTS_1 constraints are not called in the body.

   Rule Names.  Naming a rule is optional and has no semantical meaning.
It only functions as documentation for the programmer.

   Pragmas.  The semantics of the pragmas are:

'passive(IDENTIFIER)'
     The constraint in the head of a rule IDENTIFIER can only match a
     passive constraint in that rule.

   Additional pragmas may be released in the future.

   Options.

   It is possible to specify options that apply to all the CHR rules in
the module.  Options are specified with the 'chr_option/2' declaration:

     :- chr_option(Option,Value).

and may appear in the file anywhere after the first constraints
declaration.

   Available options are:
'check_guard_bindings'
     This option controls whether guards should be checked for (illegal)
     variable bindings or not.  Possible values for this option are
     'on', to enable the checks, and 'off', to disable the checks.  If
     this option is on, then any guard fails when it binds a variable
     that appears in the head of the rule.  When the option is off, the
     behavior of a binding in the guard is undefined.

'optimize'
     This option controls the degree of optimization.  Possible values
     are 'full', to enable all available optimizations, and 'off' (the
     default), to disable all optimizations.  If optimization is
     enabled, then debugging must be disabled.

'debug'
     This options enables or disables the possibility to debug the CHR
     code.  Possible values are 'on' (the default) and 'off'.  See *note
     CHR Debugging:: for more details on debugging.


File: sicstus.info,  Node: CHR in Prolog Programs,  Next: CHR Debugging,  Prev: CHR Syntax and Semantics,  Up: lib-chr

10.8.3 CHR in Prolog Programs
-----------------------------

* Menu:

* CHR Embedding in Prolog Programs::  
* CHR Constraint Declaration::  
* CHR Compilation::             


File: sicstus.info,  Node: CHR Embedding in Prolog Programs,  Next: CHR Constraint Declaration,  Up: CHR in Prolog Programs

10.8.3.1 Embedding in Prolog Programs
.....................................

The CHR constraints defined in a '.pl' file are associated with a
module.  The default module is 'user'.  One should never load different
'.pl' files with the same CHR module name.


File: sicstus.info,  Node: CHR Constraint Declaration,  Next: CHR Compilation,  Prev: CHR Embedding in Prolog Programs,  Up: CHR in Prolog Programs

10.8.3.2 Constraint Declaration
...............................

Every constraint used in CHR rules has to be declared with a
'chr_constraint/1' declaration by the "constraint specifier".  For
convenience multiple constraints may be declared at once with the same
'chr_constraint/1' declaration followed by a comma-separated list of
constraint specifiers.

   A constraint specifier is, in its compact form, F/A where F and A are
respectively the functor name and arity of the constraint, e.g.

     :- chr_constraint foo/1.
     :- chr_constraint bar/2, baz/3.

   In its extended form, a constraint specifier is 'C(A_1,...,A_N)'
where C is the constraint's functor, N its arity and the A_I are
argument specifiers.  An argument specifier is a mode, optionally
followed by a type.  E.g.

     :- chr_constraint get_value(+,?).
     :- chr_constraint domain(?int,+list(int)),
                        alldifferent(?list(int)).

   A mode is one of the following:

'-'
     The corresponding argument of every occurrence of the constraint is
     always unbound.

'+'
     The corresponding argument of every occurrence of the constraint is
     always ground.

'?'
     The corresponding argument of every occurrence of the constraint
     can have any instantiation, which may change over time.  This is
     the default value.

   A type can be a user-defined type or one of the built-in types.  A
type comprises a (possibly infinite) set of values.  The type
declaration for a constraint argument means that for every instance of
that constraint the corresponding argument is only ever bound to values
in that set.  It does not state that the argument necessarily has to be
bound to a value.

   The built-in types are:

'int'
     The corresponding argument of every occurrence of the constraint is
     an integer.

'float'
     ... a floating point number.

'number'
     ... a number.

'natural'
     ... a positive integer.

'any'
     The corresponding argument of every occurrence of the constraint
     can have any type.  This is the default value.

   User-defined types are algebraic data types, similar to those in
Haskell or the discriminated unions in Mercury.  An algebraic data type
is defined using

     :- chr_type TYPE ---> BODY.

   If the type term is a functor of arity zero (i.e. one having zero
arguments), then it names a "monomorphic" type.  Otherwise, it names a
"polymorphic" type; the arguments of the functor must be distinct type
variables.  The body term is defined as a sequence of constructor
definitions separated by semi-colons.

   Each constructor definition must be a functor whose arguments (if
any) are types.  Discriminated union definitions must be transparent:
all type variables occurring in the body must also occur in the type.

   Here are some examples of algebraic data type definitions:

     :- chr_type color ---> red ; blue ; yellow ; green.
     :- chr_type tree --->  empty ; leaf(int) ; branch(tree, tree).
     :- chr_type list(T) --->    [] ; [T | list(T)].
     :- chr_type pair(T1, T2) ---> (T1 - T2).

   Each algebraic data type definition introduces a distinct type.  Two
algebraic data types that have the same bodies are considered to be
distinct types (name equivalence).

   Constructors may be overloaded among different types: there may be
any number of constructors with a given name and arity, so long as they
all have different types.

   Aliases can be defined using '=='.  For example, if your program uses
lists of lists of integers, then you can define an alias as follows:

     :- chr_type lli == list(list(int)).


File: sicstus.info,  Node: CHR Compilation,  Prev: CHR Constraint Declaration,  Up: CHR in Prolog Programs

10.8.3.3 Compilation
....................

The Prolog CHR compiler exploits 'user:term_expansion/6' rules to
translate the constraint handling rules to plain Prolog.  These rules
are loaded from 'library(chr)'.  They are activated after finding a
declaration of the format:

     :- chr_constraint ...

   It is advised to define CHR rules in a module-file, where the module
declaration is immediately followed by loading 'library(chr)' as
exemplified below:

     :- module(zebra, [ zebra/0 ]).
     :- use_module(library(chr)).

     :- chr_constraint ...


File: sicstus.info,  Node: CHR Debugging,  Next: CHR Examples,  Prev: CHR in Prolog Programs,  Up: lib-chr

10.8.4 Debugging
----------------

The CHR debugging facilities are currently rather limited.  Only tracing
is currently available.  To use the CHR debugging facilities for a CHR
file it must be compiled for debugging.  Generating debug info is
controlled by the CHR option 'debug', whose default is derived from the
CHR flag 'generate_debug_info'.

* Menu:

* CHR Ports::                   
* CHR Tracing::                 
* CHR Debugging Predicates::    


File: sicstus.info,  Node: CHR Ports,  Next: CHR Tracing,  Up: CHR Debugging

10.8.4.1 Ports
..............

For CHR constraints the four standard ports are defined:

'call'
     A new constraint is called and becomes active.

'exit'
     An active constraint exits: it has either been inserted in the
     store after trying all rules or has been removed from the
     constraint store.

'fail'
     An active constraint fails.

'redo'
     An active constraint starts looking for an alternative solution.

   In addition to the above ports, CHR constraints have five additional
ports:

'wake'
     A suspended constraint is woken and becomes active.

'insert'
     An active constraint has tried all rules and is suspended in the
     constraint store.

'remove'
     An active or passive constraint is removed from the constraint
     store.

'try'
     An active constraints tries a rule with possibly some passive
     constraints.  The try port is entered just before committing to the
     rule.

'apply'
     An active constraints commits to a rule with possibly some passive
     constraints.  The apply port is entered just after committing to
     the rule.


File: sicstus.info,  Node: CHR Tracing,  Next: CHR Debugging Predicates,  Prev: CHR Ports,  Up: CHR Debugging

10.8.4.2 Tracing
................

Tracing is enabled with the 'chr_trace/0' predicate and disabled with
the 'chr_notrace/0' predicate.

   When enabled, the tracer will step through the 'call', 'exit',
'fail', 'wake' and 'apply' ports, accepting debug commands, and simply
write out the other ports.

   The following debug commands are currently supported:

     CHR debug options:

             <cr>    creep           c       creep
             s       skip
             g       ancestors
             n       nodebug
             b       break
             a       abort
             f       fail
             ?       help            h       help

   Their meaning is:

'creep'
     Step to the next port.

'skip'
     Skip to exit port of this call or wake port.

'ancestors'
     Print list of ancestor call and wake ports.

'nodebug'
     Disable the tracer.

'break'
     Enter a recursive Prolog toplevel.  See 'break/0'.

'abort'
     Exit to the toplevel.  See 'abort/0'.

'fail'
     Insert failure in execution.

'help'
     Print the above available debug options.


File: sicstus.info,  Node: CHR Debugging Predicates,  Prev: CHR Tracing,  Up: CHR Debugging

10.8.4.3 Debugging Predicates
.............................

The 'chr' module exports several predicates that allow inspecting and
printing the content of the constraint store.

'chr_trace/0'

     Activate the CHR tracer.  By default the CHR tracer is activated
     and deactivated automatically by the Prolog predicates 'trace/0'
     and 'notrace/0'.

'chr_notrace/0'

     De-activate the CHR tracer.  By default the CHR tracer is activated
     and deactivated automatically by the Prolog predicates 'trace/0'
     and 'notrace/0'.

'chr_leash(+SPEC)'

     Define the set of CHR ports on which the CHR tracer asks for user
     intervention (i.e. stops).  SPEC is either a list of ports as
     defined in *note CHR Ports:: or a predefined alias.  Defined
     aliases are: 'full' to stop at all ports, 'none' or 'off' to never
     stop, and 'default' to stop at the 'call', 'exit', 'fail', 'wake'
     and 'apply' ports.  See also 'leash/1'.

'chr_flag(+FLAGNAME, ?OLDVALUE, ?NEWVALUE)'

     OLDVALUE is the value of the CHR flag FLAGNAME, and the new value
     of FLAGNAME is set to NEWVALUE.  The valid CHR flag are the
     following:

     'toplevel_show_store'
          If 'on' (the default), then the Prolog toplevel displays the
          constraint store at the end of each query.  If 'off', then the
          toplevel does not display this.

     'generate_debug_info'
          Provides the default if the 'debug' option is not given.  The
          valid values are 'true' and 'false' (the default).

     'optimize'
          Provides the default if the 'optimize' option is not given.
          The valid values are 'full' and 'off' (the default).

'chr_show_store(+MOD)'

     Prints all suspended constraints of module MOD to the current
     output stream.

'find_chr_constraint(-CONSTRAINT)   since release 4.3.2'

     Unifies CONSTRAINT with a constraint in the store.


File: sicstus.info,  Node: CHR Examples,  Next: CHR Guidelines,  Prev: CHR Debugging,  Up: lib-chr

10.8.5 Examples
---------------

Here are two example constraint solvers written in CHR.

  1. The program below defines a solver with one constraint, 'leq/2',
     which is a less-than-or-equal constraint, also known as a partial
     order constraint.

          :- module(leq,[leq/2]).
          :- use_module(library(chr)).

          :- chr_constraint leq/2.
          reflexivity   leq(X,X) <=> true.
          antisymmetry  leq(X,Y), leq(Y,X) <=> X = Y.
          idempotence   leq(X,Y) \ leq(X,Y) <=> true.
          transitivity  leq(X,Y), leq(Y,Z) ==> leq(X,Z).

     When the above program is loaded, you can call the 'leq/2'
     constraint in a query, e.g.:

          | ?- leq(X,Y), leq(Y,Z).
          leq(X,Y),
          leq(X,Z),
          leq(Y,Z) ?

  2. The program below implements a simple finite domain constraint
     solver.

          :- module(dom,[dom/2]).
          :- use_module(library(chr)).
          :- use_module(library(sets), [intersection/3]).

          :- chr_constraint dom(?int,+list(int)).
          :- chr_type list(T) ---> [] ; [T|list(T)].

          dom(X,[]) <=> fail.
          dom(X,[Y]) <=> X = Y.
          dom(X,L) <=> nonvar(X) | memberchk(X,L).
          dom(X,L1), dom(X,L2) <=> intersection(L1,L2,L3), dom(X,L3).

     When the above program is loaded, you can call the 'dom/2'
     constraint in a query, e.g.:

          | ?- dom(A,[1,2,3]), dom(A,[3,4,5]).
          A = 3

   Finally, Martin Keser's WebCHR package at
<http://chr.informatik.uni-ulm.de/~webchr/> contains more than 40
example programs for SICStus 4, complete with documentation and example
queries.


File: sicstus.info,  Node: CHR Guidelines,  Prev: CHR Examples,  Up: lib-chr

10.8.6 Guidelines
-----------------

In this subsection we cover several guidelines on how to use CHR to
write constraint solvers and how to do so efficiently.

Check guard bindings yourself.
     It is considered bad practice to write guards that bind variables
     of the head and to rely on the system to detect this at runtime.
     It is inefficient and obscures the working of the program.

Set semantics.
     The CHR system allows the presence of identical constraints, i.e.
     multiple constraints with the same functor, arity and arguments.
     For most constraint solvers, this is not desirable: it affects
     efficiency and possibly termination.  Hence appropriate simpagation
     rules should be added of the form:

          CONSTRAINT \ CONSTRAINT <=> TRUE.

Multi-headed rules.
     Multi-headed rules are executed more efficiently when the
     constraints share one or more variables.

Mode and type declarations.
     Provide mode and type declarations to get more efficient program
     execution.

Compile once, run many times.
     Does consulting your CHR program take a long time?  Probably it
     takes the CHR compiler a long time to compile the CHR rules into
     Prolog code.  When you disable optimizations the CHR compiler will
     be a lot quicker, but you may lose performance.


File: sicstus.info,  Node: lib-clpb,  Next: lib-clpfd,  Prev: lib-chr,  Up: The Prolog Library

10.9 Constraint Logic Programming over Booleans--'library(clpb)'
================================================================

* Menu:

* CLPB Introduction:: Introduction
* CLPB Interface:: Solver Interface
* CLPB Examples:: Examples


File: sicstus.info,  Node: CLPB Introduction,  Next: CLPB Interface,  Up: lib-clpb

10.9.1 Introduction
-------------------

The clp(B) system provided by this library module is an instance of the
general Constraint Logic Programming scheme introduced in [Jaffar &
Michaylov 87].  It is a solver for constraints over the Boolean domain,
i.e. the values 0 and 1.  The library module is a direct port from
SICStus Prolog 3.  It is not supported by SICS in any way.

   The Boolean domain is particularly useful for modeling digital
circuits, and the constraint solver can be used for verification,
design, optimization etc. of such circuits.

   To load the solver, enter the query:

     | ?- use_module(library(clpb)).

   The solver contains predicates for checking the consistency and
entailment of a constraint wrt. previous constraints, and for computing
particular solutions to the set of previous constraints.

   The underlying representation of Boolean functions is based on
Boolean Decision Diagrams [Bryant 86].  This representation is very
efficient, and allows many combinatorial problems to be solved with good
performance.

   Boolean expressions are composed from the following operands: the
constants 0 and 1 ('FALSE' and 'TRUE'), logical variables, and symbolic
constants, and from the following connectives.  P and Q are Boolean
expressions, X is a logical variable, IS is a list of integers or
integer ranges, and ES is a list of Boolean expressions:

'~ P'
     True if P is false.

'P * Q'
     True if P and Q are both true.

'P + Q'
     True if at least one of P and Q is true.

'P # Q'
     True if exactly one of P and Q is true.

'X ^ P'
     True if there exists an X such that P is true.  Same as 'P[X/0] +
     P[X/1]'.

'P =:= Q'
     Same as '~P # Q'.

'P =\= Q'
     Same as 'P # Q'.

'P =< Q'
     Same as '~P + Q'.

'P >= Q'
     Same as 'P + ~Q'.

'P < Q'
     Same as '~P * Q'.

'P > Q'
     Same as 'P * ~Q'.

'card(IS, ES)'
     True if the number of true expressions in ES is a member of the set
     denoted by IS.

   Symbolic constants (Prolog atoms) denote parametric values and can be
viewed as all-quantified variables whose quantifiers are placed outside
the entire expression.  They are useful for forcing certain variables of
an equation to be treated as input parameters.


File: sicstus.info,  Node: CLPB Interface,  Next: CLPB Examples,  Prev: CLPB Introduction,  Up: lib-clpb

10.9.2 Solver Interface
-----------------------

The following predicates are defined:

'sat(+EXPRESSION)'

     EXPRESSION is a Boolean expression.  This checks the consistency of
     the expression wrt. the accumulated constraints, and, if the check
     succeeds, _tells_ the constraint that the expression be true.

     If a variable X, occurring in the expression, is subsequently
     unified with some term T, then this is treated as a shorthand for
     the constraint
          | ?- sat(X=:=T).

'taut(+EXPRESSION, ?TRUTH)'

     EXPRESSION is a Boolean expression.  This _asks_ whether the
     expression is now entailed by the accumulated constraints
     (TRUTH=1), or whether its negation is entailed by the accumulated
     constraints (TRUTH=0).  Otherwise, it fails.

'labeling(+VARIABLES)'

     VARIABLES is a list of variables.  The variables are instantiated
     to a list of 0s and 1s, in a way that satisfies any accumulated
     constraints.  Enumerates all solutions by backtracking, but creates
     choicepoints only if necessary.


File: sicstus.info,  Node: CLPB Examples,  Prev: CLPB Interface,  Up: lib-clpb

10.9.3 Examples
---------------

* Menu:

* CLPB Example 1:: Example 1
* CLPB Example 2:: Example 2
* CLPB Example 3:: Example 3                   A one-bit adder circuit.
* CLPB Example 4:: Example 4                   Fault detection.


File: sicstus.info,  Node: CLPB Example 1,  Next: CLPB Example 2,  Up: CLPB Examples

10.9.3.1 Example 1
..................

     | ?- sat(X + Y).

     sat(X=\=_A*Y#Y)

illustrates three facts.  First, any accumulated constraints affecting
the top-level variables are displayed floundered goals, since the query
is not true for all 'X' and 'Y'.  Secondly, accumulated constraints are
displayed as 'sat(V=:=EXPR)' or 'sat(V=\=EXPR)' where V is a variable
and EXPR is a "polynomial", i.e. an exclusive or of conjunctions of
variables and constants.  Thirdly, '_A' had to be introduced as an
artificial variable, since 'Y' cannot be expressed as a function of 'X'.
That is, 'X + Y' is true iff there exists an '_A' such that
'X=\=_A*Y#Y'.  Let's check it!

     | ?- taut(_A ^ (X=\=_A*Y#Y) =:= X + Y, T).

     T = 1

verifies the above answer.  Notice that the formula in this query is a
tautology, and so it is entailed by an empty set of constraints.


File: sicstus.info,  Node: CLPB Example 2,  Next: CLPB Example 3,  Prev: CLPB Example 1,  Up: CLPB Examples

10.9.3.2 Example 2
..................

     | ?- taut(A =< C, T).

     no
     | ?- sat(A =< B), sat(B =< C), taut(A =< C, T).

     T = 1,
     sat(A=:=_A*_B*C),
     sat(B=:=_B*C)

     | ?- taut(a, T).

     T = 0

     | ?- taut(~a, T).

     T = 0

illustrates the entailment predicate.  In the first query, the
expression "A implies C" is neither known to be true nor false, so the
query fails.  In the second query, the system is told that "A implies B"
and "B implies C", so "A implies C" is entailed.  The expressions in the
third and fourth queries are to be read "for each a, a is true" and "for
each a, a is false", respectively, and so 'T = 0' in both cases since
both are unsatisfiable.  This illustrates the fact that the implicit
universal quantifiers introduced by symbolic constants are placed in
front of the entire expression.


File: sicstus.info,  Node: CLPB Example 3,  Next: CLPB Example 4,  Prev: CLPB Example 2,  Up: CLPB Examples

10.9.3.3 Example 3
..................

     | ?- [user].
     | adder(X, Y, Sum, Cin, Cout) :-
          sat(Sum =:= card([1,3],[X,Y,Cin])),
          sat(Cout =:= card([2-3],[X,Y,Cin])).
     | ^D
     % consulted user in module user, 0 msec 424 bytes

     | ?- adder(x, y, Sum, cin, Cout).

     sat(Sum=:=cin#x#y),
     sat(Cout=:=x*cin#x*y#y*cin)

     | ?- adder(x, y, Sum, 0, Cout).

     sat(Sum=:=x#y),
     sat(Cout=:=x*y)

     | ?- adder(X, Y, 0, Cin, 1), labeling([X,Y,Cin]).

     Cin = 0,
     X = 1,
     Y = 1 ? ;

     Cin = 1,
     X = 0,
     Y = 1 ? ;

     Cin = 1,
     X = 1,
     Y = 0 ? ;

illustrates the use of cardinality constraints and models a one-bit
adder circuit.  The first query illustrates how representing the input
signals by symbolic constants forces the output signals to be displayed
as functions of the inputs and not vice versa.  The second query
computes the simplified functions obtained by setting carry-in to 0.
The third query asks for particular input values satisfying sum and
carry-out being 0 and 1, respectively.


File: sicstus.info,  Node: CLPB Example 4,  Prev: CLPB Example 3,  Up: CLPB Examples

10.9.3.4 Example 4
..................

The predicate 'fault/3' below describes a 1-bit adder consisting of five
gates, with at most one faulty gate.  If one of the variables 'Fi' is
equal to 1, then the corresponding gate is faulty, and its output signal
is undefined (i.e. the constraint representing the gate is relaxed).

   Assuming that we have found some incorrect output from a circuit, we
are interesting in finding the faulty gate.  Two instances of incorrect
output are listed in 'fault_ex/2':

     fault([F1,F2,F3,F4,F5], [X,Y,Cin], [Sum,Cout]) :-
             sat(
                         card([0-1],[F1,F2,F3,F4,F5]) *
                         (F1 + (U1 =:= X * Cin)) *
                         (F2 + (U2 =:= Y * U3)) *
                         (F3 + (Cout =:= U1 + U2)) *
                         (F4 + (U3 =:= X # Cin)) *
                         (F5 + (Sum =:= Y # U3))
                     ).

     fault_ex(1, Faults) :- fault(Faults, [1,1,0], [1,0]).
     fault_ex(2, Faults) :- fault(Faults, [1,0,1], [0,0]).

   To find the faulty gates, we run the query

     | ?- fault_ex(I,L), labeling(L).

     I = 1,
     L = [0,0,0,1,0] ? ;

     I = 2,
     L = [1,0,0,0,0] ? ;

     I = 2,
     L = [0,0,1,0,0] ? ;

     no

   Thus for input data '[1,1,0]', gate 4 must be faulty.  For input data
'[1,0,1]', either gate 1 or gate 3 must be faulty.

   To get a symbolic representation of the outputs interms of the input,
we run the query

     | ?- fault([0,0,0,0,0], [x,y,cin], [Sum,Cout]).

     sat(Cout=:=x*cin#x*y#y*cin),
     sat(Sum=:=cin#x#y)

which shows that the sum and carry out signals indeed compute the
intended functions if no gate is faulty.


File: sicstus.info,  Node: lib-clpfd,  Next: lib-clpqr,  Prev: lib-clpb,  Up: The Prolog Library

10.10 Constraint Logic Programming over Finite Domains--'library(clpfd)'
========================================================================

* Menu:

* CLPFD Intro:: Introduction
* CLPFD Caveats:: Caveats
* CLPFD Interface:: Solver Interface
* Available Constraints:: Available Constraints
* Enumeration Predicates:: Enumeration Predicates
* Statistics Predicates:: Statistics Predicates
* Answer Constraints:: Answer Constraints
* CLPFD Debugging:: Debugging
* Defining Global Constraints:: Defining Global Constraints
* Defining Primitive Constraints:: Defining Primitive Constraints
* CLPFD Coexisting:: Coexisting with Attributes and Blocked Goals
* CLPFD Example Programs:: Example Programs
* Syntax Summary:: Syntax Summary


File: sicstus.info,  Node: CLPFD Intro,  Next: CLPFD Caveats,  Up: lib-clpfd

10.10.1 Introduction
--------------------

The clp(FD) solver described in this chapter is an instance of the
general Constraint Logic Programming scheme introduced in [Jaffar &
Michaylov 87].  This constraint domain is particularly useful for
modeling discrete optimization and verification problems such as
scheduling, planning, packing, timetabling etc.  The treatise [Van
Hentenryck 89] is an excellent exposition of the theoretical and
practical framework behind constraint solving in finite domains, and
summarizes the work up to 1989.

   This solver has the following highlights:

   * A rich set of global constraints with state-of-the-art propagators.
   * Two classes of propagators are handled internally: indexicals and
     global propagators.
   * Propagators of both classes can be user-defined, by means of
     programming interfaces.
   * The constraints described in this chapter are automatically
     translated to sets of propagators.
   * The truth value of a primitive constraint can be reflected into a
     0/1-variable, i.e. a variable with domain '0..1' (reification).

   This library fully supports multiple SICStus runtimes in a process.

* Menu:

* Referencing CLPFD:: Referencing this Software
* Acknowledgments CLPFD:: Acknowledgments

   The rest of this chapter is organized as follows: How to load the
solver and how to write simple programs is explained in *note CLPFD
Interface::.  A description of all constraints that the solver provides
is contained in *note Available Constraints::.  The predicates for
searching for solution are documented in *note Enumeration Predicates::.
The predicates for getting execution statistics are documented in *note
Statistics Predicates::.  A few notes on debugging are given in *note
CLPFD Debugging::.  A few example programs are given in *note CLPFD
Example Programs::.  Finally, *note Syntax Summary:: contains syntax
rules for all expressions.

   The following sections discuss advanced features and are probably
only relevant to experienced users: How to control the amount of
information presented in answers to queries is explained in *note Answer
Constraints::.  How to add new global constraints via a programming
interface is described in *note Defining Global Constraints::.  How to
define new primitive constraints with indexicals is described in *note
Defining Primitive Constraints::.  The fine points of coexisting with
attributes and blocked goals are described in *note CLPFD Coexisting::.


File: sicstus.info,  Node: Referencing CLPFD,  Next: Acknowledgments CLPFD,  Up: CLPFD Intro

10.10.1.1 Referencing this Software
...................................

When referring to this implementation of clp(FD) in publications, please
use the following reference:
     Carlsson M., Ottosson G., Carlson B. 'An Open-Ended Finite Domain
     Constraint Solver', Proc.  Programming Languages: Implementations,
     Logics, and Programs, 1997.


File: sicstus.info,  Node: Acknowledgments CLPFD,  Prev: Referencing CLPFD,  Up: CLPFD Intro

10.10.1.2 Acknowledgments
.........................

The first version of this solver was written as part of Key Hyckenberg's
MSc thesis in 1995, with contributions from Greger Ottosson at the
Computing Science Department, Uppsala University.  The code was later
rewritten by Mats Carlsson with contributions by Nicolas Beldiceanu.
Pe'ter Szeredi contributed material for this manual chapter.

   The development of this software was supported by the Swedish
National Board for Technical and Industrial Development (NUTEK) under
the auspices of Advanced Software Technology (ASTEC) Center of
Competence at Uppsala University.

   We include a collection of examples, among which some have been
distributed with the INRIA implementation of clp(FD) [Diaz & Codognet
93].


File: sicstus.info,  Node: CLPFD Caveats,  Next: CLPFD Interface,  Prev: CLPFD Intro,  Up: lib-clpfd

10.10.2 Caveats and Limitations
-------------------------------

Following are some general statements about the constraints and
libraries of this library module.

Domain Variables
     Only small integers (*note Glossary::) and domain variables are
     allowed as arguments to finite domain constraints.  Whenever a
     domain variable is required in the argument of a constraint, a
     small integer can be given instead.  The conversion from unbound
     variable to domain variable is automatic.

Aliasing
     In case of variable aliasing, i.e. if a variable occurs more than
     once in a global constraint that is being posted, or due to a
     subsequent variable-variable unification, then any guarantee to
     maintain a particular level of consistency no longer holds, and
     idempotency is almost always lost.

Termination
     Of course, all constraints and predicates terminate.  However, due
     to the combinatorial nature of constraint solving, and to the fact
     that constraint solving is based on filtering domains, which can be
     huge, pathological cases where termination takes extremely long
     time are easily constructed.  After about 15,000 years on a 64-bit
     machine, the following query terminates with a representation
     error, when the lower bound of X exceeds the small integer range:

          | ?- X #> abs(X).
          [... ... ...]
          ! Representation error in user:'t=<u+c'/3
          ! CLPFD integer overflow
          ! goal:  't=<u+c'(_245,_247,-1)

     Anyway, if you find non-pathological cases that take longer than
     reasonable time to terminate, then please write to
     <sicstus-support@sics.se>.

Error Checking
     Contrary to most library modules, CLPFD constraints and predicates
     check their arguments to almost the same extent as built-in
     predicates.  If you find a case where reasonable error checking is
     missing, then please write to <sicstus-support@sics.se>.


File: sicstus.info,  Node: CLPFD Interface,  Next: Available Constraints,  Prev: CLPFD Caveats,  Up: lib-clpfd

10.10.3 Solver Interface
------------------------

* Menu:

* Posting Constraints:: Posting Constraints
* A Constraint Satisfaction Problem:: A Constraint Satisfaction Problem
* Reified Constraints:: Reified Constraints

The solver contains predicates for checking the consistency and
entailment of finite domain constraints, as well as solving for solution
values for your problem variables.

   In the context of this constraint solver, a "finite domain" is a
subset of small integers, and a "finite domain constraint" denotes a
relation over a tuple of small integers (*note Glossary::).  Hence, only
small integers and unbound variables are allowed in finite domain
constraints.

   A finite domain is denoted symbolically by a CONSTANTRANGE (*note
Syntax of Indexicals::), a special case of which is an interval, written
as one of the expressions 'A..B', 'A..sup', 'inf..B', or 'inf..sup'.
Here, A and B should be small integers, 'inf' denotes minus infinity,
and 'sup' denotes plus infinity.  *Please note*: 'inf' and 'sup' do not
denote integers, they only denote the absence of a lower resp.  upper
bound.  Such CONSTANTRANGE terms occur in certain contexts, the most
common of which is the unary constraint of the form:

     | ?- X in 1..5.
     X in 1..5

   which constrains X to be in the given interval.  Note that variables
do not have to be "declared" in this way before they are used in
constraints.  If an unconstrained variable occurs in a constraint, then
it will be treated as having the domain 'inf..sup'.

   All "domain variables", i.e. variables that occur as arguments to
finite domain constraints get associated with a finite domain, either
explicitly declared by the program, or implicitly imposed by the
constraint solver.  Temporarily, the domain of a variable may actually
be infinite, if it does not have a finite lower or upper bound.  If
during the computation a variable receives a new lower or upper bound
that cannot be represented as a small integer, then an overflow
condition is issued.  This is expressed as silent failure or as a
representation error, subject to the 'overflow' option of 'fd_flag/3'.

   The set of current domains of all domain variables is called the
"domain store".  Domain store S is an "extension" of domain store T if
each domain in S is a subset of the corresponding domain in T.  If some
domain is empty, then the store is "contradictory" and execution
backtracks; otherwise, it is "consistent".

   At the end of a successful computation, all domains have usually
become singletons, i.e. the domain variables have become assigned.  The
domains do not become singletons automatically.  Usually, it takes some
amount of search to find an assignment that satisfies all constraints.
It is the programmer's responsibility to do so.  If some domain
variables are left unassigned in a computation, then the garbage
collector will preserve all constraint data that is attached to them.

   *Please note*: if a term containing domain variables is written,
copied, asserted, gathered as a solution to 'findall/3' and friends, or
raised as an exception, then those domain variables will be replaced by
brand new variables in the copy.  To retain the domains and any attached
constraints, you can use 'copy_term/3' with 'clpfd:full_answer' asserted
(*note ref-lte-cpt:: and *note Answer Constraints::).  *API change wrt.
release 3.*

   Every finite domain constraint is implemented by a "propagator", or a
set of such.  Some constraints have alternative propagators with
differing properties.  All propagators act as coroutines performing
incremental constraint solving, removing values from domains, and/or
entailment checking.  They wake up by changes in the domains of its
arguments.  A propagator P can be seen as a function on constraint store
S: P(S) denotes the extension of S resulting from applying P on S.

   Propagators come in two kinds: "indexicals", stateless reactive
functional rules implemented by a stack machine and running, and "global
propagators", usually stateful, implemented in C or Prolog, and using
algorithms from many fields of computer science.  At the heart of the
constraint solver is a scheduler for propagators, where indexicals have
priority over global propagators.

   Certain properties of propagators are desirable:

Correct
     A correct propagator never removes values that are consistent wrt.
     its constraint.  This property is mandatory.

Checking
     A checking propagator accepts all ground assignments that satisfies
     the given constraint, and rejects all ground assignments that
     violate it.  This property is also mandatory.

Contracting
     A contracting propagator never adds any value to any domain.  This
     property is also mandatory.

Monotone
     A propagator P is monotone if, for all domain stores S and T, S is
     an extension of T implies that P(S) is an extension of P(T).  This
     property is not mandatory but helps understanding and debugging.

Idempotent
     A propagator P is idempotent if, for all domain stores S, P(S)
     equals P(P(S)).

Domain-Consistent
     A domain-consistent propagator removes all inconsistent values.
     This property is not mandatory and only a few propagators have it.
     The reason is that the complexity of maintaining domain consistency
     is often prohibitively high.

Bounds-Consistent
     A bounds-consistent propagator adjusts all inconsistent upper and
     lower domain bounds.  This property is not mandatory, and is
     implied by domain consistency.  This property is more widespread
     and usually less costly to maintain than domain consistency, but
     far from all propagators have it.


File: sicstus.info,  Node: Posting Constraints,  Next: A Constraint Satisfaction Problem,  Up: CLPFD Interface

10.10.3.1 Posting Constraints
.............................

A constraint is called as any other Prolog predicate.  When called, the
constraint is "posted" to the store.  For example:

     | ?- X in 1..5, Y in 2..8, X+Y #= T.
     X in 1..5,
     Y in 2..8,
     T in 3..13

     | ?- X in 1..5, T in 3..13, X+Y #= T.
     X in 1..5,
     T in 3..13,
     Y in -2..12

   Note that the answer constraint shows the domains of nonground query
variables, but does not show any constraints that may be attached to
them.

   Normally, after posting a constraint, propagation to fixpoint is
performed, which can be an overkill.  The following provides a means of
posting a set of constraints in one batch, suspending all propagation
until the whole set has been posted.  Suspending propagation can
significantly reduce posting overhead.

'fd_batch(+CONSTRAINTS)   since release 4.2.1'

     where CONSTRAINTS should be a list of constraints, user-defined or
     exported by 'library(clpfd)'.  General Prolog goals among the
     constraints will have undefined behavior.


File: sicstus.info,  Node: A Constraint Satisfaction Problem,  Next: Reified Constraints,  Prev: Posting Constraints,  Up: CLPFD Interface

10.10.3.2 A Constraint Satisfaction Problem
...........................................

Constraint satisfaction problems (CSPs) are a major class of problems
for which this solver is ideally suited.  In a CSP, the goal is to pick
values from predefined domains for certain variables so that the given
constraints on the variables are all satisfied.

   As a simple CSP example, let us consider the Send More Money puzzle.
In this problem, the variables are the letters S, E, N, D, M, O, R, and
Y. Each letter represents a digit between 0 and 9.  The problem is to
assign a value to each digit, such that SEND + MORE equals MONEY.

   A program that solves the puzzle is given below.  The program
contains the typical three steps of a clp(FD) program:

  1. declare the domains of the variables
  2. post the problem constraints
  3. look for a feasible solution via backtrack search, or look for an
     optimal solution via branch-and-bound search

   Sometimes, an extra step precedes the search for a solution: the
posting of surrogate constraints to break symmetries or to otherwise
help prune the search space.  No surrogate constraints are used in this
example.

   The domains of this puzzle are stated via the 'domain/3' goal and by
requiring that S and M be greater than zero.  The two problem constraint
of this puzzle are the equation ('sum/8') and the constraint that all
letters take distinct values ('all_different/1').  Finally, the
backtrack search is performed by 'labeling/2'.  Different search
strategies can be encoded in the 'Type' parameter.  In the example
query, the default search strategy is used (select the leftmost
variable, try values in ascending order).

     :- use_module(library(clpfd)).

     mm([S,E,N,D,M,O,R,Y], Type) :-
          domain([S,E,N,D,M,O,R,Y], 0, 9),      % step 1
          S#>0, M#>0,
          all_different([S,E,N,D,M,O,R,Y]),     % step 2
          sum(S,E,N,D,M,O,R,Y),
          labeling(Type, [S,E,N,D,M,O,R,Y]).    % step 3

     sum(S, E, N, D, M, O, R, Y) :-
                       1000*S + 100*E + 10*N + D
          +            1000*M + 100*O + 10*R + E
          #= 10000*M + 1000*O + 100*N + 10*E + Y.

     | ?- mm([S,E,N,D,M,O,R,Y], []).
     D = 7,
     E = 5,
     M = 1,
     N = 6,
     O = 0,
     R = 8,
     S = 9,
     Y = 2


File: sicstus.info,  Node: Reified Constraints,  Prev: A Constraint Satisfaction Problem,  Up: CLPFD Interface

10.10.3.3 Reified Constraints
.............................

Instead of merely posting constraints it is often useful to reflect its
truth value into a 0/1-variable B, so that:

   * the constraint is posted if B is set to 1
   * the negation of the constraint is posted if B is set to 0
   * B is set to 1 if the constraint becomes entailed
   * B is set to 0 if the constraint becomes disentailed

   This mechanism is known as "reification".  Several frequently used
operations can be defined in terms of reified constraints.  A reified
constraint is written:

     | ?- CONSTRAINT #<=> B.

where CONSTRAINT is reifiable.  As an example of a constraint that uses
reification, consider 'exactly(X,L,N)', defined to be true if X occurs
exactly N times in the list L.  It can be defined thus:

     exactly(_, [], 0).
     exactly(X, [Y|L], N) :-
         X #= Y #<=> B,
         N #= M+B,
         exactly(X, L, M).

   Finally, reified constraints can be used as terms inside arithmetic
expression.  The value of the term is 1 if the constraint is true, and 0
otherwise.  For example:

     | ?- X #= 10, B #= (X#>=2) + (X#>=4) + (X#>=8).
     B = 3,
     X = 10


File: sicstus.info,  Node: Available Constraints,  Next: Enumeration Predicates,  Prev: CLPFD Interface,  Up: lib-clpfd

10.10.4 Available Constraints
-----------------------------

This section describes constraints that can be used with this solver,
organized into classes.  Unless documented otherwise, constraints are
not reifiable and do not guarantee any particular level of consistency.
Whenever a domain variable is required in the argument of a constraint,
a small integer can be given instead.

* Menu:

* Arithmetic Constraints:: Arithmetic Constraints
* Membership Constraints:: Membership Constraints
* Propositional Constraints:: Propositional Constraints
* Arithmetic-Logical Constraints:: Arithmetic-Logical Constraints
* Extensional Constraints:: Extensional Constraints
* Graph Constraints:: Graph Constraints
* Scheduling Constraints:: Scheduling Constraints
* Placement Constraints:: Placement Constraints
* Automata Constraints:: Automata Constraints
* User-Defined Constraints:: User-Defined Constraints


File: sicstus.info,  Node: Arithmetic Constraints,  Next: Membership Constraints,  Up: Available Constraints

10.10.4.1 Arithmetic Constraints
................................

'?EXPR RELOP ?EXPR   reifiable'

     defines an arithmetic constraint.  The syntax for EXPR and RELOP is
     defined by a grammar (*note Syntax of Arithmetic Expressions::).
     Note that the expressions are not restricted to being linear.
     Constraints over nonlinear expressions, however, will usually yield
     less constraint propagation than constraints over linear
     expressions.

     Arithmetic constraints can be reified as e.g.:

          | ?- X in 1..2, Y in 3..5, X#=<Y #<=> B.
          B = 1,
          X in 1..2,
          Y in 3..5

   Linear arithmetic constraints, except equalities, maintain bounds
consistency.  Their reified versions detect bounds entailment and
disentailment.

   The following constraints are among the library constraints that
general arithmetic constraints compile to.  They express a relation
between a sum or a scalar product and a value, using a dedicated
algorithm, which avoids creating any temporary variables holding
intermediate values.  If you are computing a sum or a scalar product,
then it can be much more efficient to compute lists of coefficients and
variables and post a single sum or scalar product constraint than to
post a sequence of elementary constraints.

'sum(+XS, +RELOP, ?VALUE)'

     where XS is a list of domain variables, RELOP is a relational
     symbol as above, and VALUE is an integer or a domain variable.
     True if 'sum(XS) RELOP VALUE'.  Corresponds roughly to 'sumlist/2'
     in 'library(lists)'.

'scalar_product(+COEFFS, +XS, +RELOP, ?VALUE)'
'scalar_product(+COEFFS, +XS, +RELOP, ?VALUE, +OPTIONS)'

     where COEFFS is a list of length N of integers, XS is a list of
     length N of integers or domain variables, RELOP is a relational
     symbol as above, and VALUE is a domain variable.  True if
     'sum(COEFFS*XS) RELOP VALUE'.

     OPTIONS is a list that may include the following options:

     'among(LEAST,MOST,RANGE)   since release 4.3.1'
          If given, then LEAST and MOST should be integers and RANGE
          should be a CONSTANTRANGE (*note Syntax of Indexicals::).
          This option imposes the additional constraint on XS that at
          least LEAST and at most MOST elements belong to RANGE.  This
          side constraint invokes the algorithm of [Razakarison,
          Carlsson, Beldiceanu & Simonis 13].

     'consistency(CONS)'
          This can be used to control the level of consistency used by
          the constraint.  The value is one of the following:
          'domain'
               The constraint maintains domain consistency.  *Please
               note*: This option is only meaningful if RELOP is '#=',
               and requires that any domain variables have finite
               bounds.
          'bounds'
          'value'
               The constraint tries to maintain bounds consistency (the
               default).

   The following constraints constrain a value to be the minimum
(maximum) of a given list of values.

'minimum(?VALUE, +XS)'

     where XS is a list of domain variables, and VALUE is a domain
     variable.  True if VALUE is the minimum of XS.  Corresponds to
     'min_member/2' in 'library(lists)' and to 'minimum/2' in MiniZinc.

'maximum(?VALUE, +XS)'

     where XS is a list of domain variables, and VALUE is a domain
     variable.  True if VALUE is the maximum of XS.  Corresponds to
     'max_member/2' in 'library(lists)' and to 'maximum/2' in MiniZinc.


File: sicstus.info,  Node: Membership Constraints,  Next: Propositional Constraints,  Prev: Arithmetic Constraints,  Up: Available Constraints

10.10.4.2 Membership Constraints
................................

'domain(+VARIABLES, +MIN, +MAX)'

     where VARIABLES is a list of domain variables, MIN is an integer or
     the atom 'inf' (minus infinity), and MAX is an integer or the atom
     'sup' (plus infinity).  True if the variables all are elements of
     the range 'MIN..MAX'.

'?X in +RANGE   reifiable'

     where X is a domain variable and RANGE is a CONSTANTRANGE (*note
     Syntax of Indexicals::).  True if X is an element of the range.

'?X in_set +FDSET   reifiable'

     where X is a domain variable and FDSET is an FD set (*note FD Set
     Operations::).  True if X is an element of the FD set.

   'in/2' and 'in_set/2' constraints maintain domain consistency and
their reified versions detect domain entailment and disentailment.


File: sicstus.info,  Node: Propositional Constraints,  Next: Arithmetic-Logical Constraints,  Prev: Membership Constraints,  Up: Available Constraints

10.10.4.3 Propositional Constraints
...................................

Propositional combinators can be used to combine reifiable constraints
into propositional formulae over such constraints.  Such formulae are
goal expanded by the system into sequences of reified constraints and
arithmetic constraints.  For example,

     X #= 4 #\/ Y #= 6

expresses the disjunction of two equality constraints.

   The leaves of propositional formulae can be reifiable constraints,
the constants 0 and 1, or 0/1-variables.  New primitive, reifiable
constraints can be defined with indexicals as described in *note
Defining Primitive Constraints::.

   The propositional combinators maintain domain consistency and their
reified versions detect domain entailment and disentailment.  The
following propositional combinators are available:

'#\ :Q   reifiable'

     True if the constraint Q is false.

':P #/\ :Q   reifiable'

     True if the constraints P and Q are both true.

':P #\ :Q   reifiable'

     True if exactly one of the constraints P and Q is true.

':P #\/ :Q   reifiable'

     True if at least one of the constraints P and Q is true.

':P #=> :Q   reifiable'
':Q #<= :P   reifiable'

     True if the constraint Q is true or the constraint P is false.

':P #<=> :Q   reifiable'

     True if the constraints P and Q are both true or both false.

   Note that the reification scheme introduced in *note Reified
Constraints:: is a special case of a propositional constraint.


File: sicstus.info,  Node: Arithmetic-Logical Constraints,  Next: Extensional Constraints,  Prev: Propositional Constraints,  Up: Available Constraints

10.10.4.4 Arithmetic-Logical Constraints
........................................

'smt(:CONSTRAINTBODY)   since release 4.2'

     The arithmetic, membership, and propositional constraints described
     earlier are transformed at compile time to conjunctions of library
     constraints.  Although linear in the size of the source code, the
     expansion of a propositional formula over reifiable constraints to
     library goals can have time and memory overheads, and propagates
     disjunctions very weakly.  Temporary variables holding intermediate
     values may have to be introduced, and the grain size of the
     constraint solver invocations can be rather small.  As an
     alternative to the default propagation of such constraint formulas,
     this constraint is a front-end to the 'case/[3,4]' propagator,
     which treats such a formula globally.  The pruning can be stronger
     and it can run faster than the default propagator, but this is not
     necessarily the case.  Bounds consistency is not guaranteed.

     CONSTRAINTBODY should be of one of the following forms, or a
     propositional combination of such forms.  *Note Syntax of
     Indexicals::.  for the exact definition:

        * "var" 'in' CONSTANTRANGE
        * 'element("var",CLIST,"var")'
        * 'table([VLIST],CTABLE)'
        * LINEXPR RELOP LINEXPR
        * "var" { 'X' stands for 'X#=1' }

'count(+VAL,+LIST,+RELOP,?COUNT)   since release 4.0.5,deprecated'

     where VAL is an integer, LIST is a list of domain variables, COUNT
     a domain variable, and RELOP is a relational symbol as in *note
     Arithmetic Constraints::.  True if N is the number of elements of
     LIST that are equal to VAL and N RELOP COUNT.  Implemented by
     decomposition into one 'sum/3' constraint, one arithmetic
     comparison, and several reified equalities.

     Corresponds to 'count_*/3', 'exactly/3' in MiniZinc.

     'count/4' maintains domain consistency, but in practice, the
     following constraint is a better alternative.

'global_cardinality(+XS,+VALS)'
'global_cardinality(+XS,+VALS,+OPTIONS)'

     where XS = [X1,...,XD] is a list of domain variables, and VALS =
     [K1-V1,...,KN-VN] is a list of pairs where each key KI is a unique
     integer and VI is a domain variable.  True if every element of XS
     is equal to some key and for each pair KI-VI, exactly VI elements
     of XS are equal to KI.

     If either XS or VALS is ground, and in many other special cases,
     then 'global_cardinality/[2,3]' maintains domain consistency, but
     generally, bounds consistency cannot be guaranteed.  A domain
     consistency algorithm [Regin 96] is used, roughly linear in the
     total size of the domains.

     Corresponds to 'global_cardinality*/*' and 'distribute/3' in
     MiniZinc.

     OPTIONS is a list of zero or more of the following:

     'consistency(CONS)'
          Which filtering algorithm to use.  One of the following:
          'domain'
               The constraint will use the algorithm mentioned above.
               Implies 'on(dom)'.  The default.
          'bounds'
               The constraint will use the algorithm mentioned above.
               Implies 'on(minmax)'.
          'value'
               The constraint will use a simple algorithm, which
               prevents too few or too many of the XS from taking values
               among the VALS.  Implies 'on(val)'.

     'on(ON)'
          How eagerly to wake up the constraint.  One of the following:
          'dom'
               to wake up when the domain of a variable is changed (the
               default);
          'minmax'
               to wake up when a bound of a variable is changed;
          'val'
               to wake up when a variable is fixed.

     'cost(COST,MATRIX)'
          Overrides any 'consistency/1' option value.  A cost is
          associated with the constraint and reflected into the domain
          variable COST.  MATRIX should be a D*N matrix of integers,
          represented as a list of D lists, each of length N.  Assume
          that each XI equals K(PI).  The cost of the constraint is then
          MATRIX[1,P1]+...+MATRIX[D,PD].

          With this option, a domain consistency algorithm [Regin 99] is
          used, the complexity of which is roughly O(D(M + N LOG N))
          where M is the total size of the domains.

'all_different(+VARIABLES)'
'all_different(+VARIABLES, +OPTIONS)'
'all_distinct(+VARIABLES)'
'all_distinct(+VARIABLES, +OPTIONS)'

     where VARIABLES is a list of domain variables.  Each variable is
     constrained to take a value that is unique among the variables.
     Declaratively, this is equivalent to an inequality constraint for
     each pair of variables.

     Corresponds to 'alldifferent/1' in MiniZinc.

     OPTIONS is a list of zero or more of the following:

     'L #= R   since release 4.3'
          where R should be an integer, and L an expressions of one of
          the following forms, where X1, ..., XJ occur among VARIABLES:
          'X1 + ... + XJ'
          'X1*X1 + ... + XJ*XJ'
          'X1 * ... * XJ'
          The given equation is a side constraint for the constraint to
          hold.  A special bounds consistency algorithm is used, which
          considers the main constraint and the side constraints
          globally.  This option is only valid if the domains of X1,
          ..., XJ consist of integers strictly greater than zero.

     'consistency(CONS)'
          Which algorithm to use, one of the following:

          'domain'
               The default for 'all_distinct/[1,2]' and
               'assignment/[2,3]'.  A domain consistency algorithm
               [Regin 94] is used, roughly linear in the total size of
               the domains.  Implies 'on(dom)'.

          'bounds'
               A bounds consistency algorithm [Lopez-Ortiz 03] is used,
               which runs in O(N LOG N) time for N variables.  Implies
               'on(minmax)'.

          'value'
               The default for 'all_different/[1,2]'.  An algorithm
               achieving exactly the same pruning as a set of pairwise
               inequality constraints is used, roughly linear in the
               number of variables.  Implies 'on(val)'.

     'on(ON)'
          How eagerly to wake up the constraint.  One of the following:
          'dom'
               (the default for 'all_distinct/[1,2]' and
               'assignment/[2,3]'), to wake up when the domain of a
               variable is changed;
          'min'
               to wake up when the lower bound of a domain is changed;
          'max'
               to wake up when the upper bound of a domain is changed;
          'minmax'
               to wake up when some bound of a domain is changed;
          'val'
               (the default for 'all_different/[1,2]'), to wake up when
               a variable is fixed.

'nvalue(?N, +VARIABLES)'

     where VARIABLES is a list of domain variables with finite bounds,
     and N is a domain variable.  True if N is the number of distinct
     values taken by VARIABLES.  Approximates bounds consistency in N
     and domain consistency in VARIABLES.  Can be thought of as a
     relaxed version of 'all_distinct/2'.

     Corresponds to 'nvalue/2' in MiniZinc.

   The following is a constraint over two lists of length N of
variables.  Each variable is constrained to take a value in [1,N] that
is unique for its list.  Furthermore, the lists are dual in a sense
described below.

'assignment(+XS, +YS)'
'assignment(+XS, +YS, +OPTIONS)'

     where XS = [X1,...,XN] and YS = [Y1,...,YN] are lists of domain
     variables.  True if all XI, YI IN [1,N] and XI=J IFF YJ=I.

     Corresponds to 'inverse/2' in MiniZinc.

     OPTIONS is a list of zero or more of the following, where BOOLEAN
     must be 'true' or 'false' ('false' is the default):

     'on(ON)'
          Same meaning as for 'all_different/2'.

     'consistency(CONS)'
          Same meaning as for 'all_different/2'.

     'circuit(BOOLEAN)'
          If 'true', then 'circuit(XS,YS)' must hold for the constraint
          to be true.

     'cost(COST,MATRIX)'
          A cost is associated with the constraint and reflected into
          the domain variable COST.  MATRIX should be an N*N matrix of
          integers, represented as a list of lists.  The cost of the
          constraint is MATRIX[1,X1]+...+MATRIX[N,XN].

          With this option, a domain consistency algorithm [Sellmann 02]
          is used, the complexity of which is roughly O(N(M + N LOG N))
          where M is the total size of the domains.

   The following constraint captures the relation between a list of
values, a list of the values in ascending order, and their positions in
the original list:

'sorting(+XS,+PS,+YS)'

     where XS = [X1,...,XN], PS = [P1,...,PN], and YS = [Y1,...,YN] are
     lists of domain variables.  The constraint holds if the following
     are true:

        * YS is in ascending order.

        * PS is a permutation of [1,N].

        * FOR ALL I IN [1,N] : XI = Y(PI)

     In practice, the underlying algorithm [Mehlhorn 00] is likely to
     achieve bounds consistency, and is guaranteed to do so if PS is
     ground or completely free.

     Corresponds to 'sort/2' in MiniZinc.

   The following constraint is a generalization of 'sorting/3', namely:

   * It sorts not domain variables, but tuples of them.
   * The tuples are split into a key prefix and a value suffix.  They
     are sorted wrt. the key part only.
   * The sort is stable: if two tuples have identical keys, then their
     relative order is preserved in the output.

'keysorting(+XS,+YS)   since release 4.3.1'
'keysorting(+XS,+YS,+OPTIONS)'

     where XS and YS are lists of tuples of domain variables.  Both
     lists should be of the same length N, and all tuples should have
     the same length M.  The constraint holds if the following are true:

        * PS is a permutation of [1,N].

        * FOR ALL I IN [1,N], J IN [1,M] : YS[I,J] = XS[PS[I],J].

        * [[YS[I,1],...,YS[I,K],PS[I]] | I IN [1,N]] is in lex ascending
          order, where K equals KEYS as defined below in the options.

     The filtering algorithm is based on [Mehlhorn 00] and endeavors to
     achieve bounds consistency, but does not guarantee it.

     Corresponds to Prolog's 'keysort/2'.  In particular, the sort is
     stable by definition.

     OPTIONS is a list of zero or more of the following:

     'keys(KEYS)'
          where KEYS should be a positive integer, denoting the length
          of the key prefix.  The default is 1.

     'permutation(PS)'
          where PS should be a list of length N of domain variables.
          Its meaning is described above.

   The following constraints express the fact that several vectors of
domain variables are in ascending lexicographic order:

'lex_chain(+VECTORS)'
'lex_chain(+VECTORS,+OPTIONS)'

     where VECTORS is a list of vectors (lists) of domain variables with
     finite bounds.  The constraint holds if VECTORS are in ascending
     lexicographic order.

     Corresponds to '*lex2/1', 'lex_greater*/2', 'lex_less*/2' in
     MiniZinc.

     OPTIONS is a list of zero or more of the following:

     'op(OP)'
          If OP is the atom '#=<' (the default), then the constraints
          holds if VECTORS are in non-descending lexicographic order.
          If OP is the atom '#<', then the constraints holds if VECTORS
          are in strictly ascending lexicographic order.

     'increasing'
          This option imposes the additional constraint that each vector
          in VECTORS be sorted in strictly ascending order.

     'among(LEAST,MOST,VALUES)'
          If given, then LEAST and MOST should be integers such that 0
          <= LEAST <= MOST and VALUES should be a list of distinct
          integers.  This option imposes the additional constraint on
          each vector in VECTORS that at least LEAST and at most MOST
          elements belong to VALUES.

     'global(BOOLEAN)   since release 4.2.1'
          if 'true', then a more expensive algorithm [Carlsson &
          Beldiceanu 02], which guaranteed domain consistency unless the
          'increasing/0' or 'among/3' options are given, will be used.

   In the following constraints, a _literal_ is either a term 'X' or a
term '#\ X', where 'X' is a 0/1 variable.  They maintain domain
consistency:

'bool_and(+LITS, +LIT)   since release 4.3'

     where LITS is a list of literals '[L0,...,Lj]' and LIT is a
     literal.  True if LIT equals the Boolean conjunction of LITS, and
     usually more efficient than the equivalent 'L0#/\...#/\Lj #<=>
     Lit'.

'bool_or(+LITS, +LIT)   since release 4.3'

     where LITS is a list of literals '[L0,...,Lj]' and LIT is a
     literal.  True if LIT equals the Boolean disjunction of LITS, and
     usually more efficient than the equivalent 'L0#\/...#\/Lj #<=>
     Lit'.

'bool_xor(+LITS, +LIT)   since release 4.3'

     where LITS is a list of literals '[L0,...,Lj]' and LIT is a
     literal.  True if LIT equals the Boolean exclusive or of LITS, and
     usually more efficient than the equivalent 'L0#\...#\Lj #<=> Lit'.

'bool_channel(+LITS, ?Y, +RELOP, +OFFSET)   since release 4.3'

     where LITS is a list of literals '[L0,...,Lj]', Y is a domain
     variable, RELOP is an arithmetic comparison as in *note Syntax of
     Arithmetic Expressions::, and OFFSET is an integer.  Expresses the
     constraint LI #<=> (Y RELOP I+OFFSET) for 'I in 0..j'.  Usually
     more efficient than a bunch of reified comparisons between a given
     variable and a sequence of integers.


File: sicstus.info,  Node: Extensional Constraints,  Next: Graph Constraints,  Prev: Arithmetic-Logical Constraints,  Up: Available Constraints

10.10.4.5 Extensional Constraints
.................................

'element(?X,+LIST,?Y)'

     where X and Y are domain variables and LIST is a list of domain
     variables.  True if the X:th element of LIST is Y.  Operationally,
     the domains of X and Y are constrained so that for every element in
     the domain of X, there is a compatible element in the domain of Y,
     and vice versa.

     Maintains domain consistency in X and bounds consistency in LIST
     and Y.  Corresponds to 'nth1/3' in 'library(lists)' and to
     'element/3' and 'member/2' in MiniZinc.

'relation(?X,+MAPLIST,?Y)   since release 4.0.5,deprecated'

     where X and Y are domain variables and MAPLIST is a list of
     'INTEGER-CONSTANTRANGE' pairs, where the integer keys occur
     uniquely (*note Syntax of Indexicals::).  True if MAPLIST contains
     a pair 'X-R' and Y is in the range denoted by R.  Maintains domain
     consistency.

     An arbitrary binary constraint can be defined with 'relation/3'.
     'relation/3' is implemented by straightforward transformation to
     the following, more general constraint, with which arbitrary
     relations can be defined compactly:

'table(+TUPLES,+EXTENSION)'
'table(+TUPLES,+EXTENSION,+OPTIONS)'

     Defines an N-ary constraint by extension.  EXTENSION should be a
     list of lists of integers, each of length N.  TUPLES should be a
     list of lists of domain variables, each also of length N.  The
     constraint holds if every TUPLE in TUPLES occurs in the EXTENSION.
     The constraint will maintain domain consistency.

     Corresponds to 'table/2' in MiniZinc.

     For convenience, EXTENSION may contain CONSTANTRANGE (*note Syntax
     of Indexicals::) expressions in addition to integers.

     OPTIONS is a list of zero or more of the following:

     'order(ORDER)   since release 4.1'
          Determines the variable order used internally.  The following
          values are valid:
          'leftmost'
               The order is the one given in the arguments (the
               default).
          'id3'
               Each tuple, and the columns of the extension, is permuted
               according to the heuristic that more discriminating
               columns should precede less discriminating ones.

     'method(METHOD)   since release 4.1'
          Controls the choice of internal data structure and algorithm.
          The following values are valid:
          'default   since release 4.4'
               SICStus choice handles propagation as it sees fit (the
               default).
          'noaux'
               SICStus handles propagation with the 'case/[3,4]'
               constraint, see below, converting the extension to a DAG.
          'aux'
               SICStus handles propagation with the 'case/[3,4]'
               constraint, see below.  Before converting the extension
               to a DAG, an auxiliary, first variable is introduced,
               denoting extension row number.

   'table/[2,3]' can be implemented in terms of the following, more
general constraint, which allows a compact representation of arbitrary
relations:

'case(+TEMPLATE, +TUPLES, +DAG)'
'case(+TEMPLATE, +TUPLES, +DAG, +OPTIONS)'

     This constraint encodes an N-ary constraint, defined by extension
     and/or linear inequalities.  It uses a DAG-shaped data structure
     where nodes corresponds to variables and every arc is labeled by an
     admissible interval for the node above it and optionally by linear
     inequalities.  The variable order is fixed: every path from the
     root node to a leaf node should visit every variable exactly once,
     in the order in which they occur lexically in TEMPLATE.  The
     constraint is true for a single ground tuple if there is a path
     from the root node to a leaf node such that (a) each tuple element
     is contained in the corresponding MIN..MAX interval on the path,
     and (b) any encountered linear inequalities along the path are
     true.  The constraint is true for a set of ground tuples if it is
     true for each tuple of the set.  The details are given below.

     TEMPLATE is a nonground Prolog term, each variable of which should
     occur exactly once.  Its variables are merely place-holders; they
     should not occur outside the constraint nor inside TUPLES.

     TUPLES is a list of terms of the same shape as TEMPLATE.  They
     should not share any variables with TEMPLATE.

     DAG is a list of "nodes" of the form 'node(ID,X,CHILDREN)', where X
     is a template variable, and ID should be an integer, uniquely
     identifying each node.  The first node in the list is the "root
     node".

     Nodes are either INTERNAL NODES or LEAF NODES.  For an internal
     node, CHILDREN is a list of terms '(MIN..MAX)-ID2' or
     '(MIN..MAX)-SIDECONSTRAINTS-ID2', where ID2 is the ID of a child
     node, MIN is an integer or the atom 'inf' (minus infinity), and MAX
     is an integer or the atom 'sup' (plus infinity).  For a leaf node,
     CHILDREN is a list of terms '(MIN..MAX)' or
     '(MIN..MAX)-SIDECONSTRAINTS'.

     SIDECONSTRAINTS is a list of side constraints of the form
     'scalar_product(COEFFS, XS, #=<, BOUND)', where COEFFS is a list of
     length K of integers, XS is a list of length K of template
     variables, and BOUND is an integer.

     Variables in TUPLES for which their template variable counterparts
     are constrained by side constraints, must have bounded domains.  In
     the absence of side constraint, the constraint maintains domain
     consistency.

     OPTIONS is a list of zero or more of the following:

     'scalar_product(COEFFS, XS, #=<, BOUND)   since release 4.2'
          A side constraint located at the root of the DAG.

     For example, recall that 'element(X,L,Y)' wakes up when the domain
     of X or the lower or upper bound of Y has changed, performs full
     pruning of X, but only prunes the bounds of Y.  The following two
     constraints:

          element(X, [1,1,1,1,2,2,2,2], Y),
          element(X, [10,10,20,20,10,10,30,30], Z)

     can be replaced by the following single constraint, which is
     equivalent declaratively, but which maintains domain consistency:

          elts(X, Y, Z) :-
              case(f(A,B,C), [f(X,Y,Z)],
                   [node(0, A,[(1..2)-1,(3..4)-2,(5..6)-3,(7..8)-4]),
                    node(1, B,[(1..1)-5]),
                    node(2, B,[(1..1)-6]),
                    node(3, B,[(2..2)-5]),
                    node(4, B,[(2..2)-7]),
                    node(5, C,[(10..10)]),
                    node(6, C,[(20..20)]),
                    node(7, C,[(30..30)])]).

     The DAG of the previous example has the following shape:


 [image src="images/clpfd1.png" text="" ]
                    DAG corresponding to 'elts/3'.

     A couple of sample queries:

          | ?- elts(X, Y, Z).
          X in 1..8,
          Y in 1..2,
          Z in {10}\/{20}\/{30}

          | ?- elts(X, Y, Z), Z #>= 15.
          X in(3..4)\/(7..8),
          Y in 1..2,
          Z in {20}\/{30}

          | ?- elts(X, Y, Z), Y = 1.
          Y = 1,
          X in 1..4,
          Z in {10}\/{20}


     As an example with side constraints, consider assigning tasks to
     machines with given unavailibility periods.  In this case, one can
     use a "calendar" constraint [CHIP 03, Beldiceanu, Carlsson & Rampon
     05] to link the real origins of the tasks (taking the
     unavailibility periods into account) with virtual origins of the
     tasks (not taking the unavailibility periods into account).  One
     can then state machine resource constraints using the virtual
     origins, and temporal constraints between the tasks using the real
     origins.

     Assume, for example, three machines with unavailibility periods
     given by the following table:

                     [image src="images/clpfd3.png" ]
              Unavailibility periods for three machines.

     Machine '1' is not available during (real) time periods '1-2' and
     '6-6', machine '2' is not available during (real) time periods
     '3-4' and '7-7', and machine '3' is always available.

     The following can then be used to express a calendar constraint for
     a given task scheduled on machine 'M in 1..3', with virtual origin
     'V in 1..8', and real origin 'R in 1..8':

          calendar(M, V, R) :-
                  M in 1..3,
                  V in 1..8,
                  R in 1..8,
                  smt((M#=1 #/\ V in 1..3 #/\ R#=V+2) #\/
                      (M#=1 #/\ V in 4..5 #/\ R#=V+3) #\/
                      (M#=2 #/\ V in 1..2 #/\ R#=V) #\/
                      (M#=2 #/\ V in 3..4 #/\ R#=V+2) #\/
                      (M#=2 #/\ V in 5..5 #/\ R#=V+3) #\/
                      (M#=3               #/\ R#=V)).

     or equivalently as:

          calendar(M, V, R) :-
              case(f(A,B,C),
                   [f(M,V,R)],
                   [node(0, A, [(1..1)-1, (2..2)-2, (3..3)-3]),
                    node(1, B, [(1..3)-[scalar_product([1,-1],[B,C],#=<,-2),
                                        scalar_product([1,-1],[C,B],#=<, 2)]-4,
                                (4..5)-[scalar_product([1,-1],[B,C],#=<,-3),
                                        scalar_product([1,-1],[C,B],#=<, 3)]-4]),
                    node(2, B, [(1..2)-[scalar_product([1,-1],[B,C],#=<, 0),
                                        scalar_product([1,-1],[C,B],#=<, 0)]-4,
                                (3..4)-[scalar_product([1,-1],[B,C],#=<,-2),
                                        scalar_product([1,-1],[C,B],#=<, 2)]-4,
                                (5..5)-[scalar_product([1,-1],[B,C],#=<,-3),
                                        scalar_product([1,-1],[C,B],#=<, 3)]-4]),
                    node(3, B, [(1..8)-[scalar_product([1,-1],[B,C],#=<, 0),
                                        scalar_product([1,-1],[C,B],#=<, 0)]-4]),
                    node(4, C, [(1..8)])]).

     Note that equality must be modeled as the conjunction of
     inequalities, as only constraints of the form
     'scalar_product(+COEFFS, +XS, #=<, +BOUND)' are allowed as side
     constraints.

     The DAG of the calendar constraint has the following shape:


 [image src="images/clpfd2.png" ]
                  DAG corresponding to 'calendar/3'.

     A couple of sample queries:

          | ?- M in 1..3, V in 1..8, R in 1..8,
               calendar(M, V, R).
          M in 1..3,
          V in 1..8,
          R in 1..8

          | ?- M in 1..3, V in 1..8, R in 1..8,
               calendar(M, V, R), M #= 1.
          M = 1,
          V in 1..5,
          R in 1..8

          | ?- M in 1..3, V in 1..8, R in 1..8,
               calendar(M, V, R), M #= 2, V #> 4.
          M = 2,
          V = 5,
          R = 8



File: sicstus.info,  Node: Graph Constraints,  Next: Scheduling Constraints,  Prev: Extensional Constraints,  Up: Available Constraints

10.10.4.6 Graph Constraints
...........................

The following constraint can be thought of as constraining N nodes in a
graph to form a Hamiltonian circuit.  The nodes are numbered from 1 to
N.  The circuit starts in node 1, visits each node, and returns to the
origin.

'circuit(+SUCC)'
'circuit(+SUCC, +PRED)'

     where SUCC is a list of length N of domain variables.  The I:th
     element of SUCC (PRED) is the successor (predecessor) of I in the
     graph.  True if the values form a Hamiltonian circuit.

     Corresponds to 'circuit/1' in MiniZinc.


File: sicstus.info,  Node: Scheduling Constraints,  Next: Placement Constraints,  Prev: Graph Constraints,  Up: Available Constraints

10.10.4.7 Scheduling Constraints
................................

The following constraint can be thought of as constraining N tasks so
that the total resource consumption does not exceed a given limit at any
time.  *API change wrt. release 3:*

'cumulative(+TASKS)'
'cumulative(+TASKS,+OPTIONS)'

     A task is represented by a term 'task(OI,DI,EI,HI,TI)' where OI is
     the start time, DI the non-negative duration, EI the end time, HI
     the non-negative resource consumption, and TI the task identifier.
     All fields are domain variables with bounded domains.

     Let N be the number of tasks and L the global resource limit (by
     default 1, but see below), and:

          HIJ = HI, if OI <= J < OI+DI
          HIJ = 0 otherwise

     The constraint holds if:

       1. For every task I, OI+DI=EI, and
       2. For all instants J, H1J+...+HNJ <= L.

     Corresponds to 'cumulative/4' in MiniZinc.  If all durations are 1,
     then it corresponds to 'bin_packing/3' in MiniZinc.

     OPTIONS is a list of zero or more of the following, where BOOLEAN
     must be 'true' or 'false' ('false' is the default).

     'limit(L)'
          See above.

     'precedences(PS)'
          PS encodes a set of precedence constraints to apply to the
          tasks.  PS should be a list of terms of the form:

               'TI-TJ #= DIJ'

          where TI and TJ should be task identifiers, and DIJ should be
          a a domain variable, denoting:

               OI-OJ = DIJ

     'global(BOOLEAN)'
          if 'true', then a more expensive algorithm will be used in
          order to achieve tighter pruning of the bounds of the
          parameters.

     This constraint is due to Aggoun and Beldiceanu [Aggoun &
     Beldiceanu 93].

   The following constraint can be thought of as constraining N tasks to
be placed in time and on M machines.  Each machine has a resource limit,
which is interpreted as a lower or upper bound on the total amount of
resource used on that machine at any point in time that intersects with
some task.

'cumulatives(+TASKS,+MACHINES)'
'cumulatives(+TASKS,+MACHINES,+OPTIONS)'

     A task is represented by a term 'task(OI,DI,EI,HI,MI)' where OI is
     the start time, DI the non-negative duration, EI the end time, HI
     the resource consumption (if positive) or production (if negative),
     and MI a machine identifier.  All fields are domain variables with
     bounded domains.

     A machine is represented by a term 'machine(MJ,LJ)' where MJ is the
     identifier, an integer; and LJ is the resource bound of the
     machine, which must be a domain variable with bounded domains.

     Let there be N tasks and:

          HIJM = HI, if MI=M and OI <= J < OI+DI
          HIJM = 0 otherwise

     If the resource bound is 'lower' (the default), then the constraint
     holds if:

       1. For every task I, SI+DI=EI, and
       2. For all machines M and instants J such that there exists a
          task I where MI=M and OI <= J < OI+DI, H1JM+...+HNJM >= LM.

     If the resource bound is 'upper', then the constraint holds if:

       1. For every task I, SI+DI=EI, and
       2. For all machines M and instants J, H1JM+...+HNJM <= LM.

     OPTIONS is a list of zero or more of the following, where BOOLEAN
     must be 'true' or 'false' ('false' is the default):

     'bound(B)'
          If 'lower' (the default), then each resource limit is treated
          as a lower bound.  If 'upper', then each resource limit is
          treated as an upper bound.

     'prune(P)'
          If 'all' (the default), then the constraint will try to prune
          as many variables as possible.  If 'next', then only variables
          that occur in the first nonground task term (wrt. the order
          given when the constraint was posted) can be pruned.

     'generalization(BOOLEAN)'
          If 'true', then extra reasoning based on assumptions on
          machine assignment will be done to infer more.

     'task_intervals(BOOLEAN)'
          If 'true', then extra global reasoning will be performed in an
          attempt to infer more.

   The following constraint is a generalization of 'cumulative/[1,2]' in
the following sense:

   * The new constraint deals with the consumption of multiple resources
     simultaneously, not just a single resource.  For the constraint to
     succeed, none of the resources can exceed its limit.

   * Resources can be of two kinds:
     _cumulative_
          This is the kind of resource that 'cumulative/[1,2]' deals
          with: at no point in time can the total resource use exceed
          the limit.

     _colored_
          For this kind of resource, each task specifies not a resource
          use, but a color, encoded as an integer.  At no point in time
          can the total number of distinct colors in use exceed the
          limit.  The color code 0 is treated specially: it denotes that
          the task does not have any color.

   On the other hand, the new constraint has the limitation that all
fields and parameters except start and end times must be given as
integers:

'multi_cumulative(+TASKS,+CAPACITIES)   since release 4.3.1'
'multi_cumulative(+TASKS,+CAPACITIES,+OPTIONS)   since release 4.3.1'

     A task is represented by a term 'task(OI,DI,EI,HSI,TI)' where OI is
     the start time, DI the non-negative duration, EI the end time, HSI
     the list of non-negative resource uses or colors, and TI the task
     identifier.  The start and end times should be domain variables
     with bounded domains.  The other fields should be integers.

     The capacities should be a list of terms of the following form,
     where LIMIT should be a non-negative integer.  CAPACITIES and all
     the HSI should be of the same length:

     'cumulative(LIMIT)'
          denotes a cumulative resource.

     'colored(LIMIT)'
          denotes a colored resource.

     OPTIONS is a list of zero or more of the following:

     'greedy(FLAG)'
          If given, then FLAG is a domain variable in '0..1'.  If FLAG
          equals 1, either initially or by binding FLAG during search,
          then the constraint switches behavior into greedy assignment
          mode.  The greedy assignment will either succeed and assign
          all start and end times to values that satisfy the constraint,
          or merely fail.  FLAG is never bound by the constraint; its
          sole function is to control the behavior of the constraint.

     'precedences(PS)'
          PS encodes a set of precedence constraints to apply to the
          tasks.  PS should be a list of pairs 'TI-TJ' where TI and TJ
          should be task identifiers, denoting that task TI must
          complete before task TJ can start.

     This constraint is due to [Letort, Beldiceanu & Carlsson 14].


File: sicstus.info,  Node: Placement Constraints,  Next: Automata Constraints,  Prev: Scheduling Constraints,  Up: Available Constraints

10.10.4.8 Placement Constraints
...............................

'disjoint1(+LINES)'
'disjoint1(+LINES,+OPTIONS)'

     constrains a set of lines to be non-overlapping.  LINES is a list
     of terms F(SJ,DJ) or F(SJ,DJ,TJ), SJ and DJ are domain variables
     with finite bounds denoting the origin and length of line J
     respectively, F is any functor, and the optional TJ is an atomic
     term denoting the type of the line.  TJ defaults to 0 (zero).

     OPTIONS is a list of zero or more of the following, where BOOLEAN
     must be 'true' or 'false' ('false' is the default):

     'global(BOOLEAN)'
          if 'true', then a redundant algorithm using global reasoning
          is used to achieve more complete pruning.

     'wrap(MIN,MAX)'
          If used, then the space in which the lines are placed should
          be thought of as a circle where positions MIN and MAX
          coincide, where MIN and MAX should be integers.  That is, the
          space wraps around.  Furthermore, this option forces the
          domains of the origin variables to be inside [MIN,MAX-1].

     'margin(T1,T2,D)'
          This option imposes a minimal distance D between the end point
          of any line of type T1 and the origin of any line of type T2.
          D should be a positive integer or 'sup'.  If 'sup' is used,
          then all lines of type T2 must be placed before any line of
          type T1.

          This option interacts with the 'wrap/2' option in the sense
          that distances are counted with possible wrap-around, and the
          distance between any end point and origin is always finite.

     The file 'library('clpfd/examples/bridge.pl')' contains an example
     where 'disjoint1/2' is used for scheduling non-overlapping tasks.

'disjoint2(+RECTANGLES)'
'disjoint2(+RECTANGLES,+OPTIONS)'

     constrains a set of rectangles to be non-overlapping.  RECTANGLES
     is a list of terms F(XJ,LJ,YJ,HJ) or F(XJ,LJ,YJ,HJ,TJ), XJ and LJ
     are domain variables with finite bounds denoting the origin and
     size of rectangle J in the X dimension, YJ and HJ are the values
     for the Y dimension, F is any functor, and the optional TJ is an
     atomic term denoting the type of the rectangle.  TJ defaults to 0
     (zero).

     Corresponds to 'diffn/4' in MiniZinc.

     OPTIONS is a list of zero or more of the following, where BOOLEAN
     must be 'true' or 'false' ('false' is the default):

     'global(BOOLEAN)'
          If 'true', then a redundant algorithm using global reasoning
          is used to achieve more complete pruning.

     'wrap(MIN1,MAX1,MIN2,MAX2)'
          MIN1 and MAX1 should be either integers or the atoms 'inf' and
          'sup' respectively.  If they are integers, then the space in
          which the rectangles are placed should be thought of as a
          cylinder wrapping around the X dimension where positions MIN1
          and MAX1 coincide.  Furthermore, this option forces the
          domains of the XJ variables to be inside [MIN1,MAX1-1].

          MIN2 and MAX2 should be either integers or the atoms 'inf' and
          'sup' respectively.  If they are integers, then the space in
          which the rectangles are placed should be thought of as a
          cylinder wrapping around the Y dimension where positions MIN2
          and MAX2 coincide.  Furthermore, this option forces the
          domains of the YJ variables to be inside [MIN2,MAX2-1].

          If all four are integers, then the space is a toroid wrapping
          around both dimensions.

     'margin(T1,T2,D1,D2)'
          This option imposes minimal distances D1 in the X dimension
          and D2 in the Y dimension between the end point of any
          rectangle of type T1 and the origin of any rectangle of type
          T2.  D1 and D2 should be positive integers or 'sup'.  If 'sup'
          is used, then all rectangles of type T2 must be placed before
          any rectangle of type T1 in the relevant dimension.

          This option interacts with the 'wrap/4' option in the sense
          that distances are counted with possible wrap-around, and the
          distance between any end point and origin is always finite.

     'synchronization(BOOLEAN)'
          Let the "assignment dimension" and the "temporal dimension"
          denote the two dimensions, no matter which is the X and which
          is the Y dimension.  If BOOLEAN is 'true', then a redundant
          algorithm is used to achieve more complete pruning for the
          following case:

             * All rectangles have size 1 in the assignment dimension.

             * Some rectangles have the same origin and size in the
               temporal dimension, and that origin is not yet fixed.

          The following example shows an artificial placement problem
          involving 25 rectangles including four groups of rectangles
          whose left and right borders must be aligned.  If 'Synch' is
          'true', then it can be solved with first-fail labeling in 23
          backtracks.  If 'Synch' is 'false', then 60 million backtracks
          do not suffice to solve it.

               ex([O1,Y1a,Y1b,Y1c,
                   O2,Y2a,Y2b,Y2c,Y2d,
                   O3,Y3a,Y3b,Y3c,Y3d,
                   O4,Y4a,Y4b,Y4c],
                  Synch) :-
                       domain([Y1a,Y1b,Y1c,
                               Y2a,Y2b,Y2c,Y2d,
                               Y3a,Y3b,Y3c,Y3d,
                               Y4a,Y4b,Y4c], 1, 5),
                       O1 in 1..28,
                       O2 in 1..26,
                       O3 in 1..22,
                       O4 in 1..25,
                       disjoint2([t(1,1,5,1),    t(20,4,5,1),
                                  t(1,1,4,1),    t(14,4,4,1),
                                  t(1,2,3,1),    t(24,2,3,1),
                                  t(1,2,2,1),    t(21,1,2,1),
                                  t(1,3,1,1),    t(14,2,1,1),
                                  t(O1,3,Y1a,1),
                                  t(O1,3,Y1b,1),
                                  t(O1,3,Y1c,1),
                                  t(O2,5,Y2a,1),
                                  t(O2,5,Y2b,1),
                                  t(O2,5,Y2c,1),
                                  t(O2,5,Y2d,1),
                                  t(O3,9,Y3a,1),
                                  t(O3,9,Y3b,1),
                                  t(O3,9,Y3c,1),
                                  t(O3,9,Y3d,1),
                                  t(O4,6,Y4a,1),
                                  t(O4,6,Y4b,1),
                                  t(O4,6,Y4c,1)],
                                 [synchronization(Synch)]).

'bin_packing(+ITEMS,+BINS)   since release 4.4'

     constrains the placement of items of given size in bins of given
     capacity, so that the total load of any bin matches its capacity.

     ITEMS is a list of terms of the form 'item(BIN,SIZE)' where BIN is
     a domain variable denoting the bin where the item should be placed,
     and SIZE is an integer >= 0 denoting its size.

     BINS is a list of terms of the form 'bin(ID,CAP)' where ID is an
     integer identifying the bin, and CAP is a domain variable denoting
     is its capacity.  The ID values should be all different.

     The constraint holds if every BIN equals one of the ID values, and
     for every bin 'bin(ID,CAP)', the total size of the items assigned
     to it equals CAP.

'geost(+OBJECTS,+SHAPES)   since release 4.1'
'geost(+OBJECTS,+SHAPES,+OPTIONS)   since release 4.1'
'geost(+OBJECTS,+SHAPES,+OPTIONS,+RULES)   since release 4.1'

     constrains the location in space of non-overlapping
     multi-dimensional OBJECTS, each of which taking a shape among a set
     of SHAPES.

     Each shape is defined as a finite set of "shifted boxes", where
     each shifted box is described by a box in a K-dimensional space at
     the given offset with the given sizes.  A shifted box is described
     by a ground term 'sbox(SID,OFFSET,SIZE)' where SID, an integer, is
     the shape id; OFFSET, a list of K integers, denotes the offset of
     the shifted box from the origin of the object; and SIZE, a list of
     K integers greater than zero, denotes the size of the shifted box.
     Then, a "shape" is a collection of shifted boxes all sharing the
     same shape id.  The shifted boxes associated with a given shape
     must not overlap.  SHAPES is thus the list of such 'sbox/3' terms.

     Each object is described by a term 'object(OID,SID,ORIGIN' where
     OID, an integer, is the unique object id; SID, a domain variable,
     is the shape id; and ORIGIN, a list of domain variables, is the
     origin coordinate of the object.  If SID is nonground, then the
     object is said to be "polymorphic".  The possible values for SID
     are the shape ids that occur in SHAPES.  OBJECTS is thus the list
     of such 'object/3' terms.

     If given, then OPTIONS is a list of zero or more of the following,
     where BOOLEAN must be 'true' or 'false' ('false' is the default):

     'lex(LISTOFOID)'
          where LISTOFOID should be a list of distinct object ids,
          denotes that the origin vectors of the objects according to
          LISTOFOID should be in ascending lexicographic order.
          Multiple 'lex/1' options can be given, but should mention
          disjoint sets of objects.

     'cumulative(BOOLEAN)'
          If 'true', then redundant reasoning methods are enabled, based
          on projecting the objects onto each dimension.

     'disjunctive(BOOLEAN)'
          If 'true', then cliques of objects are detected that clash in
          one dimension and so must be separated in the other dimension.
          This method only applies in the 2D case.

     'longest_hole(VALUE,MAXBACKS)'
          This method only applies in the 2D case and in the absence of
          polymorphic objects.  VALUE can be 'all', 'true' or 'false'.
          If 'true', then the filtering algorithm computes and uses
          information about holes that can be tolerated without
          necessarily failing the constraint.  If 'all',then more
          precise information is computed.  If 'false', then no such
          information is computed.  MAXBACKS should be an integer '>=
          -1' and gives a bound on the effort spent tightening the
          longest hole information.  Experiments suggest that 1000 may
          be a reasonable compromise value.

     'parconflict(BOOLEAN)'
          If 'true', then redundant reasoning methods are enabled, based
          on computing the number of items that can be put in parallel
          in the different dimensions.

     'visavis_init(BOOLEAN)'
          If 'true', then a redundant method is enabled that statically
          detects placements that would cause too large holes.  This
          method can be quite effective.

     'visavis_floating(BOOLEAN)'
          If 'true', then a redundant method is enabled that dynamically
          detects placements that would cause too large holes.  It is
          more general than the following option, but only applies in
          the 2D case and in the absence of polymorphic objects.  This
          method has been shown to pay off only in rare cases.

     'visavis(BOOLEAN)'
          If 'true', then a redundant method is enabled that dynamically
          detects placements that would cause too large holes.  This
          method has not been shown to pay off experimentally.

     'corners(BOOLEAN)'
          If 'true', then a redundant method is enabled that reasons in
          terms on borders that impinge on the corners of objects.  This
          method only applies in the 2D case.  It has not been shown to
          pay off experimentally.

     'task_intervals(BOOLEAN)'
          If 'true', then a redundant reasoning method is enabled that
          detects overcrowded and undercrowded regions of the placement
          space.  This method has not been shown to pay off
          experimentally.

     'dynamic_programming(BOOLEAN)'
          If 'true', then a redundant reasoning method is enabled that
          solves a 2D knapsack problem for every two adjacent columns of
          the projection of the objects onto each dimension.  This
          method has pseudo-polynomial complexity but can be quite
          powerful.

     'polymorphism(BOOLEAN)'
          If 'true', then a reasoning method is enabled that is relevant
          in the context of polymorphic objects and no slack.  The
          method detects parts of the placement space that cannot be
          filled and thus fails the constraint.  This method has not
          been shown to pay off experimentally.

     'pallet_loading(BOOLEAN)'
          If 'true', and if all objects consist of a single shifted box
          of the same shape, modulo rotations, then a redundant method
          is enabled that recognizes necessary conditions for this
          special case.

     'overlap(BOOLEAN)'
          If 'true', then the constraint that objects be non-overlapping
          is lifted.  This option is useful mainly in conjunction with
          the RULES argument, in case the placement of objects should be
          restricted by the RULES only.

     'volume(TOTAL)'
          If given, then TOTAL is constrained to be the total volume of
          OBJECTS.

     'bounding_box(LOWER,UPPER)'
          LOWER=[L1,...,LK] and UPPER=[U1,...,UK] should be lists of
          domain variables.  The following conditions are imposed:
             * For every point P = [P1,...,PK] occupied by an object, L1
               <= P1 < U1, ..., LK <= PK < UK.
             * For every J in 1..K, there exists a point P =
               [P1,...,PJ,...,PK] occupied by an object such that PJ=LJ.
             * For every J in 1..K, there exists a point P =
               [P1,...,PJ,...,PK] occupied by an object such that
               PJ=UJ-1.

     'fixall(FLAG,PATTERNS)'
          If given, then FLAG is a domain variable in '0..1'.  If FLAG
          equals 1, then either initially or by binding FLAG during
          search, the constraint switches behavior into greedy
          assignment mode.  The greedy assignment will either succeed
          and assign all shape ids and origin coordinates to values that
          satisfy the constraint, or merely fail.  FLAG is never bound
          by the constraint; its sole function is to control the
          behavior of the constraint.

          Greedy assignment is done one object at a time, in the order
          of OBJECTS.  The assignment per object is controlled by
          PATTERNS, which should be a list of one or more pattern terms
          of the form 'object(_,SidSpec,OriginSpec)', where SIDSPEC is a
          term 'min(I)' or 'max(I)', ORIGINSPEC is a list of K such
          terms, and I is a unique integer between 1 and K+1.

          The meaning of the pattern is as follows.  The variable in the
          position of 'min(1)' or 'max(1)' is fixed first; the variable
          in the position of 'min(2)' or 'max(2)' is fixed second; and
          so on.  'min(I)' means trying values in ascending order;
          'max(I)' means descending order.

          If PATTERNS contains M pattern, then object 1 is fixed
          according to pattern 1, ..., object M is fixed according to
          pattern M, object M+1 is fixed according to pattern 1, and so
          on.  For example, suppose that the following option is given:

               fixall(F, [object(_,min(1),[min(3),max(2)]),
                          object(_,max(1),[min(2),max(3)])])

          Then, if the program binds 'F' to 1, then the constraint
          enters greedy assignment mode and endeavors to fix all objects
          as follows.

             * For object 1, 3, ..., (a) the shape is fixed to the
               smallest possible value, (b) the Y coordinate is fixed to
               the largest possible value, (c) the X coordinate is fixed
               to the smallest possible value.
             * For object 2, 4, ..., (a) the shape is fixed to the
               largest possible value, (b) the X coordinate is fixed to
               the smallest possible value, (c) the Y coordinate is
               fixed to the largest possible value.

     If given, then RULES is a list of zero or more terms of the form
     shown below, and impose extra constraints on the placement of the
     objects.  For the time being, the details are described in
     [Carlsson, Beldiceanu & Martin 08].  *Please note:* the rules
     require that all shapes of a polymorphic objects consist of the
     same number of shifted boxes.  For example, 'Shapes =
     [sbox(1,[0,0],[3,1]),sbox(1,[0,1],[2,4]),sbox(2,[0,0],[3,1])]' will
     not work.

     SENTENCE       ::=            MACRO | FOL
     MACRO          ::=            HEAD '--->'
                                   BODY
     HEAD           ::=            TERM           { to be substituted
                                                  by a BODY }
     BODY           ::=            TERM           { to substitute for
                                                  a HEAD }
     FOL            ::=            '#\' FOL       { negation }
                    |              FOL '#/\'      { conjunction }
                                   FOL
                    |              FOL '#\/'      { disjunction }
                                   FOL
                    |              FOL '#=>'      { implication }
                                   FOL
                    |              FOL '#<=>'     { equivalence }
                                   FOL
                    |              'exists(VAR,COLLECTION,FOL)'{ existential
                                                  quantification }
                    |              'forall(VAR,COLLECTION,FOL)'{ universal
                                                  quantification }
                    |              'card(VAR,COLLECTION,INTEGER,INTEGER,FOL)'{ cardinality }
                    |              'true'
                    |              'false'
                    |              EXPR RELOP     { rational
                                   EXPR           arithmetic }
                    |              HEAD           { macro application
                                                  }
     EXPR           ::=            EXPR '+'
                                   EXPR
                    |              '-' EXPR
                    |              EXPR '-'
                                   EXPR
                    |              'min(EXPR,EXPR)'
                    |              'max(EXPR,EXPR)'
                    |              EXPR '*'
                                   GROUNDEXPR
                    |              GROUNDEXPR
                                   '*' EXPR
                    |              EXPR '/'
                                   GROUNDEXPR
                    |              ATTREF
                    |              INTEGER
                    |              'fold(VAR,COLLECTION,FOP,EXPR,EXPR)'
                    |              VARIABLE       { quantified
                                                  variable }
                    |              HEAD           { macro application
                                                  }
     GROUNDEXPR     ::=            EXPR           { where EXPR is
                                                  ground }
     ATTREF         ::=            ENTITY '^'
                                   ATTR
     ATTR           ::=            TERM           { attribute name }
                    |              VARIABLE       { quantified
                                                  variable }
     RELOP          ::=            '#<' | '#='
                                   | '#>' |
                                   '#\=' |
                                   '#=<' |
                                   '#>='
     FOP            ::=            '+' | 'min'
                                   | 'max'
     COLLECTION     ::=            LIST
                    |              'objects(LIST)'{ list of oids }
                    |              'sboxes(LIST)' { list of sids }

     The following example shows 'geost/2' modeling three
     non-overlapping objects.  The first object has four possible
     shapes, and the other two have two possible shapes each.

          | ?- domain([X1,X2,X3,Y1,Y2,Y3], 1, 4),
               S1 in 1..4,
               S2 in 5..6,
               S3 in 7..8,
               geost([object(1,S1,[X1,Y1]), 
                      object(2,S2,[X2,Y2]),
                      object(3,S3,[X3,Y3])],
                     [sbox(1,[0,0],[2,1]), 
                      sbox(1,[0,1],[1,2]), 
                      sbox(1,[1,2],[3,1]),
                      sbox(2,[0,0],[3,1]), 
                      sbox(2,[0,1],[1,3]), 
                      sbox(2,[2,1],[1,1]),
                      sbox(3,[0,0],[2,1]), 
                      sbox(3,[1,1],[1,2]), 
                      sbox(3,[-2,2],[3,1]),
                      sbox(4,[0,0],[3,1]), 
                      sbox(4,[0,1],[1,1]), 
                      sbox(4,[2,1],[1,3]),
                      sbox(5,[0,0],[2,1]), 
                      sbox(5,[1,1],[1,1]), 
                      sbox(5,[0,2],[2,1]),
                      sbox(6,[0,0],[3,1]), 
                      sbox(6,[0,1],[1,1]), 
                      sbox(6,[2,1],[1,1]),
                      sbox(7,[0,0],[3,2]), 
                      sbox(8,[0,0],[2,3])]).

     The shapes are illustrated in the following picture:


 [image src="images/geost1a.png" text="" ]
               'geost/2': three objects and eight shapes

     A ground solution is shown in the following picture:


 [image src="images/geost1b.png" text="" ]
                     'geost/2': a ground solution

     The following example shows how to encode in RULES "objects with
     oid 1, 2 and 3 must all be at least 2 units apart from objects with
     oid 4, 5 and 6".

          [ (origin(O1,S1,D) ---> O1^x(D)+S1^t(D)),

            (end(O1,S1,D) ---> O1^x(D)+S1^t(D)+S1^l(D)),

            (tooclose(O1,O2,S1,S2,D) --->
                end(O1,S1,D)+2 #> origin(O2,S2,D) #/\
                end(O2,S2,D)+2 #> origin(O1,S1,D)),

            (apart(O1,O2) --->
                forall(S1,sboxes([O1^sid]),
                    forall(S2,sboxes([O2^sid]),
                        #\ tooclose(O1,O2,S1,S2,1) #\/
                        #\ tooclose(O1,O2,S1,S2,2)))),

            (forall(O1,objects([1,2,3]),
                forall(O2,objects([4,5,6]), apart(O1,O2))))].

     The following example shows how to encode in RULES "objects 3 and 7
     model rooms that must be adjacent and have a common border at least
     1 unit long".

          [ (origin(O1,S1,D) ---> O1^x(D)+S1^t(D)),

            (end(O1,S1,D) ---> O1^x(D)+S1^t(D)+S1^l(D)),

            (overlap(O1,S1,O2,S2,D) --->
                end(O1,S1,D) #> origin(O2,S2,D) #/\
                end(O2,S2,D) #> origin(O1,S1,D)),

            (abut(O1,O2) --->
                forall(S1,sboxes([O1^sid]),
                    forall(S2,sboxes([O2^sid]),
                        ((origin(O1,S1,1) #= end(O2,S2,1) #\/
                          origin(O2,S2,1) #= end(O1,S1,1)) #/\
                         overlap(O1,S1,O2,S2,2)) #\/
                        ((origin(O1,S1,2) #= end(O2,S2,2) #\/
                          origin(O2,S2,2) #= end(O1,S1,2)) #/\
                         overlap(O1,S1,O2,S2,1))))),

            (forall(O1,objects([3]),
                forall(O2,objects([7]), abut(O1,O2))))].


File: sicstus.info,  Node: Automata Constraints,  Next: User-Defined Constraints,  Prev: Placement Constraints,  Up: Available Constraints

10.10.4.9 Automata Constraints
..............................

The following constraint provides a general way of defining any
constraint involving sequences whose "checker", i.e. a procedure that
classifies ground instances as solutions or non-solutions, can be
expressed by a finite automaton, deterministic or nondeterministic,
extended with counter operations on its arcs.  The point is that it is
very much easier to come up with such a checker than to come up with a
filtering algorithm for the constraint of interest.  In the absence of
counters, it maintains domain consistency.

   Corresponds to 'regular/6' in MiniZinc.

'automaton(SIGNATURE, SOURCESSINKS, ARCS)   since release 4.1'
'automaton(SEQUENCE, TEMPLATE, SIGNATURE, SOURCESSINKS, ARCS, COUNTERS, INITIAL, FINAL)'
'automaton(SEQUENCE, TEMPLATE, SIGNATURE, SOURCESSINKS, ARCS, COUNTERS, INITIAL, FINAL, OPTIONS)   since release 4.1'

     The arguments are described below in terms of their abstract
     syntax:

     SEQUENCE
          The sequence of terms of interest; abstract grammar category
          SEQUENCE.

     TEMPLATE
          A template for an item of the sequence; abstract grammar
          category TEMPLATE.  Only relevant if some state transition
          involving counter arithmetic mentions a variable occurring in
          TEMPLATE, in which case the corresponding term in a sequence
          element will be accessed.

     SIGNATURE
          The "signature" of SEQUENCE; abstract grammar category
          SIGNATURE.  The automaton is not driven by SEQUENCE itself,
          but by SIGNATURE, which ranges over some alphabet, implicitly
          defined by the values used by ARCS.  In addition to
          'automaton/[8,9]', you must call a constraint that maps
          SEQUENCE to SIGNATURE.

     SOURCESSINKS
          The source and sink nodes of the automaton; abstract grammar
          category SOURCESSINKS.

     ARCS
          The arcs (transitions) of the automaton; abstract grammar
          category ARCS.  Any transition not mentioned is assumed to go
          to an implicit failure node.  An arc optionally contains
          expressions for updated counter values; by default, the
          counters remain unchanged.  Conditional updates can be
          specified.

     COUNTERS
          A list of variables, local to the constraint; abstract grammar
          category COUNTERS.

     INITIAL
          A list of initial values, usually instantiated; abstract
          grammar category INITIAL.

     FINAL
          A list of final values, usually uninstantiated; abstract
          grammar category FINAL.

     OPTIONS
          Abstract grammar category OPTIONS; a list of zero or more of
          the following terms.  All but the last option are implemented
          by adding auxiliary counters to the automaton including the
          necessary updates in the arcs:

          'valueprec(FIRST,LATER,N)   since release 4.1.3'
               N is unified with N, computed such that: if the value
               LATER occurs in the SIGNATURE, then FIRST occurs N times
               before the first occurrence of LATER, otherwise N=0.

          'anystretchocc(N)   since release 4.1.3'
               N is unified with the number of (nonempty) stretches of
               any single value in the SIGNATURE.

          'stretchocc(VALUEPAT,N)   since release 4.1.3'
               N is unified with the number of stretches of values
               matching VALUEPAT (abstract grammar category VALUEPAT) in
               the SIGNATURE.

          'stretchoccmod(VALUEPAT,MOD,N)   since release 4.1.3'
               N is unified with the number (modulo MOD) of stretches of
               values matching VALUEPAT (abstract grammar category
               VALUEPAT) the SIGNATURE.

          'stretchmaxlen(VALUEPAT,N)   since release 4.1.3'
               N is unified with N, computed such that: if values
               matching VALUEPAT (abstract grammar category VALUEPAT)
               occur the SIGNATURE, then N is the length of the longest
               such stretch, otherwise N=0.

          'stretchminlen(VALUEPAT,N)   since release 4.1.3'
               N is unified with N, computed such that: if values
               matching VALUEPAT (abstract grammar category VALUEPAT)
               occur the SIGNATURE, then N is the length of the shortest
               such stretch, otherwise N is a large integer.

          'wordocc(WORDPAT,N)   since release 4.1.3'
               N is unified with the number of words matching WORDPAT
               (abstract grammar category WORDPAT) in the SIGNATURE.

          'wordoccmod(WORDPAT,MOD,N)   since release 4.1.3'
               N is unified with the number (modulo MOD) of words
               matching WORDPAT (abstract grammar category WORDPAT) in
               the SIGNATURE.

          'wordprefix(WORDPAT,ZO)   since release 4.1.3'
               If the prefix of the SIGNATURE matches WORDPAT (abstract
               grammar category WORDPAT), then ZO is unified with 1,
               otherwise with 0.

          'wordsuffix(WORDPAT,ZO)   since release 4.1.3'
               If the suffix of the SIGNATURE matches WORDPAT (abstract
               grammar category WORDPAT), then ZO is unified with 1,
               otherwise with 0.

          'state(MAP,STATESEQUENCE)   since release 4.1'
               For a signature of length K, the constraint is
               implemented by decomposition into K smaller constraints
               mapping an old state to a new state.  The states are
               represented as domain variables.  STATESEQUENCE forms the
               list of these K+1 domain variables, starting with the
               initial state and ending with the final state.  MAP gives
               the interpretation of their values: it is a list of pairs
               NODE-VALUE such that if the nth state variable SN equals
               VALUE, then the automaton is in state NODE having read N
               symbols.

          'counterseq(COUNTERSEQUENCE)   since release 4.2.1'
               Similarly to the list of states, COUNTERSEQUENCE forms
               the list of the K+1 instances of COUNTERS, beginning with
               INITIAL and ending with FINAL.

     Abstract syntax:

     SEQUENCE       ::= LIST OF TEMPLATE          {all of which of the same
                                                  shape}
     TEMPLATE       ::= TERM                      {most general shape of the
                                                  SEQUENCE}
                                                  {its variables should be
                                                  local to the constraint}
     SIGNATURE      ::= LIST OF VARIABLE
     SOURCESSINKS   ::= LIST OF NODESPEC
     NODESPEC       ::= 'source(NODE)'            {an initial state}
                    | 'sink(NODE)'                {an accept state}
     NODE           ::= TERM
     ARCS           ::= LIST OF ARC
     ARC            ::=                           {from node, integer, to
                    'arc(NODE,INTEGER,NODE)'      node}
                    |                             {EXPRS correspond to new
                    'arc(NODE,INTEGER,NODE,EXPRS)'counter values}
                    |
                    'arc(NODE,INTEGER,NODE,CONDITIONAL)'
     CONDITIONAL    ::= (COND -> EXPRS)
                    | (CONDITIONAL ;
                    CONDITIONAL)
     EXPRS          ::= LIST OF EXPR              {of same length as
                                                  COUNTERS}
                                                  {EXPR as defined in *note
                                                  Syntax of Arithmetic
                                                  Expressions::}
                                                  {over COUNTERS, TEMPLATE
                                                  and constants}
                                                  {variables occurring in
                                                  COUNTERS correspond to old
                                                  counter values}
                                                  {variables occurring in
                                                  TEMPLATE refer to the
                                                  current element of
                                                  SEQUENCE}
     COND           ::= CONSTRAINT                {over COUNTERS, TEMPLATE
                                                  and constants}
                                                  {must be reifiable or
                                                  'true'}
     COUNTERS       ::= LIST OF VARIABLE          {should be local to the
                                                  constraint}
     INITIAL        ::= LIST OF DVAR              {of same length as
                                                  COUNTERS}
     FINAL          ::= LIST OF DVAR              {of same length as
                                                  COUNTERS}
     OPTION         ::= 'state(LIST OF
                    TERM,LIST OF DVAR)'
                    |
                    'valueprec(INTEGER,INTEGER,DVAR)'
                    | 'anystretchocc(DVAR)'
                    |
                    'stretchocc(VALUEPAT,DVAR)'
                    |
                    'stretchoccmod(VALUEPAT,DVAR,INTEGER)'
                    |
                    'stretchmaxlen(VALUEPAT,DVAR)'
                    |
                    'stretchminlen(VALUEPAT,DVAR)'
                    | 'wordocc(WORDPAT,DVAR)'
                    |
                    'wordoccmod(WORDPAT,DVAR,INTEGER)'
                    |
                    'wordprefix(WORDPAT,DVAR)'
                    |
                    'wordsuffix(WORDPAT,DVAR)'
     VALUEPAT       ::= INTEGER
                    | LIST OF INTEGER             {alternatives}
                    | VALUEPAT'/'VALUEPAT         {alternatives}
     WORDPAT        ::= LIST OF VALUEPAT
     DVAR           ::= VARIABLE OR INTEGER

     If no counters are used, then the arguments COUNTERS, INITIAL and
     FINAL should be '[]'.  The arguments TEMPLATE and SEQUENCE are only
     relevant if some EXPR mentions a variable in TEMPLATE, in which
     case the corresponding position in SEQUENCE will be used at that
     point.

     The constraint holds for a ground instance SEQUENCE if:

        * SIGNATURE is the signature corresponding to SEQUENCE.
        * The finite automaton encoded by SOURCESSINKS and ARCS stops in
          an accept state.
        * Any counter arithmetic on the transitions map their INITIAL
          values to the FINAL values.
        * Any extra constraint imposed by OPTIONS are true.

     Here is an example.  Suppose that you want to define the predicate
     'inflexion(N,L,OPT)' which should hold if L is a list of domain
     variables, and N is the number of times that the sequence order
     switches between strictly increasing and strictly decreasing.  For
     example, the sequence '[1,1,4,8,8,2,7,1]' switches order three
     times.

     Such a constraint is conveniently expressed by a finite automaton
     over the alphabet '[<,=,>]' denoting the order between consecutive
     list elements.  A counter is incremented when the order switches,
     and is mapped to the first argument of the constraint.  The
     automaton could look as follows:


 [image src="images/inflexion2.png" text="" ]
                      Automaton for 'inflexion/3'

     The following piece of code encodes this using 'automaton/9'.  The
     auxiliary predicate 'inflexion_signature/2' maps the sequence to a
     signature where the consecutive element order is encoded over the
     alphabet '[0,1,2]'.  We use one counter with initial value 0 and
     final value N (an argument of 'inflexion/3').  Two transitions
     increment the counter.  All states are accept states.

          inflexion(N, Vars, Opt) :-
                  inflexion_signature(Vars, Sign),
                  automaton(Sign, _, Sign,
                            [source(s),sink(i),sink(j),sink(s)],
                            [arc(s,1,s      ),
                             arc(s,2,i      ),
                             arc(s,0,j      ),
                             arc(i,1,i      ),
                             arc(i,2,i      ),
                             arc(i,0,j,[C+1]),
                             arc(j,1,j      ),
                             arc(j,0,j      ),
                             arc(j,2,i,[C+1])],
                            [C],[0],[N],Opt).

          inflexion_signature([], []).
          inflexion_signature([_], []) :- !.
          inflexion_signature([X,Y|Ys], [S|Ss]) :-
                  S in 0..2,
                  X #> Y #<=> S #= 0,
                  X #= Y #<=> S #= 1,
                  X #< Y #<=> S #= 2,
                  inflexion_signature([Y|Ys], Ss).

     Some queries:

          /* count the #inflections of a ground string */
          | ?- inflexion(N, [1,1,4,8,8,2,7,1], []).
          N = 3 ? <RET>
          yes

          /* find strings with two inflections */
          | ?- length(L,4), domain(L,0,1),
               inflexion(2,L,[]), labeling([],L).
          L = [0,1,0,1] ? ;
          L = [1,0,1,0] ? ;
          no

          /* find strings that are strictly increasing, strictly decreasing or all equal */
          | ?- length(L,4), domain(L,0,3),
               inflexion(I,L,[anystretchocc(1)]), labeling([],L).
          I = 0,
          L = [0,0,0,0] ? ;
          I = 0,
          L = [0,1,2,3] ? ;
          I = 0,
          L = [1,1,1,1] ? ;
          I = 0,
          L = [2,2,2,2] ? ;
          I = 0,
          L = [3,2,1,0] ? ;
          I = 0,
          L = [3,3,3,3] ? ;
          no

          /* find strings that contain an increase followed by a decrease */
          | ?- length(L,4), domain(L,0,1),
               inflexion(I,L,[wordocc([2,0],1)]), labeling([],L).
          I = 1,
          L = [0,0,1,0] ? ;
          I = 1,
          L = [0,1,0,0] ? ;
          I = 2,
          L = [0,1,0,1] ? ;
          I = 2,
          L = [1,0,1,0] ? ;
          no

     This constraint uses techniques from [Beldiceanu, Carlsson & Petit
     04] and [Beldiceanu, Carlsson, Flener & Pearson 10].


File: sicstus.info,  Node: User-Defined Constraints,  Prev: Automata Constraints,  Up: Available Constraints

10.10.4.10 User-Defined Constraints
...................................

New, primitive constraints can be added defined by the user on two
different levels.  On a higher level, constraints can be defined using
the global constraint programming interface; *note Defining Global
Constraints::.  Such constraints can embody specialized algorithms and
use the full power of Prolog.  They cannot be reified.

   On a lower level, new primitive constraints can be defined with
indexicals.  In this case, they take part in the basic constraint
solving algorithm and express custom designed rules for special cases of
the overall local propagation scheme.  Such constraints are called "FD
predicates"; *note Defining Primitive Constraints::.  They can
optionally be reified.


File: sicstus.info,  Node: Enumeration Predicates,  Next: Statistics Predicates,  Prev: Available Constraints,  Up: lib-clpfd

10.10.5 Enumeration Predicates
------------------------------

As is usually the case with finite domain constraint solvers, this
solver is not "complete".  That is, it does not ensure that the set of
posted constraints is satisfiable.  One must resort to search
(enumeration) to check satisfiability and get particular solutions.

   The following predicates provide several variants of search:

'indomain(?X)'

     where X is a domain variable with a bounded domain.  Assigns, in
     increasing order via backtracking, a feasible value to X.

'labeling(:OPTIONS, +VARIABLES)'

     where VARIABLES is a list of domain variables and OPTIONS is a list
     of search options.  The domain variables must all have bounded
     domains.  True if an assignment of the variables can be found,
     which satisfies the posted constraints.

'first_bound(+BB0, -BB)'
'later_bound(+BB0, -BB)'

     Provides an auxiliary service for the 'value(ENUM)' option (see
     below).

'minimize(:GOAL,?X)'
'minimize(:GOAL,?X,+OPTIONS)   since release 4.3'
'maximize(:GOAL,?X)'
'maximize(:GOAL,?X,+OPTIONS)   since release 4.3'

     Uses a restart algorithm to find an assignment that minimizes
     (maximizes) the domain variable X.  GOAL should be a Prolog goal
     that constrains X to become assigned, and could be a 'labeling/2'
     goal.  The algorithm calls GOAL repeatedly with a progressively
     tighter upper (lower) bound on X until a proof of optimality is
     obtained.

     Whether to enumerate every solution that improves the objective
     function, or only the optimal one after optimality has been proved,
     is controlled by OPTIONS.  If given, then it whould be a list
     containing a single atomic value, one of:

     'best   since release 4.3'
          Return the optimal solution after proving its optimality.
          This is the default.

     'all   since release 4.3'
          Enumerate all improving solutions, on backtracking seek the
          next improving solution.  Merely fail after proving
          optimality.

   The OPTIONS argument of 'labeling/2' controls the order in which
variables are selected for assignment (variable choice heuristic), the
way in which choices are made for the selected variable (value choice
heuristic), whether the problem is a satisfaction one or an optimization
one, and whether all solutions or only the optimal one should be
returned.  The options are divided into five groups.  One option may be
selected per group.  Also, the number of assumptions (choices) made
during the search can be counted.  Finally, limits on the execution time
and discrepancy of the search can be imposed:

     The following options control the order in which the next variable
     is selected for assignment.

     'leftmost'
     'input_order'
          The leftmost variable is selected.  This is the default.

     'min'
     'smallest'
          The leftmost variable with the smallest lower bound is
          selected.

     'max'
     'largest'
          The leftmost variable with the greatest upper bound is
          selected.

     'ff'
     'first_fail'
          The first-fail principle is used: the leftmost variable with
          the smallest domain is selected.

     'anti_first_fail   since release 4.3'
          The leftmost variable with the largest domain is selected.

     'occurrence   since release 4.3'
          The leftmost variable among those that have the most
          constraints suspended on it is selected.

     'ffc'
     'most_constrained'
          The most constrained heuristic is used: a variable with the
          smallest domain is selected, breaking ties by (a) selecting
          the variable that has the most constraints suspended on it and
          (b) selecting the leftmost one.

     'max_regret   since release 4.3'
          The variable with the largest difference between its first two
          domain elements is selected.  Ties are broken by selecting the
          leftmost variable.

     'variable(SEL)'
          SEL is a predicate to select the next variable.  Given VARS,
          the variables that remain to label, it will be called as
          SEL(VARS,SELECTED,REST).

          SEL is expected to succeed determinately, unifying SELECTED
          and REST with the selected variable and the remaining list,
          respectively.

          SEL should be a callable term, optionally with a module
          prefix, and the arguments VARS,SELECTED,REST will be appended
          to it.  For example, if SEL is 'mod:sel(Param)', then it will
          be called as 'mod:sel(Param,Vars,Selected,Rest)'.

     The following options control the way in which choices are made for
     the selected variable X:

     'step'
          Makes a binary choice between 'X #= B' and 'X #\= B', where B
          is the lower or upper bound of X.  This is the default.

     'enum'
          Makes a multiple choice for X corresponding to the values in
          its domain.

     'bisect'
          Makes a binary choice between 'X #=< M' and 'X #> M', where M
          is the middle of the domain of X, i.e. the mean of 'min(X)'
          and 'max(X)' rounded down to the nearest integer.  This
          strategy is also known as domain splitting.

     'median   since release 4.3'
          Makes a binary choice between 'X #= M' and 'X #\= M', where M
          is the median of the domain of X.  If the domain has an even
          number of elements, then the smaller middle value is used.

     'middle   since release 4.3'
          Makes a binary choice between 'X #= M' and 'X #\= M', where M
          is the middle of the domain of X, i.e. the mean of 'min(X)'
          and 'max(X)' rounded down to the nearest integer.

     'value(ENUM)'
          ENUM is a predicate that should prune the domain of X,
          possibly but not necessarily to a singleton.  It will be
          called as ENUM(X,REST,BB0,BB) where REST is the list of
          variables that need labeling except X, and BB0 and BB are
          parameters described below.

          ENUM is expected to succeed nondeterminately, pruning the
          domain of X, and to backtrack one or more times, providing
          alternative prunings.  To ensure that branch-and-bound search
          works correctly, it must call the auxiliary predicate
          'first_bound(BB0,BB)' in its first solution.  Similarly, it
          must call the auxiliary predicate 'later_bound(BB0,BB)' in any
          alternative solution.

          ENUM should be a callable term, optionally with a module
          prefix, and the arguments X,REST,BB0,BB will be appended to
          it.  For example, if ENUM is 'mod:enum(Param)', then it will
          be called as 'mod:enum(Param,X,Rest,BB0,BB)'.

     The following options control the order in which the choices are
     made for the selected variable X.  Not useful with the
     'value(ENUM)' option:

     'up'
          The domain is explored in ascending order.  This is the
          default.

     'down'
          The domain is explored in descending order.

     The following options tell the solver whether the given problem is
     a satisfaction problem or an optimization problem.  In a
     satisfaction problem, we wish to find values for the domain
     variables, but we do not care about which values.  In an
     optimization problem, we wish to find values that minimize or
     maximize some objective function reflected in a domain variable:

     'satisfy   since release 4.3'
          We have a satisfication problem.  Its solutions are enumerated
          by backtracking.  This is the default.

     'minimize(X)'
     'maximize(X)'

          We have an optimization problem, seeking an assignment that
          minimizes (maximizes) the domain variable X.  The labeling
          should constrain X to become assigned for all assignments of
          VARIABLES.  It is useful to combine these option with the
          'time_out/2', 'best', and 'all' options (see below).  If these
          options occur more than once, then the last occurrence
          overrides previous ones.

     The following options are only meaningful for optimization
     problems.  They tell the solver whether to enumerate every solution
     that improves the objective function, or only the optimal one after
     optimality has been proved:

     'best   since release 4.3'
          Return the optimal solution after proving its optimality.
          This is the default.

     'all   since release 4.3'
          Enumerate all improving solutions, on backtracking seek the
          next improving solution.  Merely fail after proving
          optimality.

     The following options are only meaningful for optimization
     problems.  They tell the solver what search scheme to use, but have
     no effect on the semantics or on the meaning of other options:

     'bab   since release 4.3'
          Use a branch-and-bound scheme, which incrementally tightens
          the bound on the objective as more and more solutions are
          found.  This is the default, and is usually the more efficient
          scheme.

     'restart   since release 4.3'
          Use a scheme that restarts the search with a tighter bound on
          the objective each time a solution is found.

     The following option counts the number of assumptions (choices)
     made during the search:

     'assumptions(K)'

          When a solution is found, K is unified with the number of
          choices made.

     Finally, limits on the discrepancy of the search and the execution
     time can be imposed:

     'discrepancy(D)'

          On the path leading to the solution there are at most D
          choicepoints in which a non-leftmost branch was taken.

     'time_out(TIME,FLAG)'

          *Note lib-timeout::.  TIME should be an integer number of
          milliseconds.  If the search is exhausted within this time and
          no solution is found, then the search merely fails, as usual.
          Otherwise, FLAG is bound to a value reflecting the outcome:

          'optimality   since release 4.4'
               If 'best' was selected in an optimization problem, then
               the search space was exhausted, having found the optimal
               solution.  The variables are bound to the corresponding
               values.  If 'best' was not selected, this flag value is
               not used.

          'success   since release 4.4'
               If 'best' was selected in an optimization problem, then
               the search timed out before the search space was
               exhausted, having found at least one solution.  If 'best'
               was not selected, then a solution was simply found before
               the time limit.  In any case, the variables are bound to
               the values corresponding to the latest solution found.

          'time_out   since release 4.4'
               If 'best' was selected in an optimization problem, then
               the search timed out before any solution was found.  If
               'best' was not selected, then the search timed out while
               searching for the next solution.  The variables are left
               unbound.

   For example, to enumerate solutions using a static variable ordering,
use:

     | ?- constraints(Variables),
          labeling([], Variables).
          %same as [leftmost,step,up,satisfy]

   To minimize a cost function using branch-and-bound search, computing
the best solution only, with a dynamic variable ordering using the
first-fail principle, and domain splitting exploring the upper part of
domains first, use:

     | ?- constraints(Variables, Cost),
          labeling([ff,bisect,down,minimize(Cost)], Variables).

   To give a time budget and collect the solutions of a satisfiability
problem up to the time limit, use:

     | ?- constraints(Variables),
          findall(Variables, labeling([time_out(BUDGET,success)|OPTIONS]), Solutions).

where 'Flag=success' will hold if all solutions were found, and
'Flag=time_out' will hold if the time expired.

   The file 'library('clpfd/examples/tsp.pl')' contains an example of
user-defined variable and value choice heuristics.

   Note that, when used for optimization, 'labeling/2' has a limitation
compared to 'minimize/[2,3]' and 'maximize/[2,3]': the variable and
value choice heuristics specified by 'labeling/2' must apply to the
whole set of variables, with no provision for different heuristics for
different subsets.  As of release 4.3, this limitation has been lifted
by the following predicate:

'solve(:OPTIONS, :SEARCHES)   since release 4.3'

     where OPTIONS is a list of options of the same shape as taken by
     'labeling/2', and SEARCHES is a list of 'labeling/2' and
     'indomain/1' goals, or a single such goal.  The domain variables of
     SEARCHES must all have bounded domains.  True if the conjunction of
     SEARCHES is true.

     The main purpose of this predicate is for optimization, allowing to
     use different heuristics in the different SEARCHES.  For
     satisfiability problems, a simple sequence of 'labeling/2' and
     'indomain/1' goals does the trick.

     The treatment of the OPTIONS, as well as the suboption lists given
     in the 'labeling/2' goals of SEARCHES, is a bit special.  Some
     options are global for the whole search, and are ignored if they
     occur in the suboption lists.  Others are local to the given
     'labeling/2' goal, but provides a default value for the whole
     search if it occurs in OPTIONS.  The following table defines the
     role of each option as 'global' or 'local':

     'all'                         'global'
     'anti_first_fail'             'local'
     'assumptions/1'               'global'
     'bab'                         'global'
     'best'                        'global'
     'bisect'                      'local'
     'discrepancy/1'               'local'
     'down'                        'local'
     'enum'                        'local'
     'ffc'                         'local'
     'ff'                          'local'
     'first_fail'                  'local'
     'input_order'                 'local'
     'largest'                     'local'
     'leftmost'                    'local'
     'maximize/1'                  'global'
     'max'                         'local'
     'max_regret'                  'local'
     'median'                      'local'
     'middle'                      'local'
     'minimize/1'                  'global'
     'min'                         'local'
     'most_constrained'            'local'
     'occurrence'                  'local'
     'restart'                     'global'
     'satisfy'                     'global'
     'smallest'                    'local'
     'step'                        'local'
     'time_out/2'                  'global'
     'up'                          'local'
     'value/1'                     'local'
     'variable/1'                  'local'

   For example, suppose that you want to minimize a cost function using
branch-and-bound search, enumerating every improving solution, using
left-to-right search on some variables followed by first-fail domain
splitting search on some other variables.  This can be expressed as:

     | ?- constraints([X1,X2,X3,Y1,Y2,Y3], Cost),
          solve([minimize(Cost),all],
                [labeling([leftmost],[X1,X2,X3]),
                 labeling([ff,bisect],[Y1,Y2,Y3])]).


File: sicstus.info,  Node: Statistics Predicates,  Next: Answer Constraints,  Prev: Enumeration Predicates,  Up: lib-clpfd

10.10.6 Statistics Predicates
-----------------------------

The following predicates can be used to access execution statistics.

'fd_statistics'
'fd_statistics(?KEY, ?VALUE)'

     This allows a program to access execution statistics specific to
     this solver.  General statistics about CPU time and memory
     consumption etc. is available from the built-in predicate
     'statistics/2'.

     Without arguments, displays on the standard error stream a summary
     of the following statistics, and zeroes all counters.  With
     arguments, for each of the possible keys KEY, VALUE is unified with
     the current value of a counter, which is simultaneously zeroed.
     The following counters are maintained:

     'resumptions'
          The number of times a constraint was resumed.

     'entailments'
          The number of times a (dis)entailment was detected by a
          constraint.

     'prunings'
          The number of times a domain was pruned.

     'backtracks'
          The number of times a contradiction was found by a domain
          being wiped out, or by a global constraint signalling failure.
          Other causes of backtracking, such as failed Prolog tests, are
          not covered by this counter.

     'constraints'
          The number of propagators created.


File: sicstus.info,  Node: Answer Constraints,  Next: CLPFD Debugging,  Prev: Statistics Predicates,  Up: lib-clpfd

10.10.7 Answer Constraints
--------------------------

By default, the answer constraint only shows the projection of the store
onto the variables that occur in the query, but not any constraints that
may be attached to these variables, nor any domains or constraints
attached to other variables.  This is a conscious decision, as no
efficient algorithm for projecting answer constraints onto the query
variables is known for this constraint system.

   It is possible, however, to get a complete answer constraint
including all variables that took part in the computation and their
domains and attached constraints.  This is done by asserting a clause
for the following predicate:

'clpfd:full_answer   hook,volatile'

     If false (the default), then the answer constraint, as well as
     constraints projected by 'copy_term/3',
     'clpfd:project_attributes/2', 'clpfd:attribute_goal/2' and their
     callers, only contain the domains of the query variables.  If true,
     then those constraints contain the domains and any attached
     constraints of all variables.  Initially defined as a dynamic,
     volatile predicate with no clauses.


File: sicstus.info,  Node: CLPFD Debugging,  Next: Defining Global Constraints,  Prev: Answer Constraints,  Up: lib-clpfd

10.10.8 Debugging
-----------------

Code using 'library(clpfd)' can be debugged with the usual debugger, but
it does not capture all relevant aspects of constraint execution: the
propagation cascade and domain changes are not visible.  To capture such
aspects, a separate, dedicated debugger is available; *note lib-fdbg::.

   The 'v' command ("print variable bindings") of the usual debugger can
be handy.  It will endeavor to print the variable bindings of the clause
containing the current goal, as well as any goals that are blocked on a
variable found among those bindings.  In particular, it will show the
current domains of such variables.  *Note Debug Commands::.


File: sicstus.info,  Node: Defining Global Constraints,  Next: Defining Primitive Constraints,  Prev: CLPFD Debugging,  Up: lib-clpfd

10.10.9 Defining Global Constraints
-----------------------------------

* Menu:

* The Global Constraint Programming Interface:: The Global Constraint Programming Interface
* Reflection Predicates:: Reflection Predicates
* FD Set Operations:: FD Set Operations
* A Global Constraint Example:: A Global Constraint Example


File: sicstus.info,  Node: The Global Constraint Programming Interface,  Next: Reflection Predicates,  Up: Defining Global Constraints

10.10.9.1 The Global Constraint Programming Interface
.....................................................

This section describes a programming interface by means of which new
constraints can be written.  The interface consists of a set of
predicates provided by this library module.  Constraints defined in this
way can take arbitrary arguments and may use any constraint solving
algorithm, provided it makes sense.  Reification cannot be expressed in
this interface; instead, reification may be achieved by explicitly
passing a 0/1-variable to the constraint in question.

   Global constraints have state, which may be updated each time the
constraint is resumed.  The state information may be used e.g. in
incremental constraint solving.

   The following two predicates are the principal entrypoints for
defining and posting new global constraints:

'clpfd:dispatch_global(+CONSTRAINT, +STATE0, -STATE, -ACTIONS)   extendible'

     Tells the solver how to solve constraints of the form CONSTRAINT.
     Defined as a multifile predicate.

     When defining a new constraint, a clause of this predicate must be
     added.  Its body defines a constraint solving method and should
     always succeed determinately.  When a global constraint is called
     or resumed, the solver will call this predicate to deal with the
     constraint.

          *Please note*: the constraint is identified by its principal
          functor; there is no provision for having two constraints with
          the same name in different modules.  It is good practice to
          include a cut in every clause of 'clpfd:dispatch_global/4'.

          *Please note*: During propagation, if the domain of a variable
          becomes reduced to a single value, then the variable will
          eventually be bound to that value, but it is undefined exactly
          when that happens.  Therefore, clauses of
          'clpfd:dispatch_global/4' should not use 'nonvar/1' or
          'integer/1' to check if a variable is fixed.  Use e.g.
          'fd_min/1' and 'fd_max/1' instead.

     STATE0 and STATE are the old and new state respectively.

     The constraint solving method must not invoke the constraint solver
     recursively e.g. by binding variables or posting new constraints;
     instead, ACTIONS should be unified with a list of requests to the
     solver.  Each request should be of the following form:

     'exit'
          The constraint has become entailed, and ceases to exist.

     'fail'
          The constraint has become disentailed, causing the solver to
          backtrack.

     'X = V'
          The solver binds X to V.

     'X in R'
          The solver constrains X to be a member of the CONSTANTRANGE R
          (*note Syntax of Indexicals::).

     'X in_set S'
          The solver constrains X to be a member of the FD set S (*note
          FD Set Operations::).

     'call(GOAL)'
          The solver calls the goal or constraint GOAL, which should be
          module prefixed unless it is a built-in predicate or an
          exported predicate of the 'clpfd' module.

          GOAL is executed as any Prolog goal, but in a context where
          some constraints may already be enqueued for execution, in
          which case those constraints will run after the completion of
          the call request.

'fd_global(:CONSTRAINT, +STATE, +SUSP)'
'fd_global(:CONSTRAINT, +STATE, +SUSP, +OPTIONS)'

     where CONSTRAINT is a constraint goal, STATE is its initial state,
     and SUSP is a term encoding how the constraint should wake up in
     response to domain changes.  This predicate posts the constraint.

     SUSP is a list of F(VAR) terms where VAR is a variable to suspend
     on and F is a functor encoding when to wake up:

     'dom(X)'
          wake up when the domain of X has changed

     'min(X)'
          wake up when the lower bound of X has changed

     'max(X)'
          wake up when the upper bound of X has changed

     'minmax(X)'
          wake up when the lower or upper bound of X has changed

     'val(X)'
          wake up when the lower and upper bounds of X have coincided

     OPTIONS is a list of zero or more of the following:

     'source(TERM)'
          By default, the symbolic form computed by 'copy_term/3', and
          shown in the answer constraint if 'clpfd:full_answer' holds,
          equals CONSTRAINT, module name expanded.  With this option,
          the symbolic form will instead be TERM.  In particular, if
          TERM equals 'true', then the constraint will not appear in the
          BODY argument of 'copy_term/3'.  This can be useful if you are
          posting some redundant (implied) constraint.

     'idempotent(BOOLEAN)'
          If 'true' (the default), then the constraint solving method is
          assumed to be idempotent.  That is, in the scope of
          'clpfd:dispatch_global/4', the solver will not check for the
          resumption conditions for the given constraint, while
          performing its ACTIONS.  If 'false', then an action may well
          cause the solver to resume the constraint that produced the
          action.

          If a variable occurs more than once in a global constraint
          that is being posted, or due to a variable-variable
          unification, then the solver will no longer trust the
          constraint solving method to be idempotent.

   For an example of usage, *note A Global Constraint Example::.

   The following predicate controls operational aspects of the
constraint solver:

'fd_flag(+FLAGNAME, ?OLDVALUE, ?NEWVALUE)'

     OLDVALUE is the value of the FD flag FLAGNAME, and the new value of
     FLAGNAME is set to NEWVALUE.  The possible FD flag names and values
     are:

     'overflow'
          Determines the behavior on integer overflow conditions.
          Possible values:

          'error'
               Raises a representation error (the default).

          'fail'
               Silently fails.

     'debug'
          Controls the visibility of constraint propagation.  Possible
          values are 'on' and 'off' (the default).  For internal use by
          'library(fdbg)'.


File: sicstus.info,  Node: Reflection Predicates,  Next: FD Set Operations,  Prev: The Global Constraint Programming Interface,  Up: Defining Global Constraints

10.10.9.2 Reflection Predicates
...............................

The constraint solving method needs access to information about the
current domains of variables.  This is provided by the following
predicates, which are all constant time operations.

'fd_var(?X)'

     Checks that X is currently an unbound variable that is known to the
     CLPFD solver.

'fd_min(?X, ?MIN)'

     where X is a domain variable.  MIN is unified with the smallest
     value in the current domain of X, i.e. an integer or the atom 'inf'
     denoting minus infinity.

'fd_max(?X, ?MAX)'

     where X is a domain variable.  MAX is unified with the upper bound
     of the current domain of X, i.e. an integer or the atom 'sup'
     denoting plus infinity.

'fd_size(?X, ?SIZE)'

     where X is a domain variable.  SIZE is unified with the size of the
     current domain of X, if the domain is bounded, or the atom 'sup'
     otherwise.

'fd_set(?X, ?SET)'

     where X is a domain variable.  SET is unified with an FD set
     denoting the internal representation of the current domain of X;
     see below.

'fd_dom(?X, ?RANGE)'

     where X is a domain variable.  RANGE is unified with a
     CONSTANTRANGE (*note Syntax of Indexicals::) denoting the current
     domain of X.

'fd_degree(?X, ?DEGREE)'

     where X is a domain variable.  DEGREE is unified with the number of
     constraints that are attached to X.

          *Please note*: this number may include some constraints that
          have been detected as entailed.  Also, DEGREE is not the
          number of neighbors of X in the constraint network.

   The following predicates can be used for computing the set of
variables that are (transitively) connected via constraints to some
given variable(s).

'fd_neighbors(+VAR, -NEIGHBORS)'

     Given a domain variable VAR, NEIGHBORS is the set of variables that
     can be reached from VAR via constraints posted so far.

'fd_closure(+VARS, -CLOSURE)'

     Given a list VARS of domain variables, CLOSURE is the set of
     variables (including VARS) that can be transitively reached via
     constraints posted so far.  Thus, 'fd_closure/2' is the transitive
     closure of 'fd_neighbors/2'.


File: sicstus.info,  Node: FD Set Operations,  Next: A Global Constraint Example,  Prev: Reflection Predicates,  Up: Defining Global Constraints

10.10.9.3 FD Set Operations
...........................

The domains of variables are internally represented compactly as "FD
set" terms.  The details of this representation are subject to change
and should not be relied on.  Therefore, a number of operations on FD
sets are provided, as such terms play an important role in the
interface.  The following operations are the primitive ones:

'is_fdset(+SET)'

     SET is a valid FD set.

'empty_fdset(?SET)'

     SET is the empty FD set.

'fdset_parts(?SET, ?MIN, ?MAX, ?REST)'

     SET is an FD set, which is a union of the non-empty interval
     [MIN,MAX] and the FD set REST, and all elements of REST are greater
     than MAX+1.  MIN and MAX are both integers or the atoms 'inf' and
     'sup', denoting minus and plus infinity, respectively.  Either SET
     or all the other arguments must be ground.

   The following operations can all be defined in terms of the primitive
ones, but in most cases, a more efficient implementation is used:

'empty_interval(+MIN, +MAX)'

     [MIN,MAX] is an empty interval.

'fdset_interval(?SET, ?MIN, ?MAX)'

     SET is an FD set, which is the non-empty interval [MIN,MAX].

'fdset_singleton(?SET, ?ELT)'

     SET is an FD set containing ELT only.  At least one of the
     arguments must be ground.

'fdset_min(+SET, -MIN)'

     MIN is the lower bound of SET.

'fdset_max(+SET, -MIN)'

     MAX is the upper bound of SET.  This operation is linear in the
     number of intervals of SET.

'fdset_size(+SET, -SIZE)'

     SIZE is the cardinality of SET, represented as 'sup' if SET is
     infinite.  This operation is linear in the number of intervals of
     SET.

'list_to_fdset(+LIST, -SET)'

     SET is the FD set containing the elements of LIST.  Slightly more
     efficient if LIST is ordered.

'fdset_to_list(+SET, -LIST)'

     LIST is an ordered list of the elements of SET, which must be
     finite.

'range_to_fdset(+RANGE, -SET)'

     SET is the FD set containing the elements of the CONSTANTRANGE
     (*note Syntax of Indexicals::) RANGE.

'fdset_to_range(+SET, -RANGE)'

     RANGE is a constant interval, a singleton constant set, or a union
     of such, denoting the same set as SET.

'fdset_add_element(+SET1, +ELT -SET2)'

     SET2 is SET1 with ELT inserted in it.

'fdset_del_element(+SET1, +ELT, -SET2)'

     SET2 is like SET1 but with ELT removed.

'fdset_disjoint(+SET1, +SET2)'

     The two FD sets have no elements in common.

'fdset_intersect(+SET1, +SET2)'

     The two FD sets have at least one element in common.

'fdset_intersection(+SET1, +SET2, -INTERSECTION)'

     INTERSECTION is the intersection between SET1 and SET2.

'fdset_intersection(+SETS, -INTERSECTION)'
     INTERSECTION is the intersection of all the sets in SETS.

'fdset_member(?ELT, +SET)'

     is true when ELT is a member of SET.  If ELT is unbound, then SET
     must be finite.

'fdset_eq(+SET1, +SET2)'

     Is true when the two arguments represent the same set i.e. they are
     identical.

'fdset_subset(+SET1, +SET2)'

     Every element of SET1 appears in SET2.

'fdset_subtract(+SET1, +SET2, -DIFFERENCE)'

     DIFFERENCE contains all and only the elements of SET1 that are not
     also in SET2.

'fdset_union(+SET1, +SET2, -UNION)'

     UNION is the union of SET1 and SET2.

'fdset_union(+SETS, -UNION)'
     UNION is the union of all the sets in SETS.

'fdset_complement(+SET, -COMPLEMENT)'

     COMPLEMENT is the complement of SET wrt. 'inf..sup'.


File: sicstus.info,  Node: A Global Constraint Example,  Prev: FD Set Operations,  Up: Defining Global Constraints

10.10.9.4 A Global Constraint Example
.....................................

The following example defines a new global constraint 'exactly(X,L,N)',
which is true if X occurs exactly N times in the list L of domain
variables.  N must be an integer when the constraint is posted.  A
version without this restriction and defined in terms of reified
equalities was presented earlier; *note Reified Constraints::.

   This example illustrates the use of state information.  The state has
two components: the list of variables that could still be X, and the
number of variables still required to be X.

   The constraint is defined to wake up on any domain change.

                                                         _% exactly.pl_
     /*
     An implementation of exactly(I, X[1]...X[m], N):

     Necessary condition: 0 <= N <= m.
     Rewrite rules:

     [1] |= X[i]=I  ==> exactly(I, X[1]...X[i-1],X[i+1]...X[m], N-1):
     [2] |= X[i]!=I ==> exactly(I, X[1]...X[i-1],X[i+1]...X[m], N):
     [3] |= N=0     ==> X[1]!=I ... X[m]!=I
     [4] |= N=m     ==> X[1]=I  ... X[m]=I
     */
     :- use_module(library(clpfd)).

     % the entrypoint
     exactly(I, Xs, N) :-
             dom_suspensions(Xs, Susp),
             fd_global(exactly(I,Xs,N), state(Xs,N), Susp).

     dom_suspensions([], []).
     dom_suspensions([X|Xs], [dom(X)|Susp]) :-
             dom_suspensions(Xs, Susp).

     % the solver method
     :- multifile clpfd:dispatch_global/4.
     clpfd:dispatch_global(exactly(I,_,_), state(Xs0,N0), state(Xs,N), Actions) :-
             exactly_solver(I, Xs0, Xs, N0, N, Actions).

     exactly_solver(I, Xs0, Xs, N0, N, Actions) :-
             ex_filter(Xs0, Xs, N0, N, I),
             length(Xs, M),
             (   N=:=0 -> Actions = [exit|Ps], ex_neq(Xs, I, Ps)
             ;   N=:=M -> Actions = [exit|Ps], ex_eq(Xs, I, Ps)
             ;   N>0, N<M -> Actions = []
             ;   Actions = [fail]
             ).
                                                         _% exactly.pl_
     % rules [1,2]: filter the X's, decrementing N
     ex_filter([], [], N, N, _).
     ex_filter([X|Xs], Ys, L, N, I) :- X==I, !,
             M is L-1,
             ex_filter(Xs, Ys, M, N, I).
     ex_filter([X|Xs], Ys0, L, N, I) :-
             fd_set(X, Set),
             fdset_member(I, Set), !,
             Ys0 = [X|Ys],
             ex_filter(Xs, Ys, L, N, I).
     ex_filter([_|Xs], Ys, L, N, I) :-
             ex_filter(Xs, Ys, L, N, I).

     % rule [3]: all must be neq I
     ex_neq(Xs, I, Ps) :-
             fdset_singleton(Set0, I),
             fdset_complement(Set0, Set),
             eq_all(Xs, Set, Ps).

     % rule [4]: all must be eq I
     ex_eq(Xs, I, Ps) :-
             fdset_singleton(Set, I),
             eq_all(Xs, Set, Ps).

     eq_all([], _, []).
     eq_all([X|Xs], Set, [X in_set Set|Ps]) :-
             eq_all(Xs, Set, Ps).

     end_of_file.

     % sample queries:

     | ?- exactly(5,[A,B,C],1), A=5.
     A = 5,
     B in(inf..4)\/(6..sup), C in(inf..4)\/(6..sup)

     | ?- exactly(5,[A,B,C],1), A in 1..2, B in 3..4.
     C = 5,
     A in 1..2,
     B in 3..4


File: sicstus.info,  Node: Defining Primitive Constraints,  Next: CLPFD Coexisting,  Prev: Defining Global Constraints,  Up: lib-clpfd

10.10.10 Defining Primitive Constraints
---------------------------------------

Indexicals are the principal means of defining constraints, but it is
usually not necessary to resort to this level of programming--most
commonly used constraints are available in a library and/or via
macro-expansion.  The key feature about indexicals is that they give the
programmer precise control over aspects of the operational semantics of
the constraints.  Trade-offs can be made between the computational cost
of the constraints and their pruning power.  The indexical language
provides many degrees of freedom for the user to select the level of
consistency to be maintained depending on application-specific needs.

* Menu:

* Definitions:: Definitions
* Pitfalls of Interval Reasoning:: Pitfalls of Interval Reasoning
* Indexicals:: Indexicals
* Range Expressions:: Range Expressions
* Term Expressions:: Term Expressions
* Monotonicity of Ranges:: Monotonicity of Ranges
* FD Predicates:: FD Predicates
* Execution of Propagating Indexicals:: Execution of Propagating Indexicals
* Execution of Checking Indexicals:: Execution of Checking Indexicals
* Compiled Indexicals:: Compiled Indexicals


File: sicstus.info,  Node: Definitions,  Next: Pitfalls of Interval Reasoning,  Up: Defining Primitive Constraints

10.10.10.1 Definitions
......................

For constraint store S, variable X, and finite domain R:

   * D(X,S) denotes the domain of X in S.

   * (X IN R)(S) denotes the extension of S where D(X,S) has been
     intersected with R.

   The following definitions, adapted from [Van Hentenryck et al. 95],
define important notions of consistency and entailment of constraints
wrt. stores.

   A ground constraint is "true" if it holds and "false" otherwise.

   A constraint C is "domain-consistent wrt. S" iff, for each variable
XI and value VI in D(XI,S), there exist values VJ in D(XJ,S), 1 <= J <=
N /\ I != J, such that C(V1,...,VN) is true.

   A constraint C is "domain-entailed by S" iff, for all values VJ in
D(XJ,S), 1 <= J <= N, C(V1,...,VN) is true.

   Let D'(X,S) denote the interval [MIN(D(X,S)),MAX(D(X,S))].

   A constraint C is "bounds-consistent wrt. S" iff, for each variable
XI, there exist values VJ and WJ in D'(XJ,S), 1 <= J <= N, I != J, such
that C(V1,...,MIN(D(XI,S)),...,VN) and C(W1,...,MAX(D(XI,S)),...,WN) are
both true.

   A constraint C is "bounds-entailed by S" iff, for all values VJ in
D'(XJ,S), 1 <= J <= N, C(V1,...,VN) is true.

   Finally, a constraint is "domain-disentailed (bounds-disentailed)" by
S iff its negation is domain-entailed (bounds-entailed) by S.


File: sicstus.info,  Node: Pitfalls of Interval Reasoning,  Next: Indexicals,  Prev: Definitions,  Up: Defining Primitive Constraints

10.10.10.2 Pitfalls of Interval Reasoning
.........................................

In most circumstances, arithmetic constraints maintain bounds
consistency and detect bounds entailment and disentailment.  There are
cases where a bounds consistency maintaining constraint may detect a
contradiction when the constraint is not yet bounds-disentailed, as the
following example illustrates.  Note that 'X #\= Y' maintains domain
consistency if both arguments are constants or variables:

     | ?- X+Y #= Z, X=1, Z=6, Y in 1..10, Y #\= 5.
     no
     | ?- X+Y #= Z #<=> B, X=1, Z=6, Y in 1..10, Y #\= 5.
     X = 1,
     Z = 6,
     Y in(1..4)\/(6..10),
     B in 0..1

   Since '1+5#=6' holds, 'X+Y #= Z' is not bounds-disentailed, although
any attempt to make it bounds-consistent wrt. the store results in a
contradictory store.


File: sicstus.info,  Node: Indexicals,  Next: Range Expressions,  Prev: Pitfalls of Interval Reasoning,  Up: Defining Primitive Constraints

10.10.10.3 Indexicals
.....................

An "indexical" is a reactive functional rule of the form 'X in R', where
R is a finite domain valued "range expression" (see below).  *Note
Syntax of Indexicals::.  for a grammar defining indexicals and range
expressions.

   Indexicals can play one of two roles: "propagating indexicals" are
used for constraint solving, and "checking indexicals" are used for
entailment checking.  Let S(R) denote the value of R in S.  When a
propagating indexical fires, the current store S is extended to (X IN
S(R))(S).  When a checking indexical fires, it checks if D(X,S) is
contained in S(R), in which case the constraint corresponding to the
indexical is detected as entailed.


File: sicstus.info,  Node: Range Expressions,  Next: Term Expressions,  Prev: Indexicals,  Up: Defining Primitive Constraints

10.10.10.4 Range Expressions
............................

A range expression has one of the following forms, where RI denote range
expressions, TI denote integer valued "term expressions", S(TI) denotes
the integer value of TI in S, X denotes a variable, I denotes an
integer, and S denotes the current store.

'dom(X)'
     evaluates to D(X,S)

'{T1,...,TN}'
     evaluates to {S(T1),...,S(TN)}.  Any TI containing a variable that
     is not "quantified" by 'unionof/3' will cause the indexical to
     suspend until this variable has been assigned.

'T1..T2'
     evaluates to the interval between S(T1) and S(T2).

'R1/\R2'
     evaluates to the intersection of S(R1) and S(R2)

'R1\/R2'
     evaluates to the union of S(R1) and S(R2)

'\R2'
     evaluates to the complement of S(R2)

'R1+R2'
'R1+T2'
     evaluates to S(R2) or S(T2) added pointwise to S(R1)

'-R2'
     evaluates to S(R2) negated pointwise

'R1-R2'
'R1-T2'
'T1-R2'
     evaluates to S(R2) or S(T2) subtracted pointwise from S(R1) or
     S(T1)

'R1 mod R2'
'R1 mod T2'
     evaluates to the pointwise floored modulo of S(R1) and S(R2) or
     S(T2)

'R1 rem R2'
'R1 rem T2'
     evaluates to the pointwise truncated remainder of S(R1) and S(R2)
     or S(T2)

'R1 ? R2'
     evaluates to S(R2) if S(R1) is a non-empty set; otherwise,
     evaluates to the empty set.  This expression is commonly used in
     the context '(R1 ? (inf..sup) \/ R3)', which evaluates to S(R3) if
     S(R1) is an empty set; otherwise, evaluates to 'inf..sup'.  As an
     optimization, R3 is not evaluated while the value of R1 is a
     non-empty set.

'unionof(X,R1,R2)'
     evaluates to the union of S(E1),...,S(EN), where each EI has been
     formed by substituting K for X in R2, where K is the I:th element
     of S(R1).  *Note N Queens::.  for an example of usage.
          *Please note*: if S(R1) is infinite, then the evaluation of
          the indexical will be abandoned, and the indexical will simply
          suspend.

'switch(T,MAPLIST)'
     evaluates to S(E) if S(T1) equals K and MAPLIST contains a pair
     'K-E'.  Otherwise, evaluates to the empty set.  If T contains a
     variable that is not "quantified" by 'unionof/3', then the
     indexical will suspend until this variable has been assigned.


File: sicstus.info,  Node: Term Expressions,  Next: Monotonicity of Ranges,  Prev: Range Expressions,  Up: Defining Primitive Constraints

10.10.10.5 Term Expressions
...........................

A term expression has one of the following forms, where T1 and T2 denote
term expressions, X denotes a variable, I denotes an integer, and S
denotes the current store.

'min(X)'
     evaluates to the minimum of D(X,S)

'max(X)'
     evaluates to the maximum of D(X,S)

'card(X)'
     evaluates to the size of D(X,S)

'X'
     evaluates to the integer value of X.  The indexical will suspend
     until X is assigned.

'I'
     an integer

'inf'
     minus infinity

'sup'
     plus infinity

'-T1'
     evaluates to S(T1) negated

'T1+T2'
     evaluates to the sum of S(T1) and S(T2)

'T1-T2'
     evaluates to the difference of S(T1) and S(T2)

'T1*T2'
     evaluates to the product of S(T1) and S(T2), where S(T2) must not
     be negative

'T1/>T2'
     evaluates to the floored quotient of S(T1) and S(T2), where S(T2)
     must be positive

'T1/<T2'
     evaluates to the ceilinged quotient of S(T1) and S(T2), where S(T2)
     must be positive

'T1 mod T2'
     evaluates to the floored remainder of S(T1) and S(T2)

'T1 rem T2'
     evaluates to the truncated remainder of S(T1) and S(T2)


File: sicstus.info,  Node: Monotonicity of Ranges,  Next: FD Predicates,  Prev: Term Expressions,  Up: Defining Primitive Constraints

10.10.10.6 Monotonicity of Ranges
.................................

A range R is "monotone in S" iff the value of R in S' is contained in
the value of R in S, for every extension S' of S.  A range R is
"anti-monotone in S" iff the value of R in S is contained in the value
of R in S', for every extension S' of S.  By abuse of notation, we will
say that 'X in R' is (anti-)monotone iff R is (anti-)monotone.

   The consistency or entailment of a constraint C expressed as
indexicals 'X in R' in a store S is checked by considering the
relationship between D(X,S) and S(R), together with the
(anti-)monotonicity of R in S.  The details are given in *note Execution
of Propagating Indexicals:: and *note Execution of Checking
Indexicals::.

   The solver checks (anti-)monotonicity by requiring that certain
variables occurring in the indexical be ground.  This sufficient
condition can sometimes be false for an (anti-)monotone indexical, but
such situations are rare in practice.


File: sicstus.info,  Node: FD Predicates,  Next: Execution of Propagating Indexicals,  Prev: Monotonicity of Ranges,  Up: Defining Primitive Constraints

10.10.10.7 FD Predicates
........................

The following example defines the constraint X+Y=T as an FD predicate in
terms of three indexicals.  Each indexical is a rule responsible for
removing values detected as incompatible from one particular constraint
argument.  Indexicals are _not_ Prolog goals; thus, the example does not
express a conjunction.  However, an indexical may make the store
contradictory, in which case backtracking is triggered:

     plus(X,Y,T) +:
             X in min(T) - max(Y) .. max(T) - min(Y),
             Y in min(T) - max(X) .. max(T) - min(X),
             T in min(X) + min(Y) .. max(X) + max(Y).

   The above definition contains a single clause used for constraint
solving.  The first indexical wakes up whenever the bounds of S(T) or
S(Y) are updated, and removes from D(X,S) any values that are not
compatible with the new bounds of T and Y.  Note that in the event of
"holes" in the domains of T or Y, D(X,S) may contain some values that
are incompatible with X+Y=T but go undetected.  Like most built-in
arithmetic constraints, the above definition maintains bounds
consistency, which is significantly cheaper to maintain than domain
consistency and suffices in most cases.  The constraint could for
example be used as follows:

     | ?- X in 1..5, Y in 2..8, plus(X,Y,T).
     X in 1..5,
     Y in 2..8,
     T in 3..13

   Thus, when an FD predicate is called, the '+:' clause is activated.

   The definition of a user constraint has to specify the variables
involved and the finite domains with which their domains should be
intersected when the propagator is run.  Therefore the FD predicate with
N arguments consists of N indexicals, each specifying a left hand side
variable and a right hand side expression that evaluates to a finite
domain, which is a function of the expression and of the constraint
store.  For example, the third indexical in the above FD predicate
evaluates to the finite domain 3..13 for T if D(X,S) = 1..5 and D(Y,S) =
2..8.  As the domain of some variables gets smaller, the indexical may
further narrow the domain of other variables.  Therefore such an
indexical (called a propagating indexical) acts as a coroutine reacting
to the changes in the store by enforcing further changes in the store.

   In general there are three stages in the lifetime of a propagating
indexical.  When it is posted it may not be evaluated immediately (e.g.
has to wait until some variables are ground before being able to modify
the store).  Until the preconditions for the evaluation are satisfied,
the coroutine is blocked.  When the indexical becomes unblocked, it
computes a finite domain for intersecting with the domain of its left
hand side.  The coroutine then waits until some change occurs in a
domain of a variable occurring in its right hand side.  Eventually, the
computation reaches a point when the indexical is entailed by the store,
i.e. no changes in its right hand side can prune its left hand side any
longer, and the coroutine can cease to exist.

   Note that FD predicates must be correct and checking (*note CLPFD
Interface::).

   There can be several alternative definitions for the same user
constraint with different strengths in propagation.  For example, the
definition of 'plusd' below encodes the same 'X+Y=T' constraint as the
'plus' predicate above, but maintaining domain consistency:

     plusd(X,Y,T) +:
             X in dom(T) - dom(Y),
             Y in dom(T) - dom(X),
             T in dom(X) + dom(Y).

     | ?- X in {1}\/{3}, Y in {10}\/{20}, plusd(X, Y, T).
     X in{1}\/{3},
     Y in{10}\/{20},
     T in{11}\/{13}\/{21}\/{23}

   This costs more in terms of execution time, but gives more precise
results.  For singleton domains 'plus' and 'plusd' behave in the same
way.

   In our design, general indexicals can only appear in the context of
FD predicate definitions.  The rationale for this restriction is the
need for general indexicals to be able to suspend and resume, and this
ability is only provided by the FD predicate mechanism.

   If the program merely posts a constraint, then it suffices for the
definition to contain a single clause for solving the constraint.  If a
constraint is reified or occurs in a propositional formula, then the
definition must contain four clauses for solving and checking entailment
of the constraint and its negation.  The role of each clause is
reflected in the "neck" operator.  The following table summarizes the
different forms of indexical clauses corresponding to a constraint C.
In all cases, HEAD should be a compound term with all arguments being
distinct variables:

'HEAD +: INDEXICALS.'
     The body consists of propagating indexicals for solving C.  The
     body can in fact be of a more general form--*note Compiled
     Indexicals::.

'HEAD -: INDEXICALS.'
     The body consists of propagating indexicals for solving the
     negation of C.

'HEAD +? INDEXICAL.'
     The body consists of a single checking indexical for testing
     entailment of C.

'HEAD -? INDEXICAL.'
     The body consists of a single checking indexical for testing
     entailment of the negation of C.

   When a constraint is reified as in 'CONSTRAINT #<=> B', the solver
spawns two coroutines corresponding to detecting entailment and
disentailment.  Eventually, one of them will succeed in this and
consequently will bind B to 0 or 1.  A third coroutine is spawned,
waiting for B to become assigned, at which time the constraint (or its
negation) is posted.  In the mean time, the constraint may have been
detected as (dis)entailed, in which case the third coroutine is
dismissed.

   As an example of a constraint with all methods defined, consider the
following library constraint defining a disequation between two domain
variables:

     'x\\=y'(X,Y) +:
             X in \{Y},
             Y in \{X}.
     'x\\=y'(X,Y) -:
             X in dom(Y),
             Y in dom(X).
     'x\\=y'(X,Y) +?
             X in \dom(Y).
     'x\\=y'(X,Y) -?
             X in {Y}.

   The following sections provide more precise coding rules and
operational details for indexicals.  'X in R' denotes an indexical
corresponding to a constraint C.  S denotes the current store.


File: sicstus.info,  Node: Execution of Propagating Indexicals,  Next: Execution of Checking Indexicals,  Prev: FD Predicates,  Up: Defining Primitive Constraints

10.10.10.8 Execution of Propagating Indexicals
..............................................

Consider the definition of a constraint C containing a propagating
indexical 'X in R'.  Let TV(X,C,S) denote the set of values for X that
can make C true in some ground extension of the store S.  Then the
indexical should obey the following coding rules:

   * all arguments of C except X should occur in R
   * if R is ground in S, S(R) = TV(X,C,S)

   If the coding rules are observed, then S(R) can be proven to contain
TV(X,C,S) for all stores in which R is monotone.  Hence it is natural
for the implementation to wait until R becomes monotone before admitting
the propagating indexical for execution.  The execution of 'X in R' thus
involves the following:

   * If D(X,S) is disjoint from S(R), then a contradiction is detected.

   * If D(X,S) is contained in S(R), then D(X,S) does not contain any
     values known to be incompatible with C, and the indexical suspends,
     unless R is ground in S, in which case C is detected as entailed.

   * Otherwise, D(X,S) contains some values that are known to be
     incompatible with C.  Hence, S is extended to (X IN S(R))(S) (X is
     "pruned"), and the indexical suspends, unless R is ground in S, in
     which case C is detected as entailed.

   A propagating indexical is scheduled for execution as follows:

   * it is evaluated initially as soon as it has become monotone
   * it is re-evaluated when one of the following conditions occurs:
       1. the domain of a variable Y that occurs as 'dom(Y)' or
          'card(Y)' in R has been updated
       2. the lower bound of a variable Y that occurs as 'min(Y)' in R
          has been updated
       3. the upper bound of a variable Y that occurs as 'max(Y)' in R
          has been updated


File: sicstus.info,  Node: Execution of Checking Indexicals,  Next: Compiled Indexicals,  Prev: Execution of Propagating Indexicals,  Up: Defining Primitive Constraints

10.10.10.9 Execution of Checking Indexicals
...........................................

Consider the definition of a constraint C containing a checking
indexical 'X in R'.  Let FV(X,C,S) denote the set of values for X that
can make C false in some ground extension of the store S.  Then the
indexical should obey the following coding rules:

   * all arguments of C except X should occur in R
   * if R is ground in S, S(R) = TV(X,C,S)

   If the coding rules are observed, then S(R) can be proven to exclude
FV(X,C,S) for all stores in which R is anti-monotone.  Hence it is
natural for the implementation to wait until R becomes anti-monotone
before admitting the checking indexical for execution.  The execution of
'X in R' thus involves the following:

   * If D(X,S) is contained in S(R), then none of the possible values
     for X can make C false, and so C is detected as entailed.

   * Otherwise, if D(X,S) is disjoint from S(R) and R is ground in S,
     then all possible values for X will make C false, and so C is
     detected as disentailed.

   * Otherwise, D(X,S) contains some values that could make C true and
     some that could make C false, and the indexical suspends.

   A checking indexical is scheduled for execution as follows:

   * it is evaluated initially as soon as it has become anti-monotone
   * it is re-evaluated when one of the following conditions occurs:
       1. the domain of X has been pruned, or X has been assigned
       2. the domain of a variable Y that occurs as 'dom(Y)' or
          'card(Y)' in R has been pruned
       3. the lower bound of a variable Y that occurs as 'min(Y)' in R
          has been increased
       4. the upper bound of a variable Y that occurs as 'max(Y)' in R
          has been decreased


File: sicstus.info,  Node: Compiled Indexicals,  Prev: Execution of Checking Indexicals,  Up: Defining Primitive Constraints

10.10.10.10 Compiled Indexicals
...............................

The arithmetic, membership, and propositional constraints described
earlier are transformed at compile time to conjunctions of library
constraints.  Although linear in the size of the source code, the
expansion of a constraint to library goals can have time and memory
overheads.  Temporary variables holding intermediate values may have to
be introduced, and the grain size of the constraint solver invocations
can be rather small.  Therefore, an automatic translation by compilation
to indexicals is also provided for a selected set of constraints.  The
syntax for this construction is:

'HEAD +: CONSTRAINTBODY   since release 4.1.3'
     HEAD should be a compound term with all arguments being distinct
     variables.  CONSTRAINTBODY should be a constraint amenable to
     compilation to indexicals, and should not contain any variable not
     mentioned in HEAD.  This clause defines the constraint HEAD to hold
     iff CONSTRAINTBODY is true.

   Roughly, a constraint amenable to such compilation is of one of the
following forms, or is a propositional combination of such forms.  *Note
Syntax of Indexicals::.  for the exact definition:

   * "var" 'in' CONSTANTRANGE
   * 'element("var",CLIST,"var")'
   * 'table([VLIST],CTABLE)'
   * LINEXPR RELOP LINEXPR
   * "var" { 'X' stands for 'X#=1' }


File: sicstus.info,  Node: CLPFD Coexisting,  Next: CLPFD Example Programs,  Prev: Defining Primitive Constraints,  Up: lib-clpfd

10.10.11 Coexisting with Attributes and Blocked Goals
-----------------------------------------------------

Domain variables may have attributes from other modules, as well as
blocked goals, attached to them.  However, the CLPFD propagation phase
runs to completion before invoking handlers for such attributes and
resuming such blocked goals.  This could mean in particular that upon
completion of the propagation phase, attribute handlers and blocked
goals for multiple variables are ready to execute.  For details, see the
'verify_attributes/3' hook at *note lib-atts::.


File: sicstus.info,  Node: CLPFD Example Programs,  Next: Syntax Summary,  Prev: CLPFD Coexisting,  Up: lib-clpfd

10.10.12 Example Programs
-------------------------

* Menu:

* Send More Money:: Send More Money
* N Queens:: N Queens
* Cumulative Scheduling:: Cumulative Scheduling

This section contains a few example programs.  The first two programs
are included in a benchmark suite that comes with the distribution.  The
benchmark suite is run by typing:

     | ?- compile(library('clpfd/examples/bench')).
     | ?- make.


File: sicstus.info,  Node: Send More Money,  Next: N Queens,  Up: CLPFD Example Programs

10.10.12.1 Send More Money
..........................

Let us return briefly to the Send More Money problem (*note A Constraint
Satisfaction Problem::).  Its 'sum/8' predicate will expand to a
'scalar_product/4' constraint.  An indexical version is defined simply
by changing the neck symbol of 'sum/8' from ':-' to '+:', thus turning
it into an FD predicate:

     sum(S, E, N, D, M, O, R, Y) +:
                       1000*S + 100*E + 10*N + D
          +            1000*M + 100*O + 10*R + E
          #= 10000*M + 1000*O + 100*N + 10*E + Y.


File: sicstus.info,  Node: N Queens,  Next: Cumulative Scheduling,  Prev: Send More Money,  Up: CLPFD Example Programs

10.10.12.2 N Queens
...................

The problem is to place N queens on an NxN chess board so that no queen
is threatened by another queen.

   The variables of this problem are the N queens.  Each queen has a
designated row.  The problem is to select a column for it.

   The main constraint of this problem is that no queen threaten
another.  This is encoded by the 'no_threat/3' constraint and holds
between all pairs '(X,Y)' of queens.  It could be defined as:

     no_threat(X, Y, I) :-
             X   #\= Y,
             X+I #\= Y,
             X-I #\= Y.

   However, this formulation introduces new temporary domain variables
and creates twelve fine-grained indexicals.  Worse, the disequalities
only maintain bounds consistency and so may miss some opportunities for
pruning elements in the middle of domains.

   A better idea is to formulate 'no_threat/3' as an FD predicate with
two indexicals, as shown in the program below.  This constraint will not
fire until one of the queens has been assigned (the corresponding
indexical does not become monotone until then).  Hence, the constraint
is still not as strong as it could be.

   For example, if the domain of one queen is '2..3', then it will
threaten any queen placed in column 2 or 3 on an adjacent row, no matter
which of the two open positions is chosen for the first queen.  The
commented out formulation of the constraint captures this reasoning, and
illustrates the use of the 'unionof/3' operator.  This stronger version
of the constraint indeed gives less backtracking, but is computationally
more expensive and does not pay off in terms of execution time, except
possibly for very large chess boards.

   It is clear that 'no_threat/3' cannot detect any incompatible values
for a queen with domain of size greater than three.  This observation is
exploited in the third version of the constraint.

   The first-fail principle is appropriate in the enumeration part of
this problem.

     :- use_module(library(clpfd)).

     queens(N, L, LabelingType) :-
          length(L, N),
          domain(L, 1, N),
          constrain_all(L),
          labeling(LabelingType, L).

     constrain_all([]).
     constrain_all([X|Xs]) :-
          constrain_between(X, Xs, 1),
          constrain_all(Xs).

     constrain_between(_X, [], _N).
     constrain_between(X, [Y|Ys], N) :-
          no_threat(X, Y, N),
          N1 is N+1,
          constrain_between(X, Ys, N1).


     % version 1: weak but efficient
     no_threat(X, Y, I) +:
          X in \({Y} \/ {Y+I} \/ {Y-I}),
          Y in \({X} \/ {X+I} \/ {X-I}).

     /*
     % version 2: strong but very inefficient version
     no_threat(X, Y, I) +:
         X in unionof(B,dom(Y),\({B} \/ {B+I} \/ {B-I})),
         Y in unionof(B,dom(X),\({B} \/ {B+I} \/ {B-I})).

     % version 3: strong but somewhat inefficient version
     no_threat(X, Y, I) +:
         X in (4..card(Y)) ? (inf..sup) \/
               unionof(B,dom(Y),\({B} \/ {B+I} \/ {B-I})),
         Y in (4..card(X)) ? (inf..sup) \/
               unionof(B,dom(X),\({B} \/ {B+I} \/ {B-I})).
     */

     | ?- queens(8, L, [ff]).
     L = [1,5,8,6,3,7,2,4]



File: sicstus.info,  Node: Cumulative Scheduling,  Prev: N Queens,  Up: CLPFD Example Programs

10.10.12.3 Cumulative Scheduling
................................

This example is a very small scheduling problem.  We consider seven
tasks where each task has a fixed duration and a fixed amount of used
resource:

TASK     DURATION     RESOURCE
't1'     16           2
't2'     6            9
't3'     13           3
't4'     7            7
't5'     5            10
't6'     18           1
't7'     4            11

   The goal is to find a schedule that minimizes the completion time for
the schedule while not exceeding the capacity 13 of the resource.  The
resource constraint is succinctly captured by a 'cumulative/2'
constraint.  Branch-and-bound search is used to find the minimal
completion time.

   This example was adapted from [Beldiceanu & Contejean 94].

     :- use_module(library(clpfd)).

     schedule(Ss, End) :-
             Ss = [S1,S2,S3,S4,S5,S6,S7],
             Es = [E1,E2,E3,E4,E5,E6,E7],
             Tasks = [task(S1,16,E1, 2,0),
                      task(S2, 6,E2, 9,0),
                      task(S3,13,E3, 3,0),
                      task(S4, 7,E4, 7,0),
                      task(S5, 5,E5,10,0),
                      task(S6,18,E6, 1,0),
                      task(S7, 4,E7,11,0)],
             domain(Ss, 1, 30),
             domain(Es, 1, 50),
             domain([End], 1, 50),
             maximum(End, Es),
             cumulative(Tasks, [limit(13)]),
             append(Ss, [End], Vars),
             labeling([minimize(End)], Vars). % label End last

     %% End of file

     | ?- schedule(Ss, End).
     Ss = [1,17,10,10,5,5,1],
     End = 23


File: sicstus.info,  Node: Syntax Summary,  Prev: CLPFD Example Programs,  Up: lib-clpfd

10.10.13 Syntax Summary
-----------------------

* Menu:

* Syntax of Indexicals:: Syntax of Indexicals
* Syntax of Arithmetic Expressions:: Syntax of Arithmetic Expressions
* Operator Declarations:: Operator Declarations


File: sicstus.info,  Node: Syntax of Indexicals,  Next: Syntax of Arithmetic Expressions,  Up: Syntax Summary

10.10.13.1 Syntax of Indexicals
...............................

CONSTANT       ::= "integer"
               | 'inf'                       { minus infinity }
               | 'sup'                       { plus infinity }
TERM           ::= CONSTANT
               | "var"                       { suspend until assigned }
               | 'min("var")'                { min.  of domain of X }
               | 'max("var")'                { max.  of domain of X }
               | 'card("var")'               { size of domain of X }
               | '-' TERM
               | TERM '+' TERM
               | TERM '-' TERM
               | TERM '*' TERM
               | TERM '/>' TERM              { ceilinged division }
               | TERM '/<' TERM              { floored division }
               | TERM 'mod' TERM             { floored remainder }
               | TERM 'rem' TERM             { truncated remainder }
TERMSET        ::= '{TERM,...,TERM}'
RANGE          ::= TERMSET
               | 'dom("var")'                { domain of X }
               | TERM '..'  TERM             { interval }
               | RANGE '/\' RANGE            { intersection }
               | RANGE '\/' RANGE            { union }
               | '\' RANGE                   { complement }
               | '-' RANGE                   { pointwise negation }
               | RANGE '+' RANGE             { pointwise addition }
               | RANGE '-' RANGE             { pointwise subtraction }
               | RANGE 'mod' RANGE           { pointwise modulo }
               | RANGE 'rem' RANGE           { pointwise remainder }
               | RANGE '+' TERM              { pointwise addition }
               | RANGE '-' TERM              { pointwise subtraction }
               | TERM '-' RANGE              { pointwise subtraction }
               | RANGE 'mod' TERM            { pointwise floored
                                             remainder }
               | RANGE 'rem' TERM            { pointwise truncated
                                             remainder }
               | RANGE '?'  RANGE
               |
               'unionof("var",RANGE,RANGE)'
               | 'switch(TERM,MAPLIST)'
CONSTANTSET    ::= '{INTEGER,...,INTEGER}'
CONSTANTRANGE  ::= CONSTANTSET
               | CONSTANT '..'  CONSTANT
               | CONSTANTRANGE '/\'
               CONSTANTRANGE
               | CONSTANTRANGE '\/'
               CONSTANTRANGE
               | '\' CONSTANTRANGE
MAPLIST        ::= '[]'
               |
               '["integer"-CONSTANTRANGE|MAPLIST]'
CTABLE         ::= '[]'
               | '[CROW|CTABLE]'
CROW           ::= '[]'
               | '["integer"|CROW]'
               | '[CONSTANTRANGE|CROW]'
CLIST          ::= '[]'
               | '["integer"|CLIST]'
VLIST          ::= '[]'
               | '["var"|VLIST]'
INDEXICAL      ::= "var" 'in' RANGE
INDEXICALS     ::= INDEXICAL
               | INDEXICAL ',' INDEXICALS
CONSTRAINTBODY ::= "var" { 'X' stands for
               'X#=1' }
               | 'true'
               | 'false'
               | '1'
               | '0'
               | "var" 'in' CONSTANTRANGE
               |
               'element("var",CLIST,"var")'
               | 'table([VLIST],CTABLE)'
               | LINEXPR RELOP LINEXPR
               | '#\ CONSTRAINTBODY'
               | 'CONSTRAINTBODY #/\
               CONSTRAINTBODY'
               | 'CONSTRAINTBODY #\/
               CONSTRAINTBODY'
               | 'CONSTRAINTBODY #=>
               CONSTRAINTBODY'
               | 'CONSTRAINTBODY #\
               CONSTRAINTBODY'
               | 'CONSTRAINTBODY #<=>
               CONSTRAINTBODY'
IXCONSTRAINTBODY::= INDEXICALS
               | CONSTRAINTBODY
HEAD           ::= "term"                    { a compound term with
                                             unique variable args }
TELLPOS        ::= HEAD '+:'
               IXCONSTRAINTBODY
TELLNEG        ::= HEAD '-:' INDEXICALS
ASKPOS         ::= HEAD '+?'  INDEXICAL
ASKNEG         ::= HEAD '-?'  INDEXICAL
CONSTRAINTDEF  ::= TELLPOS
               | TELLNEG
               | ASKPOS
               | ASKNEG


File: sicstus.info,  Node: Syntax of Arithmetic Expressions,  Next: Operator Declarations,  Prev: Syntax of Indexicals,  Up: Syntax Summary

10.10.13.2 Syntax of Arithmetic Expressions
...........................................

*Please note*: that the Prolog arithmetic operators '/' and '//' do not
mean the same thing.

N              ::= "integer"
LINEXPR        ::= N
               | "var"
               | N '*' "var"
               | N '*' N
               | '-' LINEXPR
               | LINEXPR '+' LINEXPR
               | LINEXPR '-' LINEXPR
               | CONSTRAINTBODY              { if true then 1 else 0 }
EXPR           ::= LINEXPR
               | '-' EXPR
               | EXPR '+' EXPR
               | EXPR '-' EXPR
               | EXPR '*' EXPR
               | EXPR '/' EXPR               { truncated division }
               | EXPR '//' EXPR              { truncated division }  
                                             since release 4.3
               | EXPR 'div' EXPR             { floored division }  
                                             since release 4.3
               | EXPR 'rem' EXPR             { truncated remainder }
               | EXPR 'mod' EXPR             { floored remainder }
               | 'min(EXPR,EXPR)'
               | 'max(EXPR,EXPR)'
               | 'abs(EXPR)'
RELOP          ::= '#=' | '#\=' | '#<' |
               '#=<' | '#>' | '#>='


File: sicstus.info,  Node: Operator Declarations,  Prev: Syntax of Arithmetic Expressions,  Up: Syntax Summary

10.10.13.3 Operator Declarations
................................

     :- op(1200, xfx, [+:,-:,+?,-?]).
     :- op(760, yfx, #<=>).
     :- op(750, xfy, #=>).
     :- op(750, yfx, #<=).
     :- op(740, yfx, #\/).
     :- op(730, yfx, #\).
     :- op(720, yfx, #/\).
     :- op(710, fy, #\).
     :- op(700, xfx, [in,in_set]).
     :- op(700, xfx, [#=,#\=,#<,#=<,#>,#>=]).
     :- op(550, xfx, ..).
     :- op(500, fy, \).
     :- op(490, yfx, ?).
     :- op(400, yfx, [/>,/<]).


File: sicstus.info,  Node: lib-clpqr,  Next: lib-codesio,  Prev: lib-clpfd,  Up: The Prolog Library

10.11 Constraint Logic Programming over Rationals or Reals--'library([clpq,clpr])'
==================================================================================

* Menu:

* CLPQR Introduction:: Introduction
* CLPQR Interface:: Solver Interface
* CLPQR Linearity::                   Linearity and Nonlinear Residues
* CLPQR Numerical Precision::         Numerical Precision and Rationals
* CLPQR Projection::                  Projection and Redundancy Elimination
* CLPQR Why Disequations::            Why Disequations
* CLPQR Monash Examples::             Monash Examples
* CLPQR MIP::                         A Mixed Integer Linear Optimization Example
* CLPQR Implementation Architecture:: Implementation Architecture


File: sicstus.info,  Node: CLPQR Introduction,  Next: CLPQR Interface,  Up: lib-clpqr

10.11.1 Introduction
--------------------

The clp(Q,R) system described in this chapter is an instance of the
general Constraint Logic Programming scheme introduced by [Jaffar &
Michaylov 87].  It is a third-party product, bundled with SICStus Prolog
as two library packages.  It is not supported by SICS in any way.

   The implementation is at least as complete as other existing clp(R)
implementations: It solves linear equations over rational or real valued
variables, covers the lazy treatment of nonlinear equations, features a
decision algorithm for linear inequalities that detects implied
equations, removes redundancies, performs projections (quantifier
elimination), allows for linear dis-equations, and provides for linear
optimization.

* Menu:

* CLPQR Referencing:: Referencing this Software
* CLPQR Acknowledging:: Acknowledgments


File: sicstus.info,  Node: CLPQR Referencing,  Next: CLPQR Acknowledging,  Up: CLPQR Introduction

10.11.1.1 Referencing this Software
...................................

When referring to this implementation of clp(Q,R) in publications, you
should use the following reference:
     Holzbaur C., 'OFAI clp(q,r) Manual', Edition 1.3.3, Austrian
     Research Institute for Artificial Intelligence, Vienna, TR-95-09,
     1995.


File: sicstus.info,  Node: CLPQR Acknowledging,  Prev: CLPQR Referencing,  Up: CLPQR Introduction

10.11.1.2 Acknowledgments
.........................

The development of this software was supported by the Austrian _Fonds
zur Foerderung der Wissenschaftlichen Forschung_ under grant P9426-PHY.
Financial support for the Austrian Research Institute for Artificial
Intelligence is provided by the Austrian Federal Ministry for Science
and Research.

   We include a collection of examples that has been distributed with
the Monash University version of clp(R) [Heintze et al.  87], and its
inclusion into this distribution was kindly permitted by Roland Yap.


File: sicstus.info,  Node: CLPQR Interface,  Next: CLPQR Linearity,  Prev: CLPQR Introduction,  Up: lib-clpqr

10.11.2 Solver Interface
------------------------

Until rational numbers become first class citizens in SICStus Prolog,
rational arithmetics has to be emulated.  Because of the emulation it is
too expensive to support arithmetics with automatic coercion between all
sorts of numbers, like you find it in CommonLisp, for example.

   You must choose whether you want to operate in the field of Q
(Rationals) or R (Reals):

     | ?- use_module(library(clpq)).

     or

     | ?- use_module(library(clpr)).

   You can also load both modules, but the exported predicates listed
below will name clash (*note ref-mod-ncl::).  You can avoid the
interactive resolution dialog if the importation is skipped, e.g. via:
'use_module(library(clpq),[]),use_module(library(clpr),[])'.

* Menu:

* CLPQR Notational Conventions:: Notational Conventions
* CLPQR Solver Predicates:: Solver Predicates
* CLPQR Unification:: Unification
* CLPQR Feedback:: Feedback and Bindings


File: sicstus.info,  Node: CLPQR Notational Conventions,  Next: CLPQR Solver Predicates,  Up: CLPQR Interface

10.11.2.1 Notational Conventions
................................

Throughout this chapter, the prompts 'clp(q) ?-' and 'clp(r) ?-' are
used to differentiate between clp(Q) and clp(R) in exemplary
interactions.

   In general there are many ways to express the same linear
relationship.  This degree of freedom is manifest in the fact that the
printed manual and an actual interaction with the current version of
clp(Q,R) may show syntactically different answer constraints, despite
the fact the same semantic relationship is being expressed.  There are
means to control the presentation; *note CLPQR Variable Ordering::.  The
approximative nature of floating point numbers may also produce
numerical differences between the text in this manual and the actual
results of clp(R), for a given edition of the software.


File: sicstus.info,  Node: CLPQR Solver Predicates,  Next: CLPQR Unification,  Prev: CLPQR Notational Conventions,  Up: CLPQR Interface

10.11.2.2 Solver Predicates
...........................

The solver interface for both Q and R consists of the following
predicates, which are exported from 'module(linear)'.

'{+CONSTRAINT}'

     CONSTRAINT is a term accepted by the grammar below.  The
     corresponding constraint is added to the current constraint store
     and checked for satisfiability.  Use the module prefix to
     distinguish the solvers if both clp(Q) and clp(R) were loaded.
          | ?- clpr:{Ar+Br=10}, Ar=Br, clpq:{Aq+Bq=10}, Aq=Bq.

          Aq = 5,
          Ar = 5.0,
          Bq = 5,
          Br = 5.0

     Although clp(Q) and clp(R) are independent modules, you are asking
     for trouble if you (accidently) share variables between them:
          | ?- clpr:{A+B=10}, clpq:{A=B}.
          ! Type error in argument 2 of clpq:=/2
          ! a rational number expected, but 5.0 found
          ! goal:  _118=5.0

     This is because both solvers eventually compute values for the
     variables and Reals are incompatible with Rationals.

     Here is the constraint grammar:
     CONSTRAINT::= C
             | C ',' C              { conjunction }
     C       ::= EXPR '=:=' EXPR    { equation }
             | EXPR '=' EXPR        { equation }
             | EXPR '<' EXPR        { strict inequation }
             | EXPR '>' EXPR        { strict inequation }
             | EXPR '=<' EXPR       { nonstrict inequation }
             | EXPR '>=' EXPR       { nonstrict inequation }
             | EXPR '=\=' EXPR      { disequation }
     EXPR    ::= "variable"         { Prolog variable }
             | "number"             { floating point or integer
                                    }
             | '+' EXPR             { unary plus }
             | '-' EXPR             { unary minus }
             | EXPR '+' EXPR        { addition }
             | EXPR '-' EXPR        { subtraction }
             | EXPR '*' EXPR        { multiplication }
             | EXPR '/' EXPR        { division }
             | 'abs(EXPR)'          { absolute value }
             | 'sin(EXPR)'          { trigonometric sine }
             | 'cos(EXPR)'          { trigonometric cosine }
             | 'tan(EXPR)'          { trigonometric tangent }
             | 'pow(EXPR,EXPR)'     { raise to the power }
             | 'exp(EXPR,EXPR)'     { raise to the power }
             | 'min(EXPR,EXPR)'     { minimum of the two
                                    arguments }
             | 'max(EXPR,EXPR)'     { maximum of the two
                                    arguments }
             | '#(CONST)'           { symbolic numerical
                                    constants }

     Conjunctive constraints '{C,C}' have been made part of the syntax
     to control the granularity of constraint submission, which will be
     exploited by future versions of this software.  Symbolic numerical
     constants are provided for compatibility only; *note CLPQR Monash
     Examples::.

'entailed(+CONSTRAINT)'

     Succeeds iff the linear CONSTRAINT is entailed by the current
     constraint store.  This predicate does not change the state of the
     constraint store.
          clp(q) ?- {A =< 4}, entailed(A=\=5).

          {A=<4}

          clp(q) ?- {A =< 4}, entailed(A=\=3).

          no

'inf(+EXPR, -INF)'
'inf(+EXPR, -INF, +VECTOR, -VERTEX)'

     Computes the infimum of the linear expression EXPR and unifies it
     with INF.  If given, then VECTOR should be a list of variables
     relevant to EXPR, and VERTEX will be unified a list of the same
     length as VECTOR containing the values for VECTOR, such that the
     infimum is produced when assigned.  Failure indicates
     unboundedness.

'sup(+EXPR, -SUP)'
'sup(+EXPR, -SUP, +VECTOR, -VERTEX)'

     Computes the supremum of the linear expression EXPR and unifies it
     with SUP.  If given, then VECTOR should be a list of variables
     relevant to EXPR, and VERTEX will be unified a list of the same
     length as VECTOR containing the values for VECTOR, such that the
     supremum is produced when assigned.  Failure indicates
     unboundedness.

          clp(q) ?- { 2*X+Y =< 16, X+2*Y =< 11,
                      X+3*Y =< 15, Z = 30*X+50*Y
                    }, sup(Z, Sup, [X,Y], Vertex).

          Sup = 310,
          Vertex = [7,2],
          {Z=30*X+50*Y},
          {X+1/2*Y=<8},
          {X+3*Y=<15},
          {X+2*Y=<11}

'minimize(+EXPR)'

     Computes the infimum of the linear expression EXPR and equates it
     with the expression, i.e. as if defined as:
          minimize(Expr) :- inf(Expr, Expr).

'maximize(+EXPR)'

     Computes the supremum of the linear expression EXPR and equates it
     with the expression.
          clp(q) ?- { 2*X+Y =< 16, X+2*Y =< 11,
                      X+3*Y =< 15, Z = 30*X+50*Y
                    }, maximize(Z).

          X = 7,
          Y = 2,
          Z = 310

'bb_inf(+INTS, +EXPR, -INF)'

     Computes the infimum of the linear expression EXPR under the
     additional constraint that all of variables in the list INTS assume
     integral values at the infimum.  This allows for the solution of
     mixed integer linear optimization problems; *note CLPQR MIP::.
          clp(q) ?- {X >= Y+Z, Y > 1, Z > 1}, bb_inf([Y,Z],X,Inf).

          Inf = 4,
          {Y>1},
          {Z>1},
          {X-Y-Z>=0}

'bb_inf(+INTS, +EXPR, -INF, -VERTEX, +EPS)'

     Computes the infimum of the linear expression EXPR under the
     additional constraint that all of variables in the list INTS assume
     integral values at the infimum.  EPS is a positive number between 0
     and 0.5 that specifies how close a number X must be to the next
     integer to be considered integral: 'abs(round(X)-X) < EPS'.  The
     predicate 'bb_inf/3' uses 'EPS = 0.001'.  With clp(Q), 'EPS = 0'
     makes sense.  VERTEX is a list of the same length as INTS and
     contains the (integral) values for INTS, such that the infimum is
     produced when assigned.  Note that this will only generate one
     particular solution, which is different from the situation with
     'minimize/1', where the general solution is exhibited.

     'bb_inf/5' works properly for non-strict inequalities only!
     Disequations ('=\=') and higher dimensional strict inequalities
     ('>','<') are beyond its scope.  Strict bounds on the decision
     variables are honored however:

          clp(q) ?- {X >= Y+Z, Y > 1, Z > 1}, bb_inf([Y,Z],X,Inf,Vertex,0).

          Inf = 4,
          Vertex = [2,2],
          {Y>1},
          {Z>1},
          {X-Y-Z>=0}

     The limitation(s) can be addressed by:

        * transforming the original problem statement so that only
          non-strict inequalities remain; for example, '{X + Y > 0}'
          becomes '{X + Y >= 1}' for integral 'X' and 'Y';

        * contemplating the use of clp(FD).

'ordering(+SPEC)'

     Provides a means to control one aspect of the presentation of the
     answer constraints; *note CLPQR Variable Ordering::.

'dump(+TARGET, -NEWVARS, -CODEDANSWER)'

     Reflects the constraints on the target variables into a term, where
     TARGET and NEWVARS are lists of variables of equal length and
     CODEDANSWER is the term representation of the projection of
     constraints onto the target variables where the target variables
     are replaced by the corresponding variables from NEWVARS (*note
     CLPQR Turning Answers into Terms::).
          clp(q) ?- {A+B =< 10, A>=4}, 
                    dump([A,B],Vs,Cs), 
                    dump([B],Bp,Cb).

          Cb = [_A=<6],
          Bp = [_A],
          Cs = [_B>=4,_C+_B=<10],
          Vs = [_C,_B],
          {A>=4},
          {A+B=<10}
     The current version of 'dump/3' is incomplete with respect to
     nonlinear constraints.  It only reports nonlinear constraints that
     are connected to the target variables.  The following example has
     no solution.  From the top-level's report we have a chance to
     deduce this fact, but 'dump/3' currently has no means to collect
     global constraints ...
          q(X) :-
                  {X>=10},
                  {sin(Z)>3}.

          clp(r) ?- q(X), dump([X],V,C).

          C = [_A>=10.0],
          V = [_A],
          clpr:{3.0-sin(_B)<0.0},
          {X>=10.0}

'projecting_assert/1(:CLAUSE)'

     If you use the database, then the clauses you assert might have
     constraints associated with their variables.  Use this predicate
     instead of 'assert/1' in order to ensure that only the relevant and
     projected constraints get stored in the database.  It will
     transform the clause into one with plain variables and extra body
     goals that set up the relevant constraint when called.


File: sicstus.info,  Node: CLPQR Unification,  Next: CLPQR Feedback,  Prev: CLPQR Solver Predicates,  Up: CLPQR Interface

10.11.2.3 Unification
.....................

Equality constraints are added to the store implicitly each time
variables that have been mentioned in explicit constraints are
bound--either to another such variable or to a number.
     clp(r) ?- {2*A+3*B=C/2}, C=10.0, A=B.

     A = 1.0,
     B = 1.0,
     C = 10.0
   Is equivalent modulo rounding errors to
     clp(r) ?- {2*A+3*B=C/2, C=10, A=B}.

     A = 1.0,
     B = 0.9999999999999999,
     C = 10.0
   The shortcut bypassing the use of '{}/1' is allowed and makes sense
because the interpretation of this equality in Prolog and clp(R)
coincides.  In general, equations involving interpreted functors, '+/2'
in this case, must be fed to the solver explicitly:
     clp(r) ?- X=3.0+1.0, X=4.0.

     no

   Moreover, variables known by clp(R) may be bound directly to floats
only.  Likewise, variables known by clp(Q) may be bound directly to
rational numbers only; *note CLPQR Fragments and Bits::.  Failing to do
so is rewarded with an exception:
     clp(q) ?- {2*A+3*B=C/2}, C=10.0, A=B.
     ! Type error in argument 2 of = /2
     ! 'a rational number' expected, but 10.0 found
     ! goal:  _254=10.0

   This is because '10.0' is not a rational constant.  To make clp(Q)
happy you have to say:
     clp(q) ?- {2*A+3*B=C/2}, C=rat(10,1), A=B.

     A = 1,
     B = 1,
     C = 10

   If you use '{}/1', then you do not have to worry about such details.


File: sicstus.info,  Node: CLPQR Feedback,  Prev: CLPQR Unification,  Up: CLPQR Interface

10.11.2.4 Feedback and Bindings
...............................

What was covered so far was how the user populates the constraint store.
The other direction of the information flow consists of the success and
failure of the above predicates and the binding of variables to
numerical values.  Example:
     clp(r) ?- {A-B+C=10, C=5+5}.

     {A = B},
     C = 10.0
   The linear constraints imply 'C=10.0' and the solver consequently
exports this binding to the Prolog world.  The fact that 'A=B' is
deduced and represented by the solver but not exported as a binding.
More about answer presentation in *note CLPQR Projection::.


File: sicstus.info,  Node: CLPQR Linearity,  Next: CLPQR Numerical Precision,  Prev: CLPQR Interface,  Up: lib-clpqr

10.11.3 Linearity and Nonlinear Residues
----------------------------------------

The clp(Q,R) system is restricted to deal with linear constraints
because the decision algorithms for general nonlinear constraints are
prohibitively expensive to run.  If you need this functionality badly,
then you should look into symbolic algebra packages.  Although the
clp(Q,R) system cannot solve nonlinear constraints, it will collect them
faithfully in the hope that through the addition of further (linear)
constraints they might get simple enough to solve eventually.  If an
answer contains nonlinear constraints, then you have to be aware of the
fact that success is qualified modulo the existence of a solution to the
system of residual (nonlinear) constraints:
     clp(r) ?- {sin(X) = cos(X)}.

     clpr:{sin(X)-cos(X)=0.0}
   There are indeed infinitely many solutions to this constraint ('X =
0.785398 + n*Pi'), but clp(Q,R) has no direct means to find and
represent them.

   The systems goes through some lengths to recognize linear expressions
as such.  The method is based on a normal form for multivariate
polynomials.  In addition, some simple isolation axioms, that can be
used in equality constraints, have been added.  The current major
limitation of the method is that full polynomial division has not been
implemented.  Examples:

This is an example where the isolation axioms are sufficient to
determine the value of X.
     clp(r) ?- {sin(cos(X)) = 1/2}.

     X = 1.0197267436954502

If we change the equation into an inequation, then clp(Q,R) gives up:
     clp(r) ?- {sin(cos(X)) < 1/2}.

     clpr:{sin(cos(X))-0.5<0.0}

The following is easy again:
     clp(r) ?- {sin(X+2+2)/sin(4+X) = Y}.

     Y = 1.0

And so is this:
     clp(r) ?- {(X+Y)*(Y+X)/X = Y*Y/X+99}.

     {Y=49.5-0.5*X}

An ancient symbol manipulation benchmark consists in rising the
expression 'X+Y+Z+1' to the 15th power:
     clp(q) ?- {exp(X+Y+Z+1,15)=0}.
     clpq:{Z^15+Z^14*15+Z^13*105+Z^12*455+Z^11*1365+Z^10*3003+...
            ... polynomial continues for a few pages ...
            =0}
Computing its roots is another story.

* Menu:

* CLPQR How Nonlinear Residues Are Made to Disappear:: How Nonlinear Residues Are Made to Disappear
* CLPQR Isolation Axioms:: Isolation Axioms


File: sicstus.info,  Node: CLPQR How Nonlinear Residues Are Made to Disappear,  Next: CLPQR Isolation Axioms,  Up: CLPQR Linearity

10.11.3.1 How Nonlinear Residues Are Made to Disappear
......................................................

Binding variables that appear in nonlinear residues will reduce the
complexity of the nonlinear expressions and eventually results in linear
expressions:
     clp(q) ?- {exp(X+Y+1,2) = 3*X*X+Y*Y}.

     clpq:{Y*2-X^2*2+Y*X*2+X*2+1=0}
Equating X and Y collapses the expression completely and even determines
the values of the two variables:
     clp(q) ?- {exp(X+Y+1,2) = 3*X*X+Y*Y}, X=Y.

     X = -1/4,
     Y = -1/4


File: sicstus.info,  Node: CLPQR Isolation Axioms,  Prev: CLPQR How Nonlinear Residues Are Made to Disappear,  Up: CLPQR Linearity

10.11.3.2 Isolation Axioms
..........................

These axioms are used to rewrite equations such that the variable to be
solved for is moved to the left hand side and the result of the
evaluation of the right hand side can be assigned to the variable.  This
allows, for example, to use the exponentiation operator for the
computation of roots and logarithms; see below.
'A = B * C'
     Residuates unless B or C is ground or A and B or C are ground.

'A = B / C'
     Residuates unless C is ground or A and B are ground.

'X = min(Y,Z)'
     Residuates unless Y and Z are ground.

'X = max(Y,Z)'
     Residuates unless Y and Z are ground.

'X = abs(Y)'
     Residuates unless Y is ground.

'X = pow(Y,Z), X = exp(Y,Z)'
     Residuates unless any pair of two of the three variables is ground.
     Example:

          clp(r) ?- { 12=pow(2,X) }.

          X = 3.5849625007211565

          clp(r) ?- { 12=pow(X,3.585) }.

          X = 1.9999854993443926

          clp(r) ?- { X=pow(2,3.585) }.

          X = 12.000311914286545

'X = sin(Y)'
     Residuates unless X or Y is ground.  Example:

          clp(r) ?- { 1/2 = sin(X) }.

          X = 0.5235987755982989

'X = cos(Y)'
     Residuates unless X or Y is ground.

'X = tan(Y)'
     Residuates unless X or Y is ground.


File: sicstus.info,  Node: CLPQR Numerical Precision,  Next: CLPQR Projection,  Prev: CLPQR Linearity,  Up: lib-clpqr

10.11.4 Numerical Precision and Rationals
-----------------------------------------

The fact that you can switch between clp(R) and clp(Q) should solve most
of your numerical problems regarding precision.  Within clp(Q), floating
point constants will be coerced into rational numbers automatically.
Transcendental functions will be approximated with rationals.  The
precision of the approximation is limited by the floating point
precision.  These two provisions allow you to switch between clp(R) and
clp(Q) without having to change your programs.

   What is to be kept in mind however is the fact that it may take quite
big rationals to accommodate the required precision.  High levels of
precision are for example required if your linear program is
ill-conditioned, i.e. in a full rank system the determinant of the
coefficient matrix is close to zero.  Another situation that may call
for elevated levels of precision is when a linear optimization problem
requires exceedingly many pivot steps before the optimum is reached.

   If your application approximates irrational numbers, then you may be
out of space particularly soon.  The following program implements N
steps of Newton's approximation for the square root function at point 2.
                                     _% library('clpqr/examples/root')_
     root(N, R) :-
       root(N, 1, R).

     root(0, S, R) :- !, S=R.
     root(N, S, R) :-
       N1 is N-1,
       { S1 = S/2 + 1/S },
       root(N1, S1, R).
It is known that this approximation converges quadratically, which means
that the number of correct digits in the decimal expansion roughly
doubles with each iteration.  Therefore the numerator and denominator of
the rational approximation have to grow likewise:
     clp(q) ?- [library('clpqr/examples/root')].
     clp(q) ?- root(3,R),print_decimal(R,70).
     1.4142156862 7450980392 1568627450 9803921568 6274509803 9215686274
     5098039215

     R = 577/408

     clp(q) ?- root(4,R),print_decimal(R,70).
     1.4142135623 7468991062 6295578890 1349101165 5962211574 4044584905
     0192000543

     R = 665857/470832

     clp(q) ?- root(5,R),print_decimal(R,70).
     1.4142135623 7309504880 1689623502 5302436149 8192577619 7428498289
     4986231958

     R = 886731088897/627013566048

     clp(q) ?- root(6,R),print_decimal(R,70).
     1.4142135623 7309504880 1688724209 6980785696 7187537723 4001561013
     1331132652

     R = 1572584048032918633353217/1111984844349868137938112

     clp(q) ?- root(7,R),print_decimal(R,70).
     1.4142135623 7309504880 1688724209 6980785696 7187537694 8073176679
     7379907324

     R = 4946041176255201878775086487573351061418968498177 /
         3497379255757941172020851852070562919437964212608
Iterating for 8 steps produces no further change in the first 70 decimal
digits of 'sqrt(2)'.  After 15 steps the approximating rational number
has a numerator and a denominator with 12543 digits each, and the next
step runs out of memory.

   Another irrational number that is easily computed is E.  The
following program implements an alternating series for '1/e', where the
absolute value of last term is an upper bound on the error.
                                     _% library('clpqr/examples/root')_
     e(N, E) :-
       { Err =:= exp(10,-(N+2)), Half =:= 1/2 },
       inv_e_series(Half, Half, 3, Err, Inv_E),
       { E =:= 1/Inv_E }.

     inv_e_series(Term, S0, _, Err, Sum) :-
       { abs(Term) =< Err }, !,
       S0 = Sum.
     inv_e_series(Term, S0, N, Err, Sum) :-
       N1 is N+1,
       { Term1 =:= -Term/N, S1 =:= Term1+S0 },
       inv_e_series(Term1, S1, N1, Err, Sum).
The computation of the rational number E that approximates E up to at
least 1000 digits in its decimal expansion requires the evaluation of
450 terms of the series, i.e. 450 calls of 'inv_e_series/5'.
     clp(q) ?- e(1000,E).

     E = 7149056228932760213666809592072842334290744221392610955845565494
         3708750229467761730471738895197792271346693089326102132000338192
         0131874187833985420922688804220167840319199699494193852403223700
         5853832741544191628747052136402176941963825543565900589161585723
         4023097417605004829991929283045372355639145644588174733401360176
         9953973706537274133283614740902771561159913069917833820285608440
         3104966899999651928637634656418969027076699082888742481392304807
         9484725489080844360397606199771786024695620205344042765860581379
         3538290451208322129898069978107971226873160872046731879753034549
         3130492167474809196348846916421782850086985668680640425192038155
         4902863298351349469211627292865440876581064873866786120098602898
         8799130098877372097360065934827751120659213470528793143805903554
         7928682131082164366007016698761961066948371407368962539467994627
         1374858249110795976398595034606994740186040425117101588480000000
         0000000000000000000000000000000000000000000000000000000000000000
         00000000000000000000000000000000000000
         /
         2629990810403002651095959155503002285441272170673105334466808931
         6863103901346024240326549035084528682487048064823380723787110941
         6809235187356318780972302796570251102928552003708556939314795678
         1978390674393498540663747334079841518303636625888963910391440709
         0887345797303470959207883316838346973393937778363411195624313553
         8835644822353659840936818391050630360633734935381528275392050975
         7271468992840907541350345459011192466892177866882264242860412188
         0652112744642450404625763019639086944558899249788084559753723892
         1643188991444945360726899532023542969572584363761073528841147012
         2634218045463494055807073778490814692996517359952229262198396182
         1838930043528583109973872348193806830382584040536394640895148751
         0766256738740729894909630785260101721285704616818889741995949666
         6303289703199393801976334974240815397920213059799071915067856758
         6716458821062645562512745336709063396510021681900076680696945309
         3660590933279867736747926648678738515702777431353845466199680991
         73361873421152165477774911660108200059

   The decimal expansion itself looks like this:
     clp(q) ?- e(1000, E), print_decimal(E, 1000).
     2.
     7182818284 5904523536 0287471352 6624977572 4709369995 9574966967
     6277240766 3035354759 4571382178 5251664274 2746639193 2003059921
     8174135966 2904357290 0334295260 5956307381 3232862794 3490763233
     8298807531 9525101901 1573834187 9307021540 8914993488 4167509244
     7614606680 8226480016 8477411853 7423454424 3710753907 7744992069
     5517027618 3860626133 1384583000 7520449338 2656029760 6737113200
     7093287091 2744374704 7230696977 2093101416 9283681902 5515108657
     4637721112 5238978442 5056953696 7707854499 6996794686 4454905987
     9316368892 3009879312 7736178215 4249992295 7635148220 8269895193
     6680331825 2886939849 6465105820 9392398294 8879332036 2509443117
     3012381970 6841614039 7019837679 3206832823 7646480429 5311802328
     7825098194 5581530175 6717361332 0698112509 9618188159 3041690351
     5988885193 4580727386 6738589422 8792284998 9208680582 5749279610
     4841984443 6346324496 8487560233 6248270419 7862320900 2160990235
     3043699418 4914631409 3431738143 6405462531 5209618369 0888707016
     7683964243 7814059271 4563549061 3031072085 1038375051 0115747704
     1718986106 8739696552 1267154688 9570350354


File: sicstus.info,  Node: CLPQR Projection,  Next: CLPQR Why Disequations,  Prev: CLPQR Numerical Precision,  Up: lib-clpqr

10.11.5 Projection and Redundancy Elimination
---------------------------------------------

Once a derivation succeeds, the Prolog system presents the bindings for
the variables in the query.  In a CLP system, the set of answer
constraints is presented in analogy.  A complication in the CLP context
are variables and associated constraints that were not mentioned in the
query.  A motivating example is the familiar 'mortgage' relation:
                                       _% library('clpqr/examples/mg')_
     mg(P,T,I,B,MP):-
       {
          T = 1,
          B + MP = P * (1 + I)
       }.
     mg(P,T,I,B,MP):-
       {
          T > 1,
          P1 = P * (1 + I) - MP,
          T1 = T - 1
       },
       mg(P1, T1, I, B, MP).
   A sample query yields:
     clp(r) ?- [library('clpqr/examples/mg')].
     clp(r) ?- mg(P,12,0.01,B,Mp).

     {B=1.1268250301319698*P-12.682503013196973*Mp}
   Without projection of the answer constraints onto the query variables
we would observe the following interaction:
     clp(r) ?- mg(P,12,0.01,B,Mp).

     {B=12.682503013196973*_A-11.682503013196971*P},
     {Mp= -(_A)+1.01*P},
     {_B=2.01*_A-1.01*P},
     {_C=3.0301*_A-2.0301*P},
     {_D=4.060401000000001*_A-3.0604009999999997*P},
     {_E=5.101005010000001*_A-4.10100501*P},
     {_F=6.152015060100001*_A-5.152015060099999*P},
     {_G=7.213535210701001*_A-6.213535210700999*P},
     {_H=8.285670562808011*_A-7.285670562808009*P},
     {_I=9.368527268436091*_A-8.36852726843609*P},
     {_J=10.462212541120453*_A-9.46221254112045*P},
     {_K=11.566834666531657*_A-10.566834666531655*P}
   The variables _A ... _K are not part of the query, they originate
from the mortgage program proper.  Although the latter answer is
equivalent to the former in terms of linear algebra, most users would
prefer the former.

* Menu:

* CLPQR Variable Ordering:: Variable Ordering
* CLPQR Turning Answers into Terms:: Turning Answers into Terms
* CLPQR Projecting Inequalities:: Projecting Inequalities


File: sicstus.info,  Node: CLPQR Variable Ordering,  Next: CLPQR Turning Answers into Terms,  Up: CLPQR Projection

10.11.5.1 Variable Ordering
...........................

In general, there are many ways to express the same linear relationship
between variables.  clp(Q,R) does not care to distinguish between them,
but the user might.  The predicate 'ordering(+SPEC)' gives you some
control over the variable ordering.  Suppose that instead of B, you want
MP to be the defined variable:
     clp(r) ?- mg(P,12,0.01,B,Mp).

     {B=1.1268250301319698*P-12.682503013196973*Mp}
   This is achieved with:
     clp(r) ?- mg(P,12,0.01,B,Mp), ordering([Mp]).

     {Mp= -0.0788487886783417*B+0.08884878867834171*P}
   One could go one step further and require P to appear before (to the
left of) B in an addition:
     clp(r) ?- mg(P,12,0.01,B,Mp), ordering([Mp,P]).

     {Mp=0.08884878867834171*P-0.0788487886783417*B}

   SPEC in 'ordering(+SPEC)' is either a list of variables with the
intended ordering, or of the form 'A<B'.  The latter form means that A
goes to the left of B.  In fact, 'ordering([A,B,C,D])' is shorthand for:
     ordering(A < B), ordering(A < C), ordering(A < D),
     ordering(B < C), ordering(B < D),
     ordering(C < D)

   The ordering specification only affects the final presentation of the
constraints.  For all other operations of clp(Q,R), the ordering is
immaterial.  Note that 'ordering/1' acts like a constraint: you can put
it anywhere in the computation, and you can submit multiple
specifications.
     clp(r) ?- ordering(B < Mp), mg(P,12,0.01,B,Mp).

     {B= -12.682503013196973*Mp+1.1268250301319698*P}

     clp(r) ?- ordering(B < Mp), mg(P,12,0.01,B,Mp), ordering(P < Mp).

     {P=0.8874492252651537*B+11.255077473484631*Mp}


File: sicstus.info,  Node: CLPQR Turning Answers into Terms,  Next: CLPQR Projecting Inequalities,  Prev: CLPQR Variable Ordering,  Up: CLPQR Projection

10.11.5.2 Turning Answers into Terms
....................................

In meta-programming applications one needs to get a grip on the results
computed by the clp(Q,R) solver.  You can use the predicate 'dump/3' for
that purpose:
     clp(r) ?- {2*A+B+C=10,C-D=E,A<10}, dump([A,B,C,D,E],[a,b,c,d,e],Constraints).

     Constraints = [e<10.0,a=10.0-c-d-2.0*e,b=c+d],
     {C=10.0-2.0*A-B},
     {E=10.0-2.0*A-B-D},
     {A<10.0}


File: sicstus.info,  Node: CLPQR Projecting Inequalities,  Prev: CLPQR Turning Answers into Terms,  Up: CLPQR Projection

10.11.5.3 Projecting Inequalities
.................................

As soon as linear inequations are involved, projection gets more
demanding complexity wise.  The current clp(Q,R) version uses a
Fourier-Motzkin algorithm for the projection of linear inequalities.
The choice of a suitable algorithm is somewhat dependent on the number
of variables to be eliminated, the total number of variables, and other
factors.  It is quite easy to produce problems of moderate size where
the elimination step takes some time.  For example, when the dimension
of the projection is 1, you might be better off computing the supremum
and the infimum of the remaining variable instead of eliminating 'n-1'
variables via implicit projection.

   In order to make answers as concise as possible, redundant
constraints are removed by the system as well.  In the following set of
inequalities, half of them are redundant.
                                 _% library('clpqr/examples/eliminat')_
     example(2, [X0,X1,X2,X3,X4]) :-
       {
            +87*X0  +52*X1  +27*X2  -54*X3  +56*X4 =<  -93,
            +33*X0  -10*X1  +61*X2  -28*X3  -29*X4 =<   63,
            -68*X0   +8*X1  +35*X2  +68*X3  +35*X4 =<  -85,
            +90*X0  +60*X1  -76*X2  -53*X3  +24*X4 =<  -68,
            -95*X0  -10*X1  +64*X2  +76*X3  -24*X4 =<   33,
            +43*X0  -22*X1  +67*X2  -68*X3  -92*X4 =<  -97,
            +39*X0   +7*X1  +62*X2  +54*X3  -26*X4 =<  -27,
            +48*X0  -13*X1   +7*X2  -61*X3  -59*X4 =<   -2,
            +49*X0  -23*X1  -31*X2  -76*X3  +27*X4 =<    3,
            -50*X0  +58*X1   -1*X2  +57*X3  +20*X4 =<    6,
            -13*X0  -63*X1  +81*X2   -3*X3  +70*X4 =<   64,
            +20*X0  +67*X1  -23*X2  -41*X3  -66*X4 =<   52,
            -81*X0  -44*X1  +19*X2  -22*X3  -73*X4 =<  -17,
            -43*X0   -9*X1  +14*X2  +27*X3  +40*X4 =<   39,
            +16*X0  +83*X1  +89*X2  +25*X3  +55*X4 =<   36,
             +2*X0  +40*X1  +65*X2  +59*X3  -32*X4 =<   13,
            -65*X0  -11*X1  +10*X2  -13*X3  +91*X4 =<   49,
            +93*X0  -73*X1  +91*X2   -1*X3  +23*X4 =<  -87
       }.
   Consequently, the answer consists of the system of nine non-redundant
inequalities only:
     clp(q) ?- [library('clpqr/examples/eliminat')].
     clp(q) ?- example(2, [X0,X1,X2,X3,X4]).

     {X0-2/17*X1-35/68*X2-X3-35/68*X4>=5/4},
     {X0-73/93*X1+91/93*X2-1/93*X3+23/93*X4=<-29/31},
     {X0-29/25*X1+1/50*X2-57/50*X3-2/5*X4>=-3/25},
     {X0+7/39*X1+62/39*X2+18/13*X3-2/3*X4=<-9/13},
     {X0+2/19*X1-64/95*X2-4/5*X3+24/95*X4>=-33/95},
     {X0+2/3*X1-38/45*X2-53/90*X3+4/15*X4=<-34/45},
     {X0-23/49*X1-31/49*X2-76/49*X3+27/49*X4=<3/49},
     {X0+44/81*X1-19/81*X2+22/81*X3+73/81*X4>=17/81},
     {X0+9/43*X1-14/43*X2-27/43*X3-40/43*X4>=-39/43}

   The projection (the shadow) of this polyhedral set into the 'X0,X1'
space can be computed via the implicit elimination of non-query
variables:
     clp(q) ?- example(2, [X0,X1|_]).

     {X0+2619277/17854273*X1>=-851123/17854273},
     {X0+6429953/16575801*X1=<-12749681/16575801},
     {X0+19130/1213083*X1>=795400/404361},
     {X0-1251619/3956679*X1>=21101146/3956679},
     {X0+601502/4257189*X1>=220850/473021}

   Projection is quite a powerful concept that leads to surprisingly
terse executable specifications of nontrivial problems like the
computation of the convex hull from a set of points in an n-dimensional
space: Given the program
                              _% library('clpqr/examples/elimination')_
     conv_hull(Points, Xs) :-
       lin_comb(Points, Lambdas, Zero, Xs),
       zero(Zero),
       polytope(Lambdas).

     polytope(Xs) :-
       positive_sum(Xs, 1).

       positive_sum([], Z) :- {Z=0}.
       positive_sum([X|Xs], SumX) :-
         { X >= 0, SumX = X+Sum },
         positive_sum(Xs, Sum).

     zero([]).
     zero([Z|Zs]) :- {Z=0}, zero(Zs).

     lin_comb([],        [],     S1, S1).
     lin_comb([Ps|Rest], [K|Ks], S1, S3) :-
       lin_comb_r(Ps, K, S1, S2),
       lin_comb(Rest, Ks, S2, S3).

       lin_comb_r([],     _, [],     []).
       lin_comb_r([P|Ps], K, [S|Ss], [Kps|Ss1]) :-
         { Kps = K*P+S },
         lin_comb_r(Ps, K, Ss, Ss1).
   we can post the following query:
     clp(q) ?- conv_hull([ [1,1], [2,0], [3,0], [1,2], [2,2] ], [X,Y]).

     {Y=<2},
     {X+1/2*Y=<3},
     {X>=1},
     {Y>=0},
     {X+Y>=2}
   This answer is easily verified graphically:
            |
          2 -    *    *
            |
            |
          1 -    *
            |
            |
          0 -----|----*----*----
                 1    2    3
   The convex hull program directly corresponds to the mathematical
definition of the convex hull.  What does the trick in operational terms
is the implicit elimination of the LAMBDAS from the program formulation.
Please note that this program does not limit the number of points or the
dimension of the space they are from.  Please note further that
quantifier elimination is a computationally expensive operation and
therefore this program is only useful as a benchmark for the projector
and not so for the intended purpose.

